<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 18]
- [cs.AI](#cs.AI) [Total: 35]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Short-Context Dominance: How Much Local Context Natural Language Actually Needs?](https://arxiv.org/abs/2512.08082)
*Vala Vakilian,Zimeng Wang,Ankit Singh Rawat,Christos Thrampoulidis*

Main category: cs.CL

TL;DR: 이 논문은 대부분의 토큰 예측이 긴 문맥 전체가 아니라 짧은 최근 문맥만으로 가능하다는 ‘short-context dominance’ 가설을 실증적으로 검증하고, 예외적으로 긴 문맥이 꼭 필요한 경우를 자동 탐지·보정하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 언어모델은 긴 컨텍스트를 처리할 수 있게 설계되지만, 실제 예측 시 얼마나 자주 긴 문맥이 정말로 필요한지, 그리고 짧은 문맥 위주의 학습·추론이 성능 편향을 만들고 있는지 체계적 이해가 부족하다. 만약 대부분의 토큰이 짧은 문맥만으로 예측 가능하다면, 긴 문맥이 중요한 ‘어려운’ 경우를 탐지·강조해 LLM의 긴 문맥 이해 성능을 개선할 수 있다.

Method: 1) 대형 LLM을 통계적 오라클로 사용해, 전체 문맥을 썼을 때의 다음 토큰 분포를 얼마나 잘 재현하는지를 기준으로 ‘최소 필요 문맥 길이(MCL)’를 정의하고, 다양한 길이(1–7k 토큰)의 시퀀스에 대해 MCL을 계산한다. 2) 실제 정답 토큰을 몰라도 추정 가능한 MCL 대용 지표 ‘DaMCL(Distributionally Aware MCL)’를 설계해, 그 값을 단순 임계값으로 분류해도 긴 문맥 필요 여부(롱 vs 숏 컨텍스트)를 잘 판별하는지 실험한다. 3) DaMCL 기반 검출기를 활용해, 디코딩 중 긴 거리 정보에 의존하는 토큰 후보를 식별·가중치를 높여주는 직관적인 디코딩 알고리즘을 설계하고, 여러 Q&A 태스크와 모델 아키텍처에서 성능 향상을 측정한다.

Result: 긴 문맥 문서에서 1–7k 토큰 길이의 시퀀스를 분석한 결과, 약 75–80%의 토큰은 최대 96개 정도의 최근 토큰만으로도 전체 문맥을 사용했을 때와 동등한 예측 분포를 재현할 수 있음을 보였다. 제안한 DaMCL 지표는 실제 정답 토큰 정보 없이도 긴 문맥 의존 토큰을 효과적으로 탐지하며, 단순 thresholding만으로도 롱/숏 컨텍스트 구분에서 높은 탐지 성능을 달성한다. 그 위에 구축한 디코딩 알고리즘은 다양한 질의응답 작업과 여러 LLM 아키텍처 전반에 걸쳐 성능 향상을 보였다.

Conclusion: LLM의 다음 토큰 예측은 대다수가 매우 짧은 최근 문맥에 의해 지배되지만, 소수의 토큰은 진정한 긴 문맥 이해를 요구한다. 제안한 DaMCL 지표와 이를 활용한 디코딩 전략은 이러한 ‘긴 문맥 의존’ 토큰을 실용적으로 식별하고 가중함으로써, 짧은 문맥 편향을 완화하고 Q&A 과제를 비롯한 다양한 태스크에서 성능을 개선할 수 있음을 보여준다.

Abstract: We investigate the short-context dominance hypothesis: that for most sequences, a small local prefix suffices to predict their next tokens. Using large language models as statistical oracles, we measure the minimum context length (MCL) needed to reproduce accurate full-context predictions across datasets with sequences of varying lengths. For sequences with 1-7k tokens from long-context documents, we consistently find that 75-80% require only the last 96 tokens at most. Given the dominance of short-context tokens, we then ask whether it is possible to detect challenging long-context sequences for which a short local prefix does not suffice for prediction. We introduce a practical proxy to MCL, called Distributionally Aware MCL (DaMCL), that does not require knowledge of the actual next-token and is compatible with sampling strategies beyond greedy decoding. Our experiments validate that simple thresholding of the metric defining DaMCL achieves high performance in detecting long vs. short context sequences. Finally, to counter the bias that short-context dominance induces in LLM output distributions, we develop an intuitive decoding algorithm that leverages our detector to identify and boost tokens that are long-range-relevant. Across Q&A tasks and model architectures, we confirm that mitigating the bias improves performance.

</details>


### [2] [Adaptation of Embedding Models to Financial Filings via LLM Distillation](https://arxiv.org/abs/2512.08088)
*Eliot Brenner,Dominic Seyler,Manjunath Hegde,Andrei Simion,Koustuv Dasgupta,Bing Xiang*

Main category: cs.CL

TL;DR: 이 논문은 범용 임베딩 모델을 교사로 삼아, 라벨이 없는 대규모 금융 도메인 말뭉치에서 특화 검색 임베딩(바이인코더) 모델을 자동으로 학습하는 파이프라인을 제안하며, 금융 문서 검색 성능을 크게 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 거대 생성 언어모델은 강력하지만, 실제 서비스에서 쓰기에는 연산 비용과 지연 시간 문제가 크며, 특히 금융 같은 특수 도메인에서는 관련 문서를 정확히 찾아주는 검색(리트리벌) 성능이 중요하다. 기존 범용 임베딩 모델은 계산 효율성은 좋지만 도메인 특화 정보 검색 성능이 떨어진다. 또한 도메인 라벨 데이터를 수작업으로 만드는 것은 비용이 매우 크다. 따라서 범용 모델과 라벨 없는 도메인 코퍼스만으로, 비용 효율적으로 도메인 특화 검색기를 만드는 방법이 필요하다.

Method: 1) 범용 검색용 임베딩 모델(교사, bi-encoder)을 시작점으로 사용한다. 2) 대규모 금융 공시 문서 코퍼스에서, 교사 및 학생 모델을 이용해 쿼리–문서 쌍을 구성하고, 어려운 양성/음성 예제를 점진적으로 채굴한다. 3) LLM이 쿼리–문서 쌍의 관련도를 판별·평가하여, 도메인 지식을 소형 검색기(학생 bi-encoder)에 증류한다. 4) 여러 반복(iteration)에 걸쳐 ‘현재 학생 모델로 코퍼스에서 더 어려운 예제를 다시 검색→이 예제를 이용해 학생을 재학습’하는 상호작용 루프를 수행한다. 5) 이렇게 학습된 학생 bi-encoder를 RAG에서 문서 검색 전용 모듈로 사용한다(생성 LLM 자체를 미세조정하지 않는다).

Result: 14가지 금융 공시 유형, 21,800개 쿼리–문서 쌍에 대해 MRR@5가 평균 27.7% 향상, mean DCG@5가 평균 44.6% 향상되었다. 또한 FinanceBench 데이터셋의 4개 문서 클래스 중 3개에서 NDCG가 개선되었음을 보여, 제안한 도메인 특화 검색 임베딩이 기존 범용 임베딩 대비 금융 도메인에서 유의미하게 우수한 성능을 낸다는 것을 입증했다.

Conclusion: 라벨이 없는 도메인 코퍼스와 범용 임베딩, LLM 판정을 활용해, 비용 효율적으로 도메인 특화 검색 임베딩을 만드는 파이프라인을 제안했다. 학생–교사 상호작용과 점진적 하드 예제 마이닝을 통해 금융 도메인에서 큰 성능 향상을 달성했으며, 인간의 대규모 주석 작업 없이도 범용 모델과 특수 도메인 간의 격차를 줄일 수 있음을 보였다.

Abstract: Despite advances in generative large language models (LLMs), practical application of specialized conversational AI agents remains constrained by computation costs, latency requirements, and the need for precise domain-specific relevance measures. While existing embedding models address the first two constraints, they underperform on information retrieval in specialized domains like finance. This paper introduces a scalable pipeline that trains specialized models from an unlabeled corpus using a general purpose retrieval embedding model as foundation. Our method yields an average of 27.7% improvement in MRR$\texttt{@}$5, 44.6% improvement in mean DCG$\texttt{@}$5 across 14 financial filing types measured over 21,800 query-document pairs, and improved NDCG on 3 of 4 document classes in FinanceBench. We adapt retrieval embeddings (bi-encoder) for RAG, not LLM generators, using LLM-judged relevance to distill domain knowledge into a compact retriever. There are prior works which pair synthetically generated queries with real passages to directly fine-tune the retrieval model. Our pipeline differs from these by introducing interaction between student and teacher models that interleaves retrieval-based mining of hard positive/negative examples from the unlabeled corpus with iterative retraining of the student model's weights using these examples. Each retrieval iteration uses the refined student model to mine the corpus for progressively harder training examples for the subsequent training iteration. The methodology provides a cost-effective solution to bridging the gap between general-purpose models and specialized domains without requiring labor-intensive human annotation.

</details>


### [3] [Segment, Embed, and Align: A Universal Recipe for Aligning Subtitles to Signing](https://arxiv.org/abs/2512.08094)
*Zifan Jiang,Youngjoon Jang,Liliane Momeni,Gül Varol,Sarah Ebling,Andrew Zisserman*

Main category: cs.CL

TL;DR: 이 논문은 다양한 언어·도메인에 공통으로 쓸 수 있는 수어 영상–자막 정렬(align) 프레임워크 SEA를 제안하며, 기존 방법보다 효율적이고 정확한 정렬 성능을 보인다.


<details>
  <summary>Details</summary>
Motivation: 수어 처리를 발전시키려면 수어 영상과 음성/문자 자막이 정확히 정렬된 병렬 데이터가 많이 필요하다. 그러나 기존 정렬 방법은 특정 언어나 데이터셋에 맞게 종단간(end-to-end)으로 학습되어 재사용성이 떨어지고, 새로운 언어·도메인에 적용하기 어렵다. 따라서 다양한 언어와 데이터셋에 공통으로 적용 가능한 보편적 정렬 접근법이 필요하다.

Method: SEA(SEGment, Embed, Align)는 두 개의 사전 학습 모델을 활용한다. (1) 비디오 프레임 시퀀스를 개별 수어 단위(사인)로 분할하는 세그멘테이션 모델, (2) 각 사인 클립을 텍스트와 공유되는 잠재 공간에 임베딩하는 멀티모달 임베딩 모델. 그런 다음, 이 임베딩 시퀀스와 자막 텍스트(및 타임스탬프)를 동적 계획법 기반의 경량 정렬 알고리즘으로 매칭한다. 이 정렬 과정은 CPU에서 한 시간 분량 영상도 1분 이내에 처리할 정도로 계산 효율적이다. 프레임워크 구조상, 작은 단어 사전부터 대규모 연속 수어 코퍼스까지 다양한 자원을 조합해 활용할 수 있게 설계되었다.

Result: 네 개의 서로 다른 수어 데이터셋에서 정렬 실험을 수행한 결과, SEA는 기존 방법들을 상회하는 state-of-the-art 정렬 정확도를 달성했다. 또한 다양한 언어와 도메인에 대해 공통 모델로 적용 가능함을 보였고, 실제 장편 영상(에피소드)에도 실용적인 시간 내에 정렬을 수행할 수 있음을 입증했다.

Conclusion: SEA는 수어 영상과 자막 사이의 정렬 문제를 범용적으로 해결할 수 있는 모듈형 프레임워크로, 정확도와 효율성 모두에서 우수한 성능을 보인다. 이를 통해 고품질 수어–텍스트 병렬 데이터를 대량으로 자동 생성할 수 있는 가능성을 제시하며, 향후 수어 인식, 수어 번역 등 수어 처리 전반의 연구를 가속하는 기반 기술로 활용될 수 있음을 시사한다.

Abstract: The goal of this work is to develop a universal approach for aligning subtitles (i.e., spoken language text with corresponding timestamps) to continuous sign language videos. Prior approaches typically rely on end-to-end training tied to a specific language or dataset, which limits their generality. In contrast, our method Segment, Embed, and Align (SEA) provides a single framework that works across multiple languages and domains. SEA leverages two pretrained models: the first to segment a video frame sequence into individual signs and the second to embed the video clip of each sign into a shared latent space with text. Alignment is subsequently performed with a lightweight dynamic programming procedure that runs efficiently on CPUs within a minute, even for hour-long episodes. SEA is flexible and can adapt to a wide range of scenarios, utilizing resources from small lexicons to large continuous corpora. Experiments on four sign language datasets demonstrate state-of-the-art alignment performance, highlighting the potential of SEA to generate high-quality parallel data for advancing sign language processing. SEA's code and models are openly available.

</details>


### [4] [Universal Adversarial Suffixes Using Calibrated Gumbel-Softmax Relaxation](https://arxiv.org/abs/2512.08123)
*Sampriti Soor,Suklav Ghosh,Arijit Sur*

Main category: cs.CL

TL;DR: 이 논문은 여러 언어모델과 다양한 과제에서 동시에 잘 통하는 ‘보편적 적대적 접미사(문장 끝 짧은 토큰열)’를 학습해, 제로/퓨샷 분류 성능과 신뢰도를 크게 떨어뜨릴 수 있음을 보인다.


<details>
  <summary>Details</summary>
Motivation: 기존 적대적 프롬프트 연구는 특정 과제나 특정 모델에 최적화된 트리거를 찾는 데 집중해, 다른 모델·과제로의 전이성이 낮고 결과 비교도 어렵다. 실제 환경에서는 하나의 공격이 여러 모델과 다양한 태스크에 통할 수 있는지, 그리고 이런 공격이 모델의 출력 신뢰도(캘리브레이션)에 어떤 영향을 주는지가 중요하다. 이를 위해, 어떤 입력에 붙여도 잘 작동하는 ‘보편적’이고 짧은 공격용 접미사가 존재하는지, 또 이를 체계적으로 학습하는 방법을 규명하고자 한다.

Method: 1) 입력 뒤에 붙는 짧은 토큰열(4–10 토큰)을 적대적 접미사로 정의한다. 2) 학습 단계에서는 토큰을 이산적으로 고정하지 않고 Gumbel-Softmax 완화를 이용해 연속적인 ‘soft’ 토큰 분포로 표현하고, 이를 통해 미분 가능한 방식으로 접미사를 최적화한다. 3) 학습 목표는 라벨 단어(레이블 영역)에 대한 보정된 교차 엔트로피를 최대화해 모델이 정답 레이블의 점수를 낮추도록 만드는 것이다. 이때 정답 토큰은 마스킹해 접미사가 정답 자체를 유출하는 단순한 편법을 막는다. 4) 엔트로피 정규화로 접미사 토큰 분포가 한두 토큰에 붕괴되지 않도록 하여, 보다 일반적인(덜 특수한) 공격 패턴을 유도한다. 5) 학습이 끝난 후 soft 접미사는 가장 확률이 높은 실제 토큰들로 이산화해, 다양한 모델과 태스크에서 공격 접미사로 사용한다.

Result: - 여러 데이터셋(감성 분석, 자연어 추론, 패러프레이즈 검출, 상식 QA, 물리 추론)과 여러 소형 언어모델(Qwen2-1.5B, Phi-1.5, TinyLlama-1.1B)에 대해, 학습된 단일 접미사가 정확도를 전반적으로 크게 낮추는 것을 보였다. - 한 모델에서 학습한 접미사가 다른 모델로 상당히 잘 전이되어, 모델 간 전이 공격 능력이 확인됐다. - 공격 시 정확도뿐 아니라 보정된 신뢰도(캘리브레이션된 confidence)도 함께 감소해, 모델이 틀리면서도 자신 있어 하는 방향으로 교란될 수 있음을 보여준다. - 접미사 길이를 4–10 토큰으로 제한해도 공격 성능이 유지되어, 매우 짧은 프롬프트 조작만으로도 강력한 효과가 있음을 실험으로 입증했다.

Conclusion: 언어모델 분류 세팅에서, 입력 끝에 붙이는 짧은 보편적 적대적 접미사만으로도 다양한 태스크와 모델 전반에 걸쳐 정확도와 신뢰도를 동시에 떨어뜨리는 강력한 공격이 가능함을 보였다. Gumbel-Softmax 기반의 soft 접미사 학습과 캘리브레이션·엔트로피 정규화 전략은 이런 전이 가능한 공격 패턴을 효율적으로 찾는 데 유용하다. 이는 프롬프트 기반 활용 환경에서 LMs가 구조적으로 취약함을 시사하며, 향후 방어 기법 설계(예: 보편적 접미사에 대한 강건 학습, 입력 후처리와 검열 등)의 필요성을 강조한다.

Abstract: Language models (LMs) are often used as zero-shot or few-shot classifiers by scoring label words, but they remain fragile to adversarial prompts. Prior work typically optimizes task- or model-specific triggers, making results difficult to compare and limiting transferability. We study universal adversarial suffixes: short token sequences (4-10 tokens) that, when appended to any input, broadly reduce accuracy across tasks and models. Our approach learns the suffix in a differentiable "soft" form using Gumbel-Softmax relaxation and then discretizes it for inference. Training maximizes calibrated cross-entropy on the label region while masking gold tokens to prevent trivial leakage, with entropy regularization to avoid collapse. A single suffix trained on one model transfers effectively to others, consistently lowering both accuracy and calibrated confidence. Experiments on sentiment analysis, natural language inference, paraphrase detection, commonsense QA, and physical reasoning with Qwen2-1.5B, Phi-1.5, and TinyLlama-1.1B demonstrate consistent attack effectiveness and transfer across tasks and model families.

</details>


### [5] [Universal Adversarial Suffixes for Language Models Using Reinforcement Learning with Calibrated Reward](https://arxiv.org/abs/2512.08131)
*Sampriti Soor,Suklav Ghosh,Arijit Sur*

Main category: cs.CL

TL;DR: 이 논문은 강화학습을 이용해 다양한 언어모델과 과제에 잘 전이되는 짧은 적대적 접미어(suffix)를 자동으로 찾는 방법을 제안하며, 기존 기법보다 더 넓은 범위에서 성능을 무너뜨리는 것을 보인다.


<details>
  <summary>Details</summary>
Motivation: 기존의 적대적 접미어(트리거) 생성 방법은 주로 기울기(gradient) 기반 탐색이나 규칙 기반 탐색을 사용했는데, 특정 모델·특정 태스크에 과도하게 맞춰져 있어 다른 모델이나 다른 태스크로 전이될 때 성능이 떨어지고, 구현 또한 취약하고 깨지기 쉬운 한계가 있었다. 더 일반적이고 견고하며, 여러 데이터셋·모델에 공통적으로 통하는 적대적 접미어를 자동으로 학습하는 방법이 필요했다.

Method: 접미어를 강화학습의 정책(policy)으로 간주하고, 대상 언어모델은 파라미터를 고정한 채 ‘보상 오라클’로만 사용한다. Proximal Policy Optimization(PPO) 알고리즘을 이용해 접미어 정책을 학습하며, 보상은 모델의 예측을 얼마나 잘 오염시키는지를 나타내도록 설계한다. 특히 보상으로 사용하는 교차엔트로피를 ‘calibrated cross-entropy’ 형태로 보정해 라벨 편향(label bias)을 제거하고, 하나의 의미에 대해 여러 표면 형태(surface form)를 모아서 보상을 계산함으로써, 특정 표현에 과적합되지 않고 다양한 프롬프트·과제에 전이되기 쉬운 접미어를 얻도록 한다.

Result: 제안한 RL 기반 접미어 학습 기법을 감성 분석, 자연어 추론, 패러프레이즈 판별, 상식 추론 등 다섯 가지 벤치마크 데이터셋에서 평가하고, Qwen2-1.5B Instruct, TinyLlama-1.1B Chat, Phi-1.5 세 가지 언어모델에 적용했다. 그 결과, RL로 학습한 접미어는 기존의 유사 장르(짧은 트리거, 프롬프트 공격 등) 기법들보다 지속적으로 더 큰 정확도 저하를 유발하고, 학습에 사용하지 않은 다른 태스크나 다른 모델로도 더 잘 전이되는 것으로 나타났다.

Conclusion: 강화학습, 특히 PPO를 이용해 언어모델의 적대적 접미어를 ‘정책’으로 학습하면, 특정 환경에 과적합되지 않으면서도 여러 태스크·모델에서 공통적으로 성능을 저하시키는 강력하고 전이 가능한 공격 수단을 만들 수 있음을 보였다. 보상 설계에서 교차엔트로피 보정과 표면 형태 통합이 전이성을 높이는 핵심 요소로 작용한다. 이 결과는 언어모델 방어·안전성 연구에서, 단일 태스크에 한정되지 않는 보다 현실적인 위협 모델을 제공하며, 향후 방어 기법 설계 시 이런 전이 가능한 적대적 접미어를 고려해야 함을 시사한다.

Abstract: Language models are vulnerable to short adversarial suffixes that can reliably alter predictions. Previous works usually find such suffixes with gradient search or rule-based methods, but these are brittle and often tied to a single task or model. In this paper, a reinforcement learning framework is used where the suffix is treated as a policy and trained with Proximal Policy Optimization against a frozen model as a reward oracle. Rewards are shaped using calibrated cross-entropy, removing label bias and aggregating across surface forms to improve transferability. The proposed method is evaluated on five diverse NLP benchmark datasets, covering sentiment, natural language inference, paraphrase, and commonsense reasoning, using three distinct language models: Qwen2-1.5B Instruct, TinyLlama-1.1B Chat, and Phi-1.5. Results show that RL-trained suffixes consistently degrade accuracy and transfer more effectively across tasks and models than previous adversarial triggers of similar genres.

</details>


### [6] [ClinicalTrialsHub: Bridging Registries and Literature for Comprehensive Clinical Trial Access](https://arxiv.org/abs/2512.08193)
*Jiwoo Park,Ruoqi Liu,Avani Jagdale,Andrew Srisuwananukorn,Jing Zhao,Lang Li,Ping Zhang,Sachin Kumar*

Main category: cs.CL

TL;DR: ClinicalTrialsHub은 ClinicalTrials.gov와 PubMed 논문을 통합·구조화해 임상시험 정보 접근성을 대폭 향상시키는 LLM 기반 검색·질의응답 플랫폼이다.


<details>
  <summary>Details</summary>
Motivation: ClinicalTrials.gov만으로는 많은 임상시험 관련 정보(세부 디자인, 결과, 해석 등)가 구조화되어 있지 않거나 누락되어 있어, 환자·의료진·연구자·정책입안자가 근거 기반 의사결정을 내리기 어려움. PubMed 논문에는 풍부한 정보가 있지만 산재해 있고 비구조화되어 있어 효율적인 검색·활용이 힘들기 때문에, 두 소스를 통합하고 자동으로 구조화하는 시스템이 필요하다.

Method: ClinicalTrials.gov 전체 데이터를 수집·정규화하고, PubMed의 관련 연구 논문 전체 텍스트를 자동 파싱한 뒤, GPT-5.1, Gemini-3-Pro 등 대규모 언어모델을 활용해 임상시험 관련 핵심 속성(설계, 군, 지표, 결과 등)을 추출·구조화한다. 사용자 자연어 질의를 구조화된 DB 질의로 변환하는 모듈과, 출처 문장에 근거한 근거-귀속(question answering with attribution) 질의응답 모듈을 구현한다. 임상의·연구자·대학원생을 대상으로 한 사용자 연구와, 정보추출·QA 성능에 대한 체계적 자동 평가를 수행해 유용성을 검증한다.

Result: ClinicalTrialsHub는 ClinicalTrials.gov만 사용할 때에 비해 구조화된 임상시험 데이터의 접근성을 83.8% 증가시켰다. 자동 정보추출과 질의응답에서 유의미한 정확도와 실용성을 보였으며, 사용자 연구에서 임상의 및 연구자들이 시스템이 임상시험 탐색과 이해를 돕는다고 평가했다.

Conclusion: ClinicalTrialsHub는 공공 임상시험 등록정보와 문헌 기반 근거를 통합·구조화해, 임상시험 데이터에 대한 접근성과 활용도를 크게 높이는 플랫폼임을 보였다. LLM 기반 자동 정보추출과 근거-귀속 QA는 환자, 의료진, 연구자, 정책입안자 모두에게 근거 기반 의사결정을 지원할 잠재력이 있으며, 향후 더 많은 데이터 소스·언어·분야로 확장 가능하다.

Abstract: We present ClinicalTrialsHub, an interactive search-focused platform that consolidates all data from ClinicalTrials.gov and augments it by automatically extracting and structuring trial-relevant information from PubMed research articles. Our system effectively increases access to structured clinical trial data by 83.8% compared to relying on ClinicalTrials.gov alone, with potential to make access easier for patients, clinicians, researchers, and policymakers, advancing evidence-based medicine. ClinicalTrialsHub uses large language models such as GPT-5.1 and Gemini-3-Pro to enhance accessibility. The platform automatically parses full-text research articles to extract structured trial information, translates user queries into structured database searches, and provides an attributed question-answering system that generates evidence-grounded answers linked to specific source sentences. We demonstrate its utility through a user study involving clinicians, clinical researchers, and PhD students of pharmaceutical sciences and nursing, and a systematic automatic evaluation of its information extraction and question answering capabilities.

</details>


### [7] [Are generative AI text annotations systematically biased?](https://arxiv.org/abs/2512.08404)
*Sjoerd B. Stolwijk,Mark Boukes,Damian Trilling*

Main category: cs.CL

TL;DR: 이 논문은 여러 GLLM이 수동 주석과 비교해 어떤 편향과 차이를 보이는지, 특히 정치 관련 개념들을 중심으로 정량적으로 평가한다.


<details>
  <summary>Details</summary>
Motivation: 언어모델로 자동 콘텐츠 주석을 하는 연구가 늘고 있지만, 수동(인간) 주석과 결과가 얼마나 다르고, 그 차이가 체계적인 편향을 만들어 downstream 분석에 어떤 영향을 주는지는 충분히 검증되지 않았다. Boukes(2024)의 수동 주석 연구를 개념적으로 복제해, 실제 사회과학 연구에서 자주 쓰이는 정치 관련 개념들에 대해 GLLM 기반 자동 주석의 신뢰성과 편향을 평가하고자 한다.

Method: 여러 대형 언어모델(Llama3.1:8b, Llama3.3:70b, GPT‑4o, Qwen2.5:72b)을 사용해, 다섯 개 프롬프트 변형과 다섯 개 분석 개념(정치 콘텐츠, 상호작용성, 합리성, 무례성/비문명성, 이데올로기)을 기준으로 텍스트에 자동 주석을 부여한다. 그런 다음 Boukes(2024)의 수동 주석과 비교해 F1 점수, 개념 출현율(prevalence), 모델 간·인간 간 중복도(overlap) 등을 분석하고, 이 주석들을 사용했을 때의 downstream 분석 결과 차이를 비교한다.

Result: GLLM들은 F1 점수 측면에서는 ‘충분히 괜찮은’ 성능을 보이나, 수동 주석과 비교했을 때 개념의 출현율이 상당히 다르고, 이로 인해 후속 분석 결과가 실질적으로 다른 결론을 낳는다. 또한 각 GLLM은 서로 간에는 높은 일치를 보이지만 인간 주석과는 체계적으로 어긋나는 경향을 보여, 공통된 체계적 편향이 존재함을 시사한다. F1 점수 차이만으로는 이런 편향의 크기와 중요성을 설명하지 못한다.

Conclusion: 표준적인 분류 지표(F1 등)로 보면 GLLM 기반 자동 주석이 충분히 좋아 보일 수 있지만, 실제 연구 활용 관점에서는 수동 주석과의 출현율·해석 차이, 그리고 모델들 사이의 공통 편향 때문에 상당한 왜곡이 발생할 수 있다. 따라서 GLLM을 인간 주석의 완전한 대체재로 사용하기 전에, 일치도뿐 아니라 prevalence, 모델 간·인간 간 중복 구조, 그리고 downstream 결과의 민감도 등을 종합적으로 검증해야 한다는 점을 강조한다.

Abstract: This paper investigates bias in GLLM annotations by conceptually replicating manual annotations of Boukes (2024). Using various GLLMs (Llama3.1:8b, Llama3.3:70b, GPT4o, Qwen2.5:72b) in combination with five different prompts for five concepts (political content, interactivity, rationality, incivility, and ideology). We find GLLMs perform adequate in terms of F1 scores, but differ from manual annotations in terms of prevalence, yield substantively different downstream results, and display systematic bias in that they overlap more with each other than with manual annotations. Differences in F1 scores fail to account for the degree of bias.

</details>


### [8] [What Triggers my Model? Contrastive Explanations Inform Gender Choices by Translation Models](https://arxiv.org/abs/2512.08440)
*Janiça Hackenbuchner,Arda Tezcan,Joke Daems*

Main category: cs.CL

TL;DR: 이 논문은 기계번역 모델이 성별을 어떻게 선택하는지 해석가능성 기법(대조 설명, saliency attribution)을 이용해 분석하고, 인간의 성별 인식과 얼마나 겹치는지 보여준다.


<details>
  <summary>Details</summary>
Motivation: 기계번역 및 LLM에서 성별 편향은 잘 알려진 문제지만, 기존 연구는 편향의 ‘정도’를 측정하는 데 집중했고, 편향이 어디에서 기인하는지(어떤 입력 맥락이 성별 결정을 유도하는지)를 충분히 분석하지 못했다. 이 논문은 해석가능성 기법을 통해 모델이 특정 성별 굴절을 선택할 때 어떤 소스 토큰이 영향을 미치는지 파악함으로써, 편향의 기원을 이해하고자 한다.

Method: 성별이 모호한 자연 언어 소스 데이터를 사용해, 번역 모델이 타깃 언어에서 어떤 성별 굴절을 선택하는지 관찰한다. 각 번역에 대해 대조 설명(contrastive explanation)과 saliency attribution을 계산해, 성별 결정에 기여한 소스 단어의 중요도를 산출한다. 특히 일관된 스코어링 임계값이 없는 문제를 다루기 위해, 서로 다른 수준의 attribution 강도에서 소스 단어가 성별 결정에 미치는 영향을 체계적으로 비교·분석한다. 그런 다음, 모델이 강조한(salient) 소스 단어와 인간이 성별을 추론할 때 중요하다고 여기는 단어를 비교하고, 추가적으로 언어학적 분석을 수행한다.

Result: 모델의 saliency attribution으로 얻은 핵심 소스 단어와 인간 참여자들이 성별 판단에 중요하다고 인식한 단어 사이에 상당한 수준의 겹침이 있음을 보였다. 이는 번역 모델이 성별을 추론할 때 인간과 유사한 단서(맥락 단어)를 활용한다는 것을 시사한다. 또한 salient 단어들에 대한 언어학적 분석을 통해, 어떤 유형의 단어(예: 직업, 역할, 특정 맥락 단서 등)가 성별 결정을 특히 강하게 유도하는지 정성적으로 제시했다.

Conclusion: 번역 모델의 성별 관련 번역 결정을 해석가능성 기법으로 분석하면, 모델이 어떤 맥락 단어를 근거로 성별 굴절을 선택하는지 이해할 수 있고, 이는 인간의 성별 인식과 일정 부분 일치한다. 이런 정보는 단순히 성별 편향을 측정하는 데 그치지 않고, 어떤 입력 맥락이 편향을 유발하는지 식별·제거하거나 보정하는 데 활용될 수 있다. 따라서 성별 편향 완화를 위해 모델 내부 의사결정 과정을 정교하게 분석하는 접근이 중요함을 제안한다.

Abstract: Interpretability can be implemented as a means to understand decisions taken by (black box) models, such as machine translation (MT) or large language models (LLMs). Yet, research in this area has been limited in relation to a manifested problem in these models: gender bias. With this research, we aim to move away from simply measuring bias to exploring its origins. Working with gender-ambiguous natural source data, this study examines which context, in the form of input tokens in the source sentence, influences (or triggers) the translation model choice of a certain gender inflection in the target language. To analyse this, we use contrastive explanations and compute saliency attribution. We first address the challenge of a lacking scoring threshold and specifically examine different attribution levels of source words on the model gender decisions in the translation. We compare salient source words with human perceptions of gender and demonstrate a noticeable overlap between human perceptions and model attribution. Additionally, we provide a linguistic analysis of salient words. Our work showcases the relevance of understanding model translation decisions in terms of gender, how this compares to human decisions and that this information should be leveraged to mitigate gender bias.

</details>


### [9] [Soft Inductive Bias Approach via Explicit Reasoning Perspectives in Inappropriate Utterance Detection Using Large Language Models](https://arxiv.org/abs/2512.08480)
*Ju-Young Kim,Ji-Hong Park,Se-Yeon Lee,Sujin Park,Gun-Woo Kim*

Main category: cs.CL

TL;DR: 이 논문은 한국어 대규모 언어모델에 ‘추론 관점’을 명시적으로 부여하는 소프트 귀납 바이어스 방법을 적용해 대화 속 부적절 발화 탐지 성능을 약 3.9% 향상시켰음을 보인다.


<details>
  <summary>Details</summary>
Motivation: 익명성이 높은 온라인 게임·커뮤니티에서의 막말과 언어폭력, 나아가 범죄로 이어질 수 있는 부적절 발화가 사회 문제로 대두되고 있다. 이를 완화하기 위해 대화 텍스트에서 부적절 발화를 자동으로 탐지하는 기술이 필요하지만, 특히 한국어 대화와 한국어 LLM, 그리고 체인 오브 쏘트(Chain-of-Thought) 추론을 결합한 연구는 아직 부족하다. 단순히 정답을 흉내 내는 수준이 아니라, 모델이 일관되고 합리적인 판단 과정을 거쳐 부적절성을 판별하도록 만드는 새로운 학습 방법의 필요성이 이 논문의 동기이다.

Method: 연구진은 ‘소프트 귀납 바이어스(soft inductive bias)’라는 접근법을 제안한다. 이는 모델이 발화의 적절성을 판단할 때 따라야 할 ‘추론 관점(reasoning perspectives)’을 명시적으로 정의해, 체인 오브 쏘트 방식의 추론을 그 관점 안에서 수행하도록 유도하는 것이다. 한국어 대규모 언어모델(카나나 1.5)을 대상으로, (1) 표준 지도학습, (2) 체인 오브 쏘트 기반 학습, (3) 제안된 추론 관점 유도 학습 등 여러 전략으로 파인튜닝을 수행한 뒤, 각 전략의 정량적 성능과 추론 과정의 질적 차이를 비교 평가한다.

Result: 제안한 소프트 귀납 바이어스를 적용해 파인튜닝한 Kanana-1.5 모델은 부적절 발화 탐지에서 평균 정확도 87.0046%를 달성해, 기존의 단순 지도학습 대비 약 3.89%p 향상된 성능을 보였다. 또한 질적 분석 결과, 모델이 추론 관점에 맞추어 보다 일관되고 합리적인 설명을 생성하며, 모호한 사례에서도 극단적 판단이나 엉뚱한 추론을 줄이는 경향을 보였다.

Conclusion: 명시적으로 설계된 추론 관점을 소프트 귀납 바이어스로 도입하면, 한국어 대규모 언어모델이 단순히 정답 패턴을 모방하는 수준을 넘어 보다 체계적이고 안정적인 추론을 통해 부적절 발화를 탐지할 수 있음을 보여준다. 이는 안전한 온라인 소통 환경을 구축하기 위한 한국어 LLM 기반 콘텐츠 모더레이션 기술에서, ‘어떻게 추론하게 할 것인가’를 설계하는 것이 중요하다는 점을 시사하며, 향후 다른 안전성·판단 과제에도 확장 가능성이 있음을 의미한다.

Abstract: Recent incidents in certain online games and communities, where anonymity is guaranteed, show that unchecked inappropriate remarks frequently escalate into verbal abuse and even criminal behavior, raising significant social concerns. Consequently, there is a growing need for research on techniques that can detect inappropriate utterances within conversational texts to help build a safer communication environment. Although large-scale language models trained on Korean corpora and chain-of-thought reasoning have recently gained attention, research applying these approaches to inappropriate utterance detection remains limited. In this study, we propose a soft inductive bias approach that explicitly defines reasoning perspectives to guide the inference process, thereby promoting rational decision-making and preventing errors that may arise during reasoning. We fine-tune a Korean large language model using the proposed method and conduct both quantitative performance comparisons and qualitative evaluations across different training strategies. Experimental results show that the Kanana-1.5 model achieves an average accuracy of 87.0046, improving by approximately 3.89 percent over standard supervised learning. These findings indicate that the proposed method goes beyond simple knowledge imitation by large language models and enables more precise and consistent judgments through constrained reasoning perspectives, demonstrating its effectiveness for inappropriate utterance detection.

</details>


### [10] [Curriculum Guided Massive Multi Agent System Solving For Robust Long Horizon Tasks](https://arxiv.org/abs/2512.08545)
*Indrajit Kar,Kalathur Chenchu Kishore Kumar*

Main category: cs.CL

TL;DR: 이 논문은 64×64 격자 형태의 다수의 경량 에이전트와 선택적 오라클 및 적응형 커리큘럼을 결합해, 장기 추론(예: 공간적 Tower of Hanoi)에서 안정성과 효율을 높이는 계층적 멀티에이전트 아키텍처를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어 모델과 멀티에이전트 시스템은 복잡한 작업을 분해하는 데 유망하지만, 긴 시점의 추론에서 성능과 비용 문제가 크다. 특히 장기 계획·조작(로보틱스, 플래닝 등)에 해당하는 문제에서는 추론 길이가 길어질수록 오류 누적과 연산비용 급증이 발생한다. 이를 해결하기 위해, 개별 거대 모델 하나에 모든 추론을 맡기지 않고, 많은 수의 경량 에이전트로 공간을 분할·협력시키면서도 신뢰도와 학습 효율을 관리할 수 있는 구조가 필요하다.

Method: 64×64 공간 격자 위에 다수의 경량 에이전트를 배치하고, 상위 수준의 계층적 구조와 선택적 오라클을 결합한 아키텍처를 제안한다. 학습은 ‘공간 커리큘럼(spatial curriculum)’으로 진행되며, 중앙의 쉬운 영역부터 시작해 점차 주변의 어려운 영역으로 확장한다. 각 에이전트의 신뢰도는 Negative Log-Likelihood(NLL)로 측정되며, 정확도와 캘리브레이션 정보를 함께 반영하는 지표로 사용된다. 커리큘럼 매니저는 톰슨 샘플링(Thompson Sampling)을 사용해, 에이전트의 수행능력과 NLL 기반 보상 신호를 바탕으로 어떤 공간 영역을 다음 학습 대상으로 삼을지 적응적으로 선택한다.

Result: 제안한 아키텍처를 공간적으로 구성된 Tower of Hanoi 벤치마크(장기 구조를 가진 조작/플래닝 과제와 유사)에서 평가한 결과, 기존 방식 대비 학습 및 추론의 안정성이 향상되고, 오라클(정답 제공자)의 호출 빈도가 줄어들었으며, 멀리 떨어진 목표까지 도달하는 장기 추론 성능이 개선되었다. 즉, 분산된 에이전트 협력이 장기 계획에서 더 강력한 추론 능력을 보여줌을 확인했다.

Conclusion: 계층적 64×64 격자 멀티에이전트 구조와 공간 커리큘럼, NLL 기반 신뢰도 측정, 톰슨 샘플링 커리큘럼 매니저의 결합은 장기 추론 과제에서 성능·안정성·비용 측면의 균형을 개선할 수 있음을 확인했다. 이는 복잡한 로봇 조작이나 계획 문제처럼 긴 시계열 구조를 가진 실제 응용에서, 단일 대형 모델 대신 다수의 경량 에이전트가 협력하는 방식이 효과적인 대안이 될 수 있음을 시사한다.

Abstract: Large Language Models and multi-agent systems have shown promise in decomposing complex tasks, yet they struggle with long-horizon reasoning tasks and escalating computation cost. This work introduces a hierarchical multi-agent architecture that distributes reasoning across a 64*64 grid of lightweight agents, supported by a selective oracle. A spatial curriculum progressively expands the operational region of the grid, ensuring that agents master easier central tasks before tackling harder peripheral ones. To improve reliability, the system integrates Negative Log-Likelihood as a measure of confidence, allowing the curriculum to prioritize regions where agents are both accurate and well calibrated. A Thompson Sampling curriculum manager adaptively chooses training zones based on competence and NLL-driven reward signals. We evaluate the approach on a spatially grounded Tower of Hanoi benchmark, which mirrors the long-horizon structure of many robotic manipulation and planning tasks. Results demonstrate improved stability, reduced oracle usage, and stronger long-range reasoning from distributed agent cooperation.

</details>


### [11] [HealthcareNLP: where are we and what is next?](https://arxiv.org/abs/2512.08617)
*Lifeng Han,Paul Rayson,Suzan Verberne,Andrew Moore,Goran Nenadic*

Main category: cs.CL

TL;DR: 이 튜토리얼은 헬스케어 분야에서의 NLP 응용을 체계적으로 정리하고, 데이터·평가·환자 3계층 구조로 HealthcareNLP의 핵심 과제·기술·미래 도전을 소개한다.


<details>
  <summary>Details</summary>
Motivation: 기존 헬스케어 NLP 리뷰들은 합성 데이터 생성, 설명 가능한 임상 NLP, RAG, LLM–지식그래프 신경‑심볼릭 통합 등 중요한 작업과 방법론을 충분히 다루지 못했다. 이를 보완하여, 환자 중심·자원 중심 관점에서 HealthcareNLP의 주요 하위 영역을 포괄적으로 정리하고 실무·연구자 모두가 이해할 수 있는 입문 자료를 제공하려는 동기가 있다.

Method: 튜토리얼 형식으로 HealthcareNLP를 세 계층(데이터/리소스, NLP 평가, 환자/사용자)으로 구조화하여 설명한다. 각 계층에서 핵심 개념(예: 어노테이션 가이드라인, 윤리·거버넌스, 합성 데이터, NER/RE/감성 분석/코딩 및 설명 가능 AI, 번역·요약·난이도 조절·공유 의사결정 지원 등)을 소개하고, RAG와 LLM-KG 통합 등 최신 방법론을 개념적으로 다룬다. 마지막에는 튜토리얼 참가자들이 직접 HealthcareNLP 응용을 사용해 보는 실습 세션을 포함한다.

Result: 논문 자체의 실험 결과는 없고, 튜토리얼 구성 및 범위를 제안한다. 그 결과, 헬스케어 응용 도메인 NLP 실무자·연구자·의료 연구자·학생이 사전 지식 없이도 HealthcareNLP의 주요 과업, 리소스, 윤리 이슈, 최신 기법을 빠르게 파악하고, 오픈 깃허브 자료를 통해 예제를 따라 해볼 수 있도록 설계되었다.

Conclusion: 본 튜토리얼은 HealthcareNLP를 환자 및 자원 중심 시각에서 데이터/리소스–NLP 과업 및 평가–환자 참여·의사소통 계층으로 조직적으로 정리하고, 기존 리뷰의 공백이었던 합성 데이터, 설명 가능한 임상 NLP, RAG, LLM‑KG 통합 등을 포함하는 입문자용 종합 가이드를 제공한다. 이를 통해 향후 HealthcareNLP 연구와 실제 의료 현장 적용 간의 간극을 줄이고, 환자 참여와 윤리·프라이버시를 고려한 응용 개발을 촉진하는 것을 목표로 한다.

Abstract: This proposed tutorial focuses on Healthcare Domain Applications of NLP, what we have achieved around HealthcareNLP, and the challenges that lie ahead for the future. Existing reviews in this domain either overlook some important tasks, such as synthetic data generation for addressing privacy concerns, or explainable clinical NLP for improved integration and implementation, or fail to mention important methodologies, including retrieval augmented generation and the neural symbolic integration of LLMs and KGs. In light of this, the goal of this tutorial is to provide an introductory overview of the most important sub-areas of a patient- and resource-oriented HealthcareNLP, with three layers of hierarchy: data/resource layer: annotation guidelines, ethical approvals, governance, synthetic data; NLP-Eval layer: NLP tasks such as NER, RE, sentiment analysis, and linking/coding with categorised methods, leading to explainable HealthAI; patients layer: Patient Public Involvement and Engagement (PPIE), health literacy, translation, simplification, and summarisation (also NLP tasks), and shared decision-making support. A hands-on session will be included in the tutorial for the audience to use HealthcareNLP applications. The target audience includes NLP practitioners in the healthcare application domain, NLP researchers who are interested in domain applications, healthcare researchers, and students from NLP fields. The type of tutorial is "Introductory to CL/NLP topics (HealthcareNLP)" and the audience does not need prior knowledge to attend this. Tutorial materials: https://github.com/4dpicture/HealthNLP

</details>


### [12] [QSTN: A Modular Framework for Robust Questionnaire Inference with Large Language Models](https://arxiv.org/abs/2512.08646)
*Maximilian Kreutner,Jens Rupprecht,Georg Ahnert,Ahmed Salem,Markus Strohmaier*

Main category: cs.CL

TL;DR: QSTN은 설문지 형태 프롬프트로 LLM 응답을 대량 생성·평가하는 오픈소스 파이썬 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: LLM을 이용해 설문조사·라벨링을 수행하는 연구가 늘어나고 있으나, 질문 제시 방식과 프롬프트 조합, 응답 생성 절차에 따라 결과가 크게 달라져 재현성과 신뢰성이 떨어진다. 이를 체계적으로 통제·평가할 수 있는 도구가 필요하다.

Method: 질문지 스타일 프롬프트를 정의하고, 다양한 질문 구조·프롬프트 변형·응답 생성 전략을 조합하여 LLM으로부터 대규모(4천만 건 이상) 설문 응답을 자동 생성·수집하는 파이프라인을 제공한다. 파이썬 프레임워크와 더불어 코딩 없이 실험을 설계·실행할 수 있는 노코드 UI를 포함한다.

Result: 4천만 개 이상의 인실리코(in-silico) 설문 응답을 기반으로, (1) 질문 구조, (2) 프롬프트 및 제시 방식, (3) 응답 생성 방법이 인간 응답과의 정렬도(alignment)에 큰 영향을 미침을 보였다. 또한 적절한 설정을 사용하면 인간 데이터와 높은 정렬도를 유지하면서도 계산 비용을 크게 절감할 수 있음을 입증했다.

Conclusion: QSTN은 LLM 기반 설문·주석 연구에서 질문 설계와 응답 생성 절차를 체계적으로 실험하고, 더 적은 비용으로 인간과 잘 정렬된 결과를 얻도록 돕는다. 이를 통해 LLM 기반 연구의 재현성과 신뢰성을 높이는 인프라 역할을 할 것으로 기대된다.

Abstract: We introduce QSTN, an open-source Python framework for systematically generating responses from questionnaire-style prompts to support in-silico surveys and annotation tasks with large language models (LLMs). QSTN enables robust evaluation of questionnaire presentation, prompt perturbations, and response generation methods. Our extensive evaluation ($>40 $ million survey responses) shows that question structure and response generation methods have a significant impact on the alignment of generated survey responses with human answers, and can be obtained for a fraction of the compute cost. In addition, we offer a no-code user interface that allows researchers to set up robust experiments with LLMs without coding knowledge. We hope that QSTN will support the reproducibility and reliability of LLM-based research in the future.

</details>


### [13] [An Agentic AI System for Multi-Framework Communication Coding](https://arxiv.org/abs/2512.08659)
*Bohao Yang,Rui Yang,Joshua M. Biro,Haoyuan Wang,Jessica L. Handley,Brianna Richardson,Sophia Bessias,Nicoleta Economou-Zavlanos,Armando D. Bedoya,Monica Agrawal,Michael M. Zavlanos,Anand Chowdhury,Raj M. Ratwani,Kai Sun,Kathryn I. Pollak,Michael J. Pencina,Chuan Hong*

Main category: cs.CL

TL;DR: MOSAIC은 LangGraph 기반 다중 에이전트 구조를 이용해 임상 대화(환자-의료진 대화)를 다양한 커뮤니케이션 코드북/프레임워크에 맞춰 자동 주석 처리하는 시스템으로, 인간 코더 수준에 근접한 높은 F1(최대 0.962)을 달성했다.


<details>
  <summary>Details</summary>
Motivation: 임상 커뮤니케이션 품질은 환자 결과에 매우 중요하지만, 대규모 환자-의료진 대화에 세밀한 주석(예: 환자 질문, 선호 표현 등)을 다는 작업은 많은 인력과 시간이 들고, 코더 간 일관성 문제와 확장성이 떨어진다. 기존 LLM 기반 접근도 대부분 단일 태스크에 맞춰져 있어 여러 코드북·프레임워크나 다양한 진료과에 동시에 적용하기 어렵고, 추론 과정이 불투명해 신뢰성과 해석 가능성도 낮다. 이를 개선하기 위해 다중 프레임워크에 유연하게 적용 가능하고, 구조화된 워크플로와 검증 절차를 갖춘 에이전트형 AI 시스템이 필요하다.

Method: LangGraph 기반의 에이전트 오케스트레이션 구조(MOSAIC)를 설계했다. 네 가지 핵심 에이전트로 구성되며, (1) Plan Agent가 입력된 과제에 맞는 커뮤니케이션 코드북을 선택하고 전체 주석 워크플로를 수립하고, (2) Update Agent가 관련 자료를 최신 상태로 유지하는 검색용 데이터베이스를 관리하며, (3) Annotation Agents가 선택된 코드북을 바탕으로 RAG(retrieval-augmented generation)와 동적 few-shot 프롬프팅을 이용해 실제 대화에 라벨을 부여하고, (4) Verification Agent가 주석 결과의 일관성과 규칙 준수를 점검해 피드백을 제공한다. 시스템은 류마티스 및 산부인과(OB/GYN) 도메인의 환자-의료진 대화 기록을 사용해 개발·튜닝 되었으며, 훈련용 26개, 테스트용 50개 전사본에 대해 인간 전문가의 골드 스탠더드 주석과 비교 평가하였다. 추가적으로 ablation 실험을 통해 구성 요소 제거 시 성능 변화를 측정하고, 기존 LLM 기반 벤치마크와도 비교하였다.

Result: 테스트 세트 전체에서 MOSAIC은 F1 점수 0.928을 기록해 골드 스탠더드 인간 주석과 매우 유사한 성능을 보였다. 특히 류마티스 도메인 전사본에서는 F1=0.962로 가장 높은 정확도를 달성했으며, 코드 카테고리 측면에서는 환자 행동(예: 질문하기, 선호 표현, 자기 주장 등)에 대한 탐지 성능이 가장 우수했다. Ablation 실험 결과, 제안한 다중 에이전트 구조와 RAG·검증 모듈을 통합했을 때가 가장 좋은 성능을 보였으며, 단순 LLM 주석이나 축소된 구성의 모델보다 일관되게 우수한 결과를 나타냈다.

Conclusion: MOSAIC은 다양한 임상 도메인과 커뮤니케이션 코드북에 걸쳐 확장 가능하고 신뢰할 수 있는 자동 임상 커뮤니케이션 주석 시스템으로 기능할 수 있음을 보여준다. LangGraph를 활용한 다중 에이전트 구조, 코드북 기반 RAG, 동적 few-shot 및 검증 에이전트의 결합을 통해 인간 수준에 가까운 정밀도와 재현율을 달성하며, 기존 단일 태스크 LLM 접근법을 능가한다. 이 시스템은 대규모 임상 대화 데이터셋 분석을 자동화하여 커뮤니케이션 연구, 의료 질 관리, 교육 등에서 인력·시간 소모를 크게 줄이고, 다양한 프레임워크에 유연하게 적용될 수 있는 기반을 제공한다.

Abstract: Clinical communication is central to patient outcomes, yet large-scale human annotation of patient-provider conversation remains labor-intensive, inconsistent, and difficult to scale. Existing approaches based on large language models typically rely on single-task models that lack adaptability, interpretability, and reliability, especially when applied across various communication frameworks and clinical domains. In this study, we developed a Multi-framework Structured Agentic AI system for Clinical Communication (MOSAIC), built on a LangGraph-based architecture that orchestrates four core agents, including a Plan Agent for codebook selection and workflow planning, an Update Agent for maintaining up-to-date retrieval databases, a set of Annotation Agents that applies codebook-guided retrieval-augmented generation (RAG) with dynamic few-shot prompting, and a Verification Agent that provides consistency checks and feedback. To evaluate performance, we compared MOSAIC outputs against gold-standard annotations created by trained human coders. We developed and evaluated MOSAIC using 26 gold standard annotated transcripts for training and 50 transcripts for testing, spanning rheumatology and OB/GYN domains. On the test set, MOSAIC achieved an overall F1 score of 0.928. Performance was highest in the Rheumatology subset (F1 = 0.962) and strongest for Patient Behavior (e.g., patients asking questions, expressing preferences, or showing assertiveness). Ablations revealed that MOSAIC outperforms baseline benchmarking.

</details>


### [14] [Automatic Essay Scoring and Feedback Generation in Basque Language Learning](https://arxiv.org/abs/2512.08713)
*Ekhi Azurmendi,Xabier Arregi,Oier Lopez de Lacalle*

Main category: cs.CL

TL;DR: 이 논문은 바스크어 C1 수준 학습자를 위한 자동 에세이 채점(AES)·피드백 생성용 공개 데이터셋과, 이를 활용해 개방형 모델을 미세조정하여 상용 모델보다 나은 성능을 달성한 연구다.


<details>
  <summary>Details</summary>
Motivation: 바스크어와 같은 저자원 언어에는 신뢰할 수 있는 자동 에세이 채점 및 피드백 시스템, 특히 공개 데이터셋과 재현 가능한 벤치마크가 부족하다. CEFR C1처럼 고급 숙련도 수준에서는 정교한 기준(정확성, 어휘·구문 다양성, 응집·일관성, 과제 충실도 등)에 맞춘 세밀한 평가와 피드백이 필요하지만, 상용 폐쇄형 시스템에 의존하면 투명성과 교육적 제어가 떨어진다. 따라서 바스크어 고급 학습자를 대상으로 한 공개 데이터와, 이를 활용한 개방형 모델 기반 AES·피드백 프레임워크를 구축할 필요가 있다.

Method: HABE로부터 CEFR C1 수준 바스크어 에세이 3,200편을 수집하고, 전문가 평가자가 정확성, 풍부함, 응집성, 결속성, 과제 부합도 등 세부 기준별 점수와 구체적 피드백·오류 예시를 함께 주석으로 달았다. 이 데이터를 이용해 RoBERTa-EusCrawl 같은 인코더 기반 모델과 Latxa 8B/70B 같은 대형 언어모델을 각각 채점과 설명(피드백) 생성을 위해 미세조정하였다. 이후 이들 개방형 모델과 GPT-5, Claude Sonnet 4.5 같은 폐쇄형 SoTA 모델을 채점 일관성과 피드백 품질 측면에서 비교하였다. 또한 자동 일관성 지표와 전문가가 추출한 학습자 오류 검증을 결합한 새로운 피드백 평가 방법론을 제안하고 적용하였다.

Result: 인코더 기반 모델은 여전히 자동 에세이 채점에서 높은 신뢰성과 성능을 보였다. Latxa LLM에 대해 지도학습 기반 미세조정을 수행한 결과, 채점 일관성과 피드백 품질에서 GPT-5, Claude Sonnet 4.5 등 폐쇄형 최첨단 시스템을 능가했다. 제안한 평가 프레임워크를 통해, 미세조정된 Latxa가 채점 기준에 정렬된 교육적으로 의미 있는 피드백을 생성하며, 상용 모델보다 더 다양한 오류 유형을 탐지·설명한다는 것이 확인되었다.

Conclusion: 바스크어 C1 수준 에세이에 대해 세밀한 기준별 점수와 풍부한 피드백이 포함된 최초의 공개 AES 데이터셋과 벤치마크를 제시함으로써, 저자원 언어에서 투명하고 재현 가능한 교육용 NLP 연구의 기반을 마련했다. 인코더 모델과 개방형 LLM(Latxa)의 미세조정이 상용 폐쇄형 모델보다 채점과 피드백 면에서 우수할 수 있음을 보여주고, 피드백 평가를 위한 새로운 방법론을 제안해 향후 연구와 실제 교육 현장에서의 활용 가능성을 높였다.

Abstract: This paper introduces the first publicly available dataset for Automatic Essay Scoring (AES) and feedback generation in Basque, targeting the CEFR C1 proficiency level. The dataset comprises 3,200 essays from HABE, each annotated by expert evaluators with criterion specific scores covering correctness, richness, coherence, cohesion, and task alignment enriched with detailed feedback and error examples. We fine-tune open-source models, including RoBERTa-EusCrawl and Latxa 8B/70B, for both scoring and explanation generation. Our experiments show that encoder models remain highly reliable for AES, while supervised fine-tuning (SFT) of Latxa significantly enhances performance, surpassing state-of-the-art (SoTA) closed-source systems such as GPT-5 and Claude Sonnet 4.5 in scoring consistency and feedback quality. We also propose a novel evaluation methodology for assessing feedback generation, combining automatic consistency metrics with expert-based validation of extracted learner errors. Results demonstrate that the fine-tuned Latxa model produces criterion-aligned, pedagogically meaningful feedback and identifies a wider range of error types than proprietary models. This resource and benchmark establish a foundation for transparent, reproducible, and educationally grounded NLP research in low-resource languages such as Basque.

</details>


### [15] [Fluent Alignment with Disfluent Judges: Post-training for Lower-resource Languages](https://arxiv.org/abs/2512.08777)
*David Samuel,Lilja Øvrelid,Erik Velldal,Andrey Kutuzov*

Main category: cs.CL

TL;DR: 저자들은 저자원이 언어에서 비유창한 보상모델로 정렬하더라도 언어모델의 유창성을 보존하는 사후 학습 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 선호도 최적화 연구는 주로 영어·중국어에 집중되어 있어, 저자원 언어에서는 원어민 데이터와 유창한 합성 데이터를 생성할 모델이 부족하다. 이에 따라 목표 언어에 대한 명령튜닝 데이터 없이도 유창하면서 선호도 정렬이 가능한 언어모델이 필요하다.

Method: 목표 언어(노르웨이어 보크몰)에 대해, 명령튜닝 데이터 없이 on-policy 방식의 선호도 정렬(post-training)을 수행하고, 이를 기계번역 데이터 기반 지도미세조정, 다국어 미세조정과 비교한다. 유창성은 원어민 평가를 통해 측정한다.

Result: 제안한 on-policy 학습 전략이 기계번역 데이터 SFT 및 다국어 미세조정보다 더 좋은 유창성과 선호도 정렬 성능을 보이며, 희귀한 특수 데이터에 의존하지 않는다.

Conclusion: 저자원 언어에서, 비유창한 보상 모델로 정렬하더라도 on-policy 기반 사후 학습을 사용하면 유창성을 유지하면서 선호도 정렬된 언어모델을 만들 수 있으며, 이는 기존의 번역 기반·다국어 미세조정보다 효과적이다.

Abstract: We propose a post-training method for lower-resource languages that preserves fluency of language models even when aligned by disfluent reward models. Preference-optimization is now a well-researched topic, but previous work has mostly addressed models for English and Chinese. Lower-resource languages lack both datasets written by native speakers and language models capable of generating fluent synthetic data. Thus, in this work, we focus on developing a fluent preference-aligned language model without any instruction-tuning data in the target language. Our approach uses an on-policy training method, which we compare with two common approaches: supervised finetuning on machine-translated data and multilingual finetuning. We conduct a case study on Norwegian Bokmål and evaluate fluency through native-speaker assessments. The results show that the on-policy aspect is crucial and outperforms the alternatives without relying on any hard-to-obtain data.

</details>


### [16] [A Systematic Evaluation of Preference Aggregation in Federated RLHF for Pluralistic Alignment of LLMs](https://arxiv.org/abs/2512.08786)
*Mahmoud Srewa,Tianyu Zhao,Salma Elmalaki*

Main category: cs.CL

TL;DR: 이 논문은 연합학습 환경에서 다양한 집단의 인간 선호를 공정하게 반영하도록 LLM을 정렬(alignment)하는 방법을 제안하고, 다양한 보상 집계 전략의 공정성과 정렬 품질 간의 트레이드오프를 체계적으로 평가한다.


<details>
  <summary>Details</summary>
Motivation: 기존 RLHF 및 정렬 방식은 중앙집중적 데이터 수집을 전제로 하며, 다양한 집단(문화, 조직, 사용자 그룹)의 상이한 선호를 공정하게 반영하지 못하고, 연합학습 환경에서는 원천 데이터 접근 불가로 인해 편향된 보상 모델 및 불공정한 정렬이 발생할 수 있다. 이에 따라, 서로 다른 집단이 제공하는 보상 신호를 어떻게 집계해야 공정성을 높이면서도 전체 정렬 품질을 유지할 수 있는지가 핵심 문제로 제기된다.

Method: 연합학습 설정에서 각 집단이 로컬에서 LLM의 답변 롤아웃을 평가해 보상(reward)을 생성하고, 서버는 원천 데이터를 보지 않고 이 집단 수준 보상만을 집계한다. 집계 방식으로 (1) min, max, average와 같은 표준 집계 방법을 실험적으로 비교하고, (2) 각 집단의 과거 정렬 성능에 따라 가중치를 동적으로 조정하는 새로운 적응형 보상 집계 스킴을 제안한다. 이 과정에서 PPO 기반 RLHF 파이프라인을 사용해 Q/A 태스크에서 LLM을 학습·평가한다.

Result: 질의응답(Q/A) 실험에서, 제안한 적응형 집계 방식은 기존의 단순 min/max/average 집계에 비해 다양한 집단 간 보상 및 성능 편차를 줄여 공정성을 일관되게 향상시키면서도, 전체적인 정렬 점수(답변 품질·선호 일치도)는 경쟁력 있는 수준으로 유지하는 것으로 나타났다.

Conclusion: 연합학습 환경에서 다양한 인구 집단을 대상으로 LLM 정렬을 수행할 때, 단순 보상 평균이나 극단값 기반 집계는 공정성 측면에서 한계가 있으며, 집단의 과거 정렬 성능을 반영하는 적응형 집계가 더 공정한 정렬을 제공한다. 제안된 평가 프레임워크와 적응형 전략은 실제 분산 환경에서 다원주의적이고 공정하게 정렬된 LLM을 개발하기 위한 실질적인 방법론을 제공한다.

Abstract: This paper addresses the challenge of aligning large language models (LLMs) with diverse human preferences within federated learning (FL) environments, where standard methods often fail to adequately represent diverse viewpoints. We introduce a comprehensive evaluation framework that systematically assesses the trade-off between alignment quality and fairness when using different aggregation strategies for human preferences. In our federated setting, each group locally evaluates rollouts and produces reward signals, and the server aggregates these group-level rewards without accessing any raw data. Specifically, we evaluate standard reward aggregation techniques (min, max, and average) and introduce a novel adaptive scheme that dynamically adjusts preference weights based on a group's historical alignment performance. Our experiments on question-answering (Q/A) tasks using a PPO-based RLHF pipeline demonstrate that our adaptive approach consistently achieves superior fairness while maintaining competitive alignment scores. This work offers a robust methodology for evaluating LLM behavior across diverse populations and provides a practical solution for developing truly pluralistic and fairly aligned models.

</details>


### [17] [Do Depth-Grown Models Overcome the Curse of Depth? An In-Depth Analysis](https://arxiv.org/abs/2512.08819)
*Ferdinand Kapl,Emmanouil Angelis,Tobias Höppe,Kaitlin Maile,Johannes von Oswald,Nino Scherrer,Stefan Bauer*

Main category: cs.CL

TL;DR: 이 논문은 Transformer를 학습하면서 층(깊이)을 점진적으로 늘리는 방법이 왜 추론 성능을 향상시키는지, 그리고 어떻게 ‘깊이의 저주’를 완화하는지를 기계론적으로 분석한다.


<details>
  <summary>Details</summary>
Motivation: MIDAS와 같은 점진적 깊이 증가 기법이 학습 비용 절감과 추론 성능 향상을 동시에 보여주었지만, 왜 이런 이득이 발생하는지에 대한 메커니즘 수준의 이해가 부족했다. 특히, 기존 연구에서 표준 pre-LN Transformer의 뒷부분 레이어가 출력에 거의 기여하지 않는 ‘깊이의 저주’ 현상이 보고되었기 때문에, 깊이 성장 방식이 이 문제를 어떻게 변화시키는지 분석할 필요가 있었다.

Method: 최근 보고된 ‘깊이의 저주’ 현상을 기반으로, Transformer의 각 레이어가 최종 출력 분포에 기여하는 정도를 깊이별로 분석한다. MIDAS에서 사용하는 ‘gradual middle stacking’ 방식—훈련 중간에 가운데 부분에 레이어를 점진적으로 추가하는 성장 전략—을 적용한 모델과 일반(성장시키지 않은) 모델을 비교한다. 이를 통해 (1) 깊이 활용도, (2) residual stream 구조, (3) 서로 순서를 바꾸어도 되는(permutable) 계산 블록의 형성 여부를 정량·정성적으로 평가한다. 또한 MIDAS를 약간 변형한 경량 기법을 제안하고, 여러 추론 벤치마크에서 성능 변화를 실험적으로 검증한다.

Result: 점진적 middle stacking을 사용하면, 전통적인 Transformer에서 관찰되던 ‘앞부분 레이어만 주로 기여하고 뒷부분 레이어는 거의 기여하지 않는’ 깊이의 저주가 완화되며, 전체 깊이에 걸쳐 레이어들이 보다 균일하고 효과적으로 활용되는 것이 확인되었다. residual stream의 표현 구조도 바뀌어, 서로 순서를 바꾸어도 성능 저하가 적은 모듈식(permutable) 계산 블록들이 형성됨을 관찰했다. 제안한 MIDAS 경량 변형은 추가적인 큰 비용 없이도 다양한 다운스트림 추론 벤치마크에서 기존 MIDAS보다 더 좋은 성능을 보였다.

Conclusion: 훈련 중 모델 깊이를 점진적으로 증가시키는 것은 단순한 비용 절감 기법이 아니라, Transformer 내부에 서로 구분되는 계산 회로와 모듈식 블록을 형성하게 하여, 기존 non-grown 모델에서 나타나는 깊이 활용 부족 문제를 완화한다. 특히 gradual middle stacking은 residual stream 구조를 재편해, 후반부 레이어까지 의미 있게 사용되도록 만들며, 가벼운 설계 수정만으로도 추론 성능을 추가로 끌어올릴 수 있음을 보여준다.

Abstract: Gradually growing the depth of Transformers during training can not only reduce training cost but also lead to improved reasoning performance, as shown by MIDAS (Saunshi et al., 2024). Thus far, however, a mechanistic understanding of these gains has been missing. In this work, we establish a connection to recent work showing that layers in the second half of non-grown, pre-layernorm Transformers contribute much less to the final output distribution than those in the first half - also known as the Curse of Depth (Sun et al., 2025, Csordás et al., 2025). Using depth-wise analyses, we demonstrate that growth via gradual middle stacking yields more effective utilization of model depth, alters the residual stream structure, and facilitates the formation of permutable computational blocks. In addition, we propose a lightweight modification of MIDAS that yields further improvements in downstream reasoning benchmarks. Overall, this work highlights how the gradual growth of model depth can lead to the formation of distinct computational circuits and overcome the limited depth utilization seen in standard non-grown models.

</details>


### [18] [Toward Faithful Retrieval-Augmented Generation with Sparse Autoencoders](https://arxiv.org/abs/2512.08892)
*Guangzhi Xiong,Zhenghao He,Bohan Liu,Sanchit Sinha,Aidong Zhang*

Main category: cs.CL

TL;DR: 이 논문은 RAG 환경에서 LLM 내부 표현을 해석해 환각(비충실 응답)을 탐지하는 경량·고성능 방법 RAGLens를 제안한다.


<details>
  <summary>Details</summary>
Motivation: RAG는 검색된 근거 문서를 활용해 사실성을 높이지만, 모델이 근거와 모순되거나 과도한 추론을 하는 ‘faithfulness failure(환각)’ 문제가 여전히 심각하다. 기존 환각 탐지법은 (1) 대규모 라벨 데이터가 필요한 별도 검출기 학습이나 (2) 외부 LLM 심판 호출에 의존해 비용이 크고, (3) LLM 내부 표현을 쓰는 시도들은 정확도가 충분히 높지 않다. 최근 기계적 해석가능성 연구에서 sparse autoencoder(SAE)가 내부 표현을 disentangle하는 데 효과적인 것으로 나타나, 이를 활용해 환각 시점에 특이적으로 활성화되는 특징을 찾고, 데이터·비용 효율적인 RAG 환각 탐지기를 만들 필요가 있다.

Method: LLM의 내부 활성값에 sparse autoencoder(SAE)를 학습해 의미적으로 분리된 특징들을 추출한다. 그런 다음 정보 이론 기반(feature selection) 방법으로 RAG 환각과 강하게 연관된 SAE 특징을 선별하고, additive feature modeling을 통해 이 특징들의 기여를 합산하는 형태의 경량 분류기를 구성한다. 이 파이프라인을 통해 LLM 내부 표현만으로 RAG 응답의 충실성(근거 대비 환각 여부)을 판별하는 시스템 RAGLens를 설계한다. 또한 각 특징이 어떤 활성 패턴과 연결되는지 해석해, 탐지 결과에 대한 근거(설명)를 제공한다.

Result: RAGLens는 기존 환각 탐지 기법들(대규모 학습 기반 검출기, 외부 LLM 심판 호출 방식, 다른 내부표현 활용 방법 등)보다 더 높은 탐지 성능을 달성한다. 동시에 모델 크기와 추론 비용이 작아 경량으로 동작하며, SAE 기반 특징 해석을 통해 어떤 내부 신호가 환각과 연결되는지 인간이 이해 가능한 수준의 rationale을 제공한다. 실험을 통해 설계 선택(특징 선택 전략, SAE 구조 등)이 성능에 기여함을 보이고, 환각 관련 신호가 LLM의 어떤 계층·위치에 분포하는지에 대한 새로운 통찰도 제시한다.

Conclusion: RAGLens는 LLM의 내부 활성에 SAE를 적용해 RAG 환각과 직결된 특징을 추출·활용함으로써, 별도의 거대 모델이나 많은 라벨 없이도 RAG 응답의 비충실성을 효과적으로 탐지하는 방법을 제안한다. 이는 환각 탐지 성능과 효율성을 동시에 개선하고, 해석 가능한 근거를 제공해 사후적인 환각 완화에도 활용 가능함을 보여준다. 또한 LLM 내부에 존재하는 환각 관련 신호의 구조를 규명하며, 향후 기계적 해석가능성과 신뢰 가능한 RAG 시스템 설계 연구에 기반을 제공한다.

Abstract: Retrieval-Augmented Generation (RAG) improves the factuality of large language models (LLMs) by grounding outputs in retrieved evidence, but faithfulness failures, where generations contradict or extend beyond the provided sources, remain a critical challenge. Existing hallucination detection methods for RAG often rely either on large-scale detector training, which requires substantial annotated data, or on querying external LLM judges, which leads to high inference costs. Although some approaches attempt to leverage internal representations of LLMs for hallucination detection, their accuracy remains limited. Motivated by recent advances in mechanistic interpretability, we employ sparse autoencoders (SAEs) to disentangle internal activations, successfully identifying features that are specifically triggered during RAG hallucinations. Building on a systematic pipeline of information-based feature selection and additive feature modeling, we introduce RAGLens, a lightweight hallucination detector that accurately flags unfaithful RAG outputs using LLM internal representations. RAGLens not only achieves superior detection performance compared to existing methods, but also provides interpretable rationales for its decisions, enabling effective post-hoc mitigation of unfaithful RAG. Finally, we justify our design choices and reveal new insights into the distribution of hallucination-related signals within LLMs. The code is available at https://github.com/Teddy-XiongGZ/RAGLens.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [19] [Impact of Data-Oriented and Object-Oriented Design on Performance and Cache Utilization with Artificial Intelligence Algorithms in Multi-Threaded CPUs](https://arxiv.org/abs/2512.07841)
*Gabriel M. Arantes,Richard F. Pinto,Bruno L. Dalmazo,Eduardo N. Borges,Giancarlo Lucca,Viviane L. D. de Mattos,Fabian C. Cardoso,Rafael A. Berri*

Main category: cs.AI

TL;DR: 이 논문은 A* 알고리즘을 사례로 데이터 지향 설계(DOD)와 객체 지향 설계(OOD)를 단일/멀티 스레드 환경에서 비교해, 캐시 활용과 실행 성능 관점에서 DOD가 하드웨어 효율성 면에서 구조적으로 우수함을 보인다.


<details>
  <summary>Details</summary>
Motivation: 멀티코어 CPU 성능은 빠르게 향상되고 있지만 메인 메모리의 접근 속도는 상대적으로 느려, CPU와 메모리 간 성능 격차가 커지고 있다. 이로 인해 메모리 계층 구조와 캐시 특성을 고려한 하드웨어 친화적 소프트웨어 설계가 중요해졌고, 전통적인 OOD가 이러한 요구를 충분히 충족하는지, DOD가 실제로 어떤 이점을 주는지 정량적으로 분석할 필요가 있다.

Method: A* 탐색 알고리즘을 네 가지 방식으로 구현했다: 단일 스레드 OOD(ST-OOD), 단일 스레드 DOD(ST-DOD), 멀티 스레드 OOD(MT-OOD), 멀티 스레드 DOD(MT-DOD). 각 구현에 대해 실행 시간, 메모리 사용량, CPU 캐시 미스, 시스템 콜 횟수 등의 지표를 측정해 비교 분석했으며, 특히 멀티 스레드 환경에서의 캐시 활용 효율과 스레드 관리 오버헤드를 중점적으로 살폈다.

Result: 멀티 스레드 환경에서 DOD 구현(MT-DOD)은 MT-OOD에 비해 실행 시간이 더 짧고, 원시 시스템 콜 수와 캐시 미스 횟수가 적어 전반적인 성능이 우수했다. 일부 상황에서는 OOD가 메모리 사용량이나 비율 기반(cache miss rate) 지표에서 약간 유리한 경우도 있었지만, 데이터 집약적 연산에서는 DOD의 이점이 더 뚜렷하게 나타났다. 또한 A*처럼 작업 단위가 매우 세분화된(fine-grained) 경우, 스레드 관리 오버헤드가 커져 두 패러다임 모두에서 멀티 스레드 구현이 단일 스레드 구현보다 성능이 떨어지는 결과가 나왔다.

Conclusion: DOD는 단순한 알고리즘에서도 캐시 미스 감소, 실행 시간 단축 등 핵심 성능 지표에서 일관된 이점을 보여 구조적 우수성을 입증했다. 특히 대규모, 데이터 집약적 AI 및 병렬 컴퓨팅 작업에서는 하드웨어 효율을 극대화하기 위해 DOD가 더 적합한 설계 접근 방식임을 시사한다. 반면, 멀티 스레딩은 연산이 미세하게 쪼개진 작업에서는 스레드 관리 오버헤드로 인해 오히려 역효과를 낼 수 있어, 병렬화의 이득과 오버헤드를 면밀히 따져 설계해야 함을 보여준다.

Abstract: The growing performance gap between multi-core CPUs and main memory necessitates hardware-aware software design paradigms. This study provides a comprehensive performance analysis of Data Oriented Design (DOD) versus the traditional Object-Oriented Design (OOD), focusing on cache utilization and efficiency in multi-threaded environments. We developed and compared four distinct versions of the A* search algorithm: single-threaded OOD (ST-OOD), single-threaded DOD (ST-DOD), multi-threaded OOD (MT-OOD), and multi-threaded DOD (MT-DOD). The evaluation was based on metrics including execution time, memory usage, and CPU cache misses. In multi-threaded tests, the DOD implementation demonstrated considerable performance gains, with faster execution times and a lower number of raw system calls and cache misses. While OOD occasionally showed marginal advantages in memory usage or percentage-based cache miss rates, DOD's efficiency in data-intensive operations was more evident. Furthermore, our findings reveal that for a fine-grained task like the A* algorithm, the overhead associated with thread management led to single-threaded versions significantly outperforming their multi-threaded counterparts in both paradigms. We conclude that even when performance differences appear subtle in simple algorithms, the consistent advantages of DOD in critical metrics highlight its foundational architectural superiority, suggesting it is a more effective approach for maximizing hardware efficiency in complex, large-scale AI and parallel computing tasks.

</details>


### [20] [Can AI autonomously build, operate, and use the entire data stack?](https://arxiv.org/abs/2512.07926)
*Arvind Agarwal,Lisa Amini,Sameep Mehta,Horst Samulowitz,Kavitha Srinivas*

Main category: cs.AI

TL;DR: 이 논문은 기존의 부분적 AI 활용을 넘어, 데이터 수명주기 전체를 지능형 에이전트가 자율적으로 관리하는 ‘완전 자율 데이터 에스테이트’ 비전을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 현재 기업 데이터 관리(E-DW, 데이터 레이크, 거버넌스 등)는 규모와 복잡성이 커져 인력 중심 운영이 한계에 이르렀고, AI는 개별 작업 지원 수준에 머물러 있다. 최근 AI가 복잡한 의사결정·자동화 영역까지 빠르게 확장되면서, 데이터 스택 전체를 하나의 자율 시스템으로 재설계해야 할 필요와 기회가 생겼다는 문제의식에서 출발한다.

Method: 이 논문은 구현 논문이라기보다 비전/포지셔닝 논문에 가깝다. (1) 현대 데이터 스택 각 단계(아키텍처, 통합, 품질, 거버넌스, 운영 등)를 개념적으로 분해하고, (2) 해당 단계들을 지능형 에이전트가 어떻게 자율적으로 관리할 수 있을지 시나리오와 설계 방향을 제시하며, (3) 현 기술 수준 대비 격차와 남은 연구 과제를 체계적으로 정리한다.

Result: 구체적인 알고리즘 성능 수치 대신, 데이터 라이프사이클 전체를 아우르는 자율 에이전트 프레임워크의 개념적 구조와 역할 분담을 제안한다. 또한, 어떤 부분에서 이미 자율화가 부분적으로 가능하며, 어떤 부분(예: 복잡한 거버넌스, 장기적인 품질 관리, 안전한 자기-조정 등)은 여전히 난제인지 정리한다. 이를 통해 연구자와 산업계가 집중해야 할 핵심 도전 과제를 명확히 한다.

Conclusion: AI를 개별 도구로 쓰는 현재 관점에서 벗어나, 데이터 시스템 자체를 스스로 설계·운영·개선하는 자율 에이전트 집합으로 보아야 한다고 주장한다. 이를 위해 에이전트 협력, 신뢰·안전성 보장, 인간 및 AI 사용자 모두를 위한 인터페이스 등 해결해야 할 연구 과제를 제시하며, 커뮤니티가 이 방향으로 활발히 논의·공동 연구를 진행하길 촉구한다.

Abstract: Enterprise data management is a monumental task. It spans data architecture and systems, integration, quality, governance, and continuous improvement. While AI assistants can help specific persona, such as data engineers and stewards, to navigate and configure the data stack, they fall far short of full automation. However, as AI becomes increasingly capable of tackling tasks that have previously resisted automation due to inherent complexities, we believe there is an imminent opportunity to target fully autonomous data estates. Currently, AI is used in different parts of the data stack, but in this paper, we argue for a paradigm shift from the use of AI in independent data component operations towards a more holistic and autonomous handling of the entire data lifecycle. Towards that end, we explore how each stage of the modern data stack can be autonomously managed by intelligent agents to build self-sufficient systems that can be used not only by human end-users, but also by AI itself. We begin by describing the mounting forces and opportunities that demand this paradigm shift, examine how agents can streamline the data lifecycle, and highlight open questions and areas where additional research is needed. We hope this work will inspire lively debate, stimulate further research, motivate collaborative approaches, and facilitate a more autonomous future for data systems.

</details>


### [21] [SkipKV: Selective Skipping of KV Generation and Storage for Efficient Inference with Large Reasoning Models](https://arxiv.org/abs/2512.07993)
*Jiayi Tian,Seyedarmin Azizi,Yequan Zhao,Erfan Baghaei Potraghloo,Sean McPherson,Sharath Nittur Sridhar,Zhengyang Wang,Zheng Zhang,Massoud Pedram,Souvik Kundu*

Main category: cs.AI

TL;DR: 이 논문은 체인-오브-쏘트(CoT) 추론 중 KV 캐시 메모리를 줄이기 위해, 문장 단위로 불필요한 정보를 제거하고 중복 생성을 억제하는 새로운 방법 SkipKV를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 추론 모델(LRM)은 CoT 방식으로 긴 추론 과정을 생성하면서 KV 캐시가 시퀀스 길이에 비례해 선형 증가한다. 이는 메모리 사용량 증가와 처리량(throughput) 저하를 야기해 실사용 배포를 어렵게 만든다. 기존 KV 캐시 축소/삭제(eviction) 기법들이 CoT 환경, 특히 멀티 배치 상황에서 실제로 효과적인지, 그리고 정확도를 유지할 수 있는지에 대한 체계적인 검증이 필요하다.

Method: 1) 기존 KV 캐시 삭제 기법들을 CoT 추론 시나리오, 특히 멀티 배치 환경에서 평가하여 한계를 분석한다. 이때 토큰 단위 스코어링의 불안정성, 패딩 토큰으로 인한 실질 KV 예산 감소, 의미를 고려하지 않은 토큰 단위 삭제로 인한 재검증 반복 문제를 지적한다. 2) 이러한 한계를 해결하기 위해, 학습 절차 없이 바로 적용 가능한 KV 압축 기법 SkipKV를 제안한다. SkipKV는 (a) 문장 단위의 coarse-grained 시퀀스 제거 전략을 사용하여, 의미적 유사도가 높은 문장을 식별·삭제하는 문장 점수(sentence-scoring) 지표를 도입하고, (b) 추론 도중 hidden activation을 조정하는 steering vector를 동적으로 업데이트하여 중복적이고 장황한 생성을 억제하고 보다 간결한 응답을 유도한다. 이를 통해 선택적 KV eviction과 generation을 동시에 수행한다.

Result: 여러 추론 벤치마크에서 SkipKV는 유사한 KV 압축 예산 하에서 기존 SoTA KV eviction 방법들 대비 최대 26.7%까지 더 높은 정확도를 달성했다. 또한, 기존 SoTA 대비 생성 길이를 최대 1.6배까지 단축하면서도 처리량(throughput)을 최대 1.7배 개선하는 성능을 보였다.

Conclusion: 문장 수준의 의미 기반 KV 캐시 압축과 동적 steering을 결합한 SkipKV는, 별도의 재학습 없이도 CoT 추론에서 메모리 사용과 처리량 문제를 효과적으로 완화하면서 정확도를 유지·개선할 수 있음을 보여준다. 토큰 단위, 의미 비인식형 KV eviction의 한계를 극복하는 실용적인 방법으로, LRM의 효율적 배포에 유용한 솔루션을 제시한다.

Abstract: Large reasoning models (LRMs) often cost significant key-value (KV) cache overhead, due to their linear growth with the verbose chain-of-thought (CoT) reasoning process. This costs both memory and throughput bottleneck limiting their efficient deployment. Towards reducing KV cache size during inference, we first investigate the effectiveness of existing KV cache eviction methods for CoT reasoning. Interestingly, we find that due to unstable token-wise scoring and the reduced effective KV budget caused by padding tokens, state-of-the-art (SoTA) eviction methods fail to maintain accuracy in the multi-batch setting. Additionally, these methods often generate longer sequences than the original model, as semantic-unaware token-wise eviction leads to repeated revalidation during reasoning. To address these issues, we present \textbf{SkipKV}, a \textbf{\textit{training-free}} KV compression method for selective \textit{eviction} and \textit{generation} operating at a coarse-grained sentence-level sequence removal for efficient CoT reasoning. In specific, it introduces a \textit{sentence-scoring metric} to identify and remove highly similar sentences while maintaining semantic coherence. To suppress redundant generation, SkipKV dynamically adjusts a steering vector to update the hidden activation states during inference enforcing the LRM to generate concise response. Extensive evaluations on multiple reasoning benchmarks demonstrate the effectiveness of SkipKV in maintaining up to $\mathbf{26.7}\%$ improved accuracy compared to the alternatives, at a similar compression budget. Additionally, compared to SoTA, SkipKV yields up to $\mathbf{1.6}\times$ fewer generation length while improving throughput up to $\mathbf{1.7}\times$.

</details>


### [22] [Toward an AI Reasoning-Enabled System for Patient-Clinical Trial Matching](https://arxiv.org/abs/2512.08026)
*Caroline N. Leach,Mitchell A. Klusty,Samuel E. Armstrong,Justine C. Pickarski,Kristen L. Hankins,Emily B. Collier,Maya Shah,Aaron D. Mullen,V. K. Cody Bumgardner*

Main category: cs.AI

TL;DR: 이 논문은 AI, 특히 LLM을 활용해 임상시험 대상자 선별을 자동화·보조하는 보안성 높고 확장 가능한 환자-임상시험 매칭 시스템의 개념증명을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 현재 임상시험 참여 적격 환자를 선별하는 과정은 수작업 중심으로, 시간이 많이 들고 인력이 많이 소모되며, 놓치는 환자도 많다. 또한 EHR 데이터는 이질적이고 복잡해 자동 처리가 어렵고, 규제·보안 요구사항도 높다. 연구진은 이런 문제를 해결해 코디네이터 부담을 줄이고 더 많은 환자에게 적절한 임상시험 기회를 제공하고자 한다.

Method: 오픈소스 추론 기능을 갖춘 LLM을 활용해, 단순히 ‘적격/부적격’을 판단하는 이진 분류를 넘어서, 구조화된 적격성 평가와 사람이 검토 가능한 추론 과정을 자동으로 생성하는 의사결정 지원 시스템을 설계했다. 이 시스템은 이질적인 EHR 데이터를 통합·처리할 수 있도록 설계되었으며, 전문가가 중간 결과를 검토·수정할 수 있는 human-in-the-loop 인터페이스와 엄격한 보안·감사 기능을 포함한다. 적격성은 고정된 판정이 아니라 ‘현재 상태’로 표현되며, 부적격인 경우에도 어떤 조건이 충족되면 미래에 적격이 될 수 있는지를 제안한다.

Result: 개념증명 단계에서, 시스템은 다양한 EHR 데이터 소스를 통합해 환자-임상시험 매칭 후보를 생성하고, 각 후보에 대한 구조화된 적격성 요약과 추론 체인을 제공할 수 있음을 보였다. 이를 통해 코디네이터는 단순 승인·거부가 아니라 ‘왜 이런 추천이 나왔는지’를 이해하면서 빠르게 검토할 수 있다. 또한 모든 AI 산출물이 감사 가능한 형태로 저장되어 규제 준수 가능성을 높였다.

Conclusion: AI 및 LLM을 활용한 환자-임상시험 매칭 시스템은 현재 수작업 중심의 선별 프로세스를 크게 효율화하고, 더 많은·더 적절한 임상시험 옵션을 환자에게 제시할 잠재력이 있다. 특히 적격성을 동적인 상태로 다루고, 인간 전문가가 개입하는 구조를 통해 신뢰성과 실무 도입 가능성을 높였으며, 향후 실제 임상환경에서의 확장·검증을 위한 기반을 마련했다.

Abstract: Screening patients for clinical trial eligibility remains a manual, time-consuming, and resource-intensive process. We present a secure, scalable proof-of-concept system for Artificial Intelligence (AI)-augmented patient-trial matching that addresses key implementation challenges: integrating heterogeneous electronic health record (EHR) data, facilitating expert review, and maintaining rigorous security standards. Leveraging open-source, reasoning-enabled large language models (LLMs), the system moves beyond binary classification to generate structured eligibility assessments with interpretable reasoning chains that support human-in-the-loop review. This decision support tool represents eligibility as a dynamic state rather than a fixed determination, identifying matches when available and offering actionable recommendations that could render a patient eligible in the future. The system aims to reduce coordinator burden, intelligently broaden the set of trials considered for each patient and guarantee comprehensive auditability of all AI-generated outputs.

</details>


### [23] [Large Language Models for Education and Research: An Empirical and User Survey-based Analysis](https://arxiv.org/abs/2512.08057)
*Md Mostafizer Rahman,Ariful Islam Shiplu,Md Faizul Ibne Amin,Yutaka Watanobe,Lu Peng*

Main category: cs.AI

TL;DR: 이 논문은 ChatGPT와 DeepSeek 두 LLM을 교육·연구 환경에서 비교 평가하여 정확도, 효율성, 사용자 경험의 트레이드오프를 분석한다.


<details>
  <summary>Details</summary>
Motivation: 교육과 연구 분야에서 LLM 활용이 급증하고 있으나, 서로 다른 LLM 간 성능과 효율, 사용자 경험을 체계적으로 비교한 실증 연구가 부족하다. 특히 ChatGPT와 DeepSeek처럼 서로 다른 설계 철학(범용 언어 이해 vs. 효율·코딩 특화)을 가진 모델이 실제 교육·연구 현장에서 어떤 강·약점을 보이는지 명확히 알 필요가 있다.

Method: 1) 배경 기술 분석을 통해 두 LLM의 설계 철학과 구조, 효율성 지향 여부 등을 비교하고, 2) 텍스트 생성, 프로그래밍, 전문 문제 해결(의학·수학 등)을 대상으로 정량적 벤치마크 실험을 수행하며, 3) 학생·교원·연구자를 대상으로 설문조사를 실시해 실사용 관점의 장단점과 경험을 수집·분석한다.

Result: 정량 평가에서 ChatGPT는 일반 언어 이해와 자연스러운 텍스트 생성에서 우수했고, DeepSeek은 효율성 중심 설계 덕분에 프로그래밍·코딩 관련 과제에서 더 뛰어난 성능을 보였다. 두 모델 모두 의학 진단 관련 출력의 정확도가 높고, 복잡한 수학 문제도 효과적으로 해결할 수 있음이 확인되었다. 설문 결과에서는 두 모델 모두 교육·연구 생산성 향상에 기여하지만, 사용성·응답 스타일·신뢰도에 차이가 있다는 피드백이 도출되었다.

Conclusion: ChatGPT와 DeepSeek은 교육·연구 분야에서 상호 보완적인 강점을 지닌다. ChatGPT는 범용 언어 이해·서술·작성 작업에 적합하고, DeepSeek은 프로그래밍과 계산 중심 작업에 유리하다. 두 모델 모두 전문 영역(의학·수학 등)에서 충분히 유용하지만, 실제 적용 시에는 정확도·계산 효율·사용자 경험 간 트레이드오프를 고려해 작업 유형에 맞는 모델을 선택해야 한다는 점을 논문은 강조한다.

Abstract: Pretrained Large Language Models (LLMs) have achieved remarkable success across diverse domains, with education and research emerging as particularly impactful areas. Among current state-of-the-art LLMs, ChatGPT and DeepSeek exhibit strong capabilities in mathematics, science, medicine, literature, and programming. In this study, we present a comprehensive evaluation of these two LLMs through background technology analysis, empirical experiments, and a real-world user survey. The evaluation explores trade-offs among model accuracy, computational efficiency, and user experience in educational and research affairs. We benchmarked these LLMs performance in text generation, programming, and specialized problem-solving. Experimental results show that ChatGPT excels in general language understanding and text generation, while DeepSeek demonstrates superior performance in programming tasks due to its efficiency- focused design. Moreover, both models deliver medically accurate diagnostic outputs and effectively solve complex mathematical problems. Complementing these quantitative findings, a survey of students, educators, and researchers highlights the practical benefits and limitations of these models, offering deeper insights into their role in advancing education and research.

</details>


### [24] [Scalable Back-End for an AI-Based Diabetes Prediction Application](https://arxiv.org/abs/2512.08147)
*Henry Anand Septian Radityo,Bernardus Willson,Reynard Tanadi,Latifa Dwiyanti,Saiful Akbar*

Main category: cs.AI

TL;DR: 이 논문은 모바일 당뇨 예측 앱을 위해 수만 명 사용자를 처리할 수 있는 확장 가능한 백엔드 아키텍처를 설계·구현하고, 성능(오류율·지연시간·동시접속자)을 실험으로 검증한 사례 연구이다.


<details>
  <summary>Details</summary>
Motivation: 전 세계적으로 당뇨병 환자가 증가하면서, 조기 예측·관리가 중요해졌고 이를 위해 AI 기반 모바일 예측 앱이 등장했다. 그러나 예측 모델만으로는 충분하지 않고, 실제 다수 사용자가 동시에 사용하는 상황에서 낮은 오류율과 짧은 응답시간을 보장할 수 있는 백엔드 인프라 설계가 필수적이라는 문제의식에서 출발했다.

Method: 모바일 당뇨 예측 앱을 지원하는 서버 측 아키텍처를 설계하면서 수평 확장(horizontal scaling), 데이터베이스 샤딩, 메시지 큐(RabbitMQ)를 활용한 비동기 통신을 적용했다. 이후 다양한 기능(사용자 프로필 관리, 활동 추적, 예측 요청 등)에 대해 동시 접속자 수를 늘려가며 실패율과 평균 지연시간을 측정해, 사전에 정의한 성능 목표(실패율<5%, 평균 지연<1000ms) 충족 여부를 평가했다.

Result: 실험 결과, 전체 24개 시스템 기능 중 20개(약 83%)가 실패율 5% 미만, 평균 지연 1000ms 미만의 성능 목표를 달성했다. 특히 읽기 위주의 예측 요청, 사용자 프로필 관리, 활동 추적과 같은 핵심 기능은 목표치를 안정적으로 만족했다. 설계한 시스템은 최대 1만 명 동시 접속 상황에서도 별다른 문제 없이 동작했으며, 비동기 메시지 큐(RabbitMQ)를 이용한 예측 요청 처리 방식이 고부하 상황에서 오류율을 낮추고 데이터 손실을 방지하는 데 중요한 역할을 했다.

Conclusion: AI 예측 모델을 서비스로 제공하려면, 모델 정확도뿐 아니라 대규모 사용자 환경에서의 확장성·신뢰성을 확보한 백엔드 아키텍처가 핵심이라는 점을 보여준다. 제안 시스템은 수평 확장, DB 샤딩, 메시지 큐 기반 비동기 처리의 조합을 통해 1만 동시 사용자 수준에서도 낮은 오류율과 수용 가능한 응답시간을 달성했고, 특히 계산량이 큰 예측 기능에서 메시지 큐 사용이 효과적임을 검증했다. 이는 향후 헬스케어 예측 앱이나 유사한 AI 기반 모바일 서비스 설계에 참고 가능한 실무적 아키텍처 지침을 제공한다.

Abstract: The rising global prevalence of diabetes necessitates early detection to prevent severe complications. While AI-powered prediction applications offer a promising solution, they require a responsive and scalable back-end architecture to serve a large user base effectively. This paper details the development and evaluation of a scalable back-end system designed for a mobile diabetes prediction application. The primary objective was to maintain a failure rate below 5% and an average latency of under 1000 ms. The architecture leverages horizontal scaling, database sharding, and asynchronous communication via a message queue. Performance evaluation showed that 83% of the system's features (20 out of 24) met the specified performance targets. Key functionalities such as user profile management, activity tracking, and read-intensive prediction operations successfully achieved the desired performance. The system demonstrated the ability to handle up to 10,000 concurrent users without issues, validating its scalability. The implementation of asynchronous communication using RabbitMQ proved crucial in minimizing the error rate for computationally intensive prediction requests, ensuring system reliability by queuing requests and preventing data loss under heavy load.

</details>


### [25] [Empowerment Gain and Causal Model Construction: Children and adults are sensitive to controllability and variability in their causal interventions](https://arxiv.org/abs/2512.08230)
*Eunice Yiu,Kelsey Allen,Shiry Ginosar,Alison Gopnik*

Main category: cs.AI

TL;DR: 이 논문은 ‘임파워먼트(empowerment)’라는 강화학습 개념을 사용해, 인간의 인과 학습을 설명하고 머신에 구현할 수 있는 다리 역할을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대규모 딥러닝 모델은 인과 구조 학습에 어려움을 겪는 반면, 인지과학은 Causal Bayes Net을 통해 인간의 인과 학습을 잘 설명해 왔다. 또한 강화학습에서는 행동과 결과 사이의 상호정보량을 최대화하는 ‘임파워먼트’ 신호가 제안되어 있다. 저자들은 이 두 전통을 연결하여, 인간과 인공지능 모두에서 인과 학습을 통합적으로 설명할 필요성을 느낀다.

Method: 이론적으로는 임파워먼트를 ‘정확한 인과 세계모형을 가질수록 높아지는’ 신호로 정의하고, 인과 모델 학습과 임파워먼트 극대화가 서로를 강화하는 관계임을 논의한다. 경험적으로는 아동과 성인을 대상으로, 사람들이 임파워먼트 단서를 이용해 인과 관계를 추론하고 효과적인 인과 개입(intervention)을 설계하는지 체계적으로 시험하는 실험을 설계·수행한다.

Result: 임파워먼트가 인과 구조를 더 잘 이해할수록 커지고, 동시에 임파워먼트를 높이려는 시도가 더 정확한 인과 세계모형 학습으로 이어질 수 있음을 보인다. 실험에서는 아동과 성인이 실제로 임파워먼트와 관련된 단서를 사용하여 인과 관계를 추론하고 개입을 설계한다는 정황적·실증적 증거를 제시한다.

Conclusion: 임파워먼트는 고전적 베이지안 인과 학습과 강화학습을 연결하는 유망한 개념으로, 인간(특히 아동)의 인과 학습의 독특한 특징을 설명하고 머신 인텔리전스에 인과 학습을 구현하는 데 활용될 수 있다. 또한 계산적으로 더 다루기 쉬운 방식으로 인과 학습을 모델링하는 틀을 제공한다.

Abstract: Learning about the causal structure of the world is a fundamental problem for human cognition. Causal models and especially causal learning have proved to be difficult for large pretrained models using standard techniques of deep learning. In contrast, cognitive scientists have applied advances in our formal understanding of causation in computer science, particularly within the Causal Bayes Net formalism, to understand human causal learning. In the very different tradition of reinforcement learning, researchers have described an intrinsic reward signal called "empowerment" which maximizes mutual information between actions and their outcomes. "Empowerment" may be an important bridge between classical Bayesian causal learning and reinforcement learning and may help to characterize causal learning in humans and enable it in machines. If an agent learns an accurate causal world model, they will necessarily increase their empowerment, and increasing empowerment will lead to a more accurate causal world model. Empowerment may also explain distinctive features of childrens causal learning, as well as providing a more tractable computational account of how that learning is possible. In an empirical study, we systematically test how children and adults use cues to empowerment to infer causal relations, and design effective causal interventions.

</details>


### [26] [Beyond Traditional Diagnostics: Transforming Patient-Side Information into Predictive Insights with Knowledge Graphs and Prototypes](https://arxiv.org/abs/2512.08261)
*Yibowen Zhao,Yinan Zhang,Zhixiang Su,Lizhen Cui,Chunyan Miao*

Main category: cs.AI

TL;DR: 이 논문은 환자 측 정보(인구통계, 자가보고 증상)만으로 질병을 예측할 때, 지식 그래프·프로토타입·LLM 기반 설명을 결합한 KPI 프레임워크로 성능과 해석가능성을 동시에 개선하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 문진·자가보고 정보만으로 질병을 예측하면 조기 내원 유도, 환자 인식 제고, 의료 자원 효율화에 도움이 된다. 하지만 실제 데이터에서는 질병 분포가 불균형(롱테일)이고, 기존 모델은 ‘왜 그런 예측을 했는지’ 설명력이 부족해 편향·불신 문제를 낳는다. 따라서 신뢰할 수 있는 의학 지식을 활용하면서, 드문 질환까지 잘 예측하고, 환자가 이해할 수 있는 설명을 제공하는 모델이 필요하다.

Method: (1) 신뢰할 수 있는 의학 지식을 모아 통합 질병 지식 그래프를 구축하고,(2) 이를 이용해 임상적으로 의미 있는 ‘질병 프로토타입(전형적 패턴)’을 만든다. (3) 환자 표현과 프로토타입 간 대비(contrastive learning)를 통해, 특히 롱테일 질환의 예측 성능을 끌어올리도록 학습한다. (4) 예측 단계에서 대형 언어모델(LLM)을 활용해, 개별 환자 상태에 맞춘 의학적으로 타당한 자연어 설명을 생성함으로써 해석성을 높인다.

Result: 실제 의료 데이터셋으로 한 다수의 실험에서 KPI는 기존 최신 기법들보다 더 높은 질병 예측 정확도를 달성했다. 특히 분포가 불균형한 질환에서도 강인한 성능을 보였으며, LLM으로 생성한 설명은 임상의 평가에서 의학적으로 타당하고 환자 서술과도 잘 부합하는 것으로 나타났다.

Conclusion: 지식 그래프, 질병 프로토타입, 대비 학습, LLM 기반 설명을 결합한 KPI 프레임워크는 환자 측 정보만으로도 정확하면서 해석 가능한 질병 예측을 가능하게 한다. 이는 환자 중심 의료 제공, 조기 개입, 디지털 문진·자가 triage 시스템의 실용성을 높이는 데 기여할 수 있음을 시사한다.

Abstract: Predicting diseases solely from patient-side information, such as demographics and self-reported symptoms, has attracted significant research attention due to its potential to enhance patient awareness, facilitate early healthcare engagement, and improve healthcare system efficiency. However, existing approaches encounter critical challenges, including imbalanced disease distributions and a lack of interpretability, resulting in biased or unreliable predictions. To address these issues, we propose the Knowledge graph-enhanced, Prototype-aware, and Interpretable (KPI) framework. KPI systematically integrates structured and trusted medical knowledge into a unified disease knowledge graph, constructs clinically meaningful disease prototypes, and employs contrastive learning to enhance predictive accuracy, which is particularly important for long-tailed diseases. Additionally, KPI utilizes large language models (LLMs) to generate patient-specific, medically relevant explanations, thereby improving interpretability and reliability. Extensive experiments on real-world datasets demonstrate that KPI outperforms state-of-the-art methods in predictive accuracy and provides clinically valid explanations that closely align with patient narratives, highlighting its practical value for patient-centered healthcare delivery.

</details>


### [27] [Reasoning Models Ace the CFA Exams](https://arxiv.org/abs/2512.08270)
*Jaisal Patel,Yunzhe Chen,Kaiwen He,Keyi Wang,David Li,Kairong Xiao,Xiao-Yang Liu*

Main category: cs.AI

TL;DR: 최신 추론 특화 LLM들을 모의 CFA 시험(총 980문항, 레벨 I~III)에 적용해 성능을 측정한 결과, 다수 모델이 기존 연구와 달리 세 레벨 모두 합격 기준을 통과했다.


<details>
  <summary>Details</summary>
Motivation: 기존 연구에서는 LLM들이 CFA 시험에서 낮은 성과를 보여, 실제 금융 자격 시험 수준의 전문적 재무·투자 지식을 요구하는 과제에 LLM을 활용하는 데 한계가 있다고 여겨졌다. 그러나 최근의 ‘추론형’ 모델들은 여러 고급 시험에서 높은 성과를 보여 왔기에, 이들이 실제 금융 전문 자격 시험(CFA)에서도 기존 결과를 뒤집을 정도의 성능을 내는지 재평가할 필요가 있었다.

Method: 세 단계(Level I, II, III)로 구성된 모의 CFA 시험 세트(총 8회, 980문항)를 구축하고, 최신 추론형 LLM들(예: Gemini 3.0 Pro, Gemini 2.5 Pro, GPT-5, Grok 4, Claude Opus 4.1, DeepSeek‑V3.1)을 동일한 조건에서 시험에 응시시키며 자동 채점을 수행했다. 합격 여부는 선행 연구에서 사용된 동일한 합격/불합격 기준을 적용해 판단했다. 또한 레벨 III에서는 선택형 문항과 서술형(constructed‑response) 문항을 구분해 세부 성능을 비교했다.

Result: 대부분의 평가 대상 추론형 모델이 CFA 세 레벨에서 모두 합격선을 넘었고, 모델별 순위는 전체 성능 기준으로 Gemini 3.0 Pro, Gemini 2.5 Pro, GPT-5, Grok 4, Claude Opus 4.1, DeepSeek‑V3.1 순으로 나타났다. 세부적으로는 Gemini 3.0 Pro가 레벨 I에서 97.6%로 최고 성적을, GPT-5가 레벨 II에서 94.3%로 최고 성적을 기록했다. 레벨 III에서는 Gemini 2.5 Pro가 선택형 문항에서 86.4%, Gemini 3.0 Pro가 서술형 문항에서 92.0%로 각각 최고 점수를 달성했다.

Conclusion: 최근 추론형 LLM들은 CFA와 같은 고난도 전문 금융 자격 시험에서도 기존 LLM과 달리 매우 높은 성능을 보여, 재무·투자 분석, 시험 대비, 교육 등 실무 및 교육 분야에서의 활용 가능성이 크다는 점을 시사한다. CFA 수준의 시험 통과가 더 이상 LLM에게 어려운 벤치마크가 아님을 보여 주며, 향후에는 단순 정답률을 넘어 설명력, 실제 업무 적용성, 윤리적 사용 등 추가적인 평가 기준이 필요함을 암시한다.

Abstract: Previous research has reported that large language models (LLMs) demonstrate poor performance on the Chartered Financial Analyst (CFA) exams. However, recent reasoning models have achieved strong results on graduate-level academic and professional examinations across various disciplines. In this paper, we evaluate state-of-the-art reasoning models on a set of mock CFA exams consisting of 980 questions across three Level I exams, two Level II exams, and three Level III exams. Using the same pass/fail criteria from prior studies, we find that most models clear all three levels. The models that pass, ordered by overall performance, are Gemini 3.0 Pro, Gemini 2.5 Pro, GPT-5, Grok 4, Claude Opus 4.1, and DeepSeek-V3.1. Specifically, Gemini 3.0 Pro achieves a record score of 97.6% on Level I. Performance is also strong on Level II, led by GPT-5 at 94.3%. On Level III, Gemini 2.5 Pro attains the highest score with 86.4% on multiple-choice questions while Gemini 3.0 Pro achieves 92.0% on constructed-response questions.

</details>


### [28] [AgentEval: Generative Agents as Reliable Proxies for Human Evaluation of AI-Generated Content](https://arxiv.org/abs/2512.08273)
*Thanh Vu,Richi Nayak,Thiru Balasubramaniam*

Main category: cs.AI

TL;DR: 이 논문은 대규모 언어 모델이 생성한 콘텐츠의 품질을 인간 설문 없이 빠르고 저렴하게 평가하기 위해 ‘생성 에이전트(Generative Agents)’를 도입하고, 이를 통해 비즈니스 환경에서 자동 콘텐츠 생성·평가 프로세스를 효율화하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 비즈니스 환경에서 고품질 콘텐츠를 만드는 데 많은 시간과 비용이 들고, 특히 인간 설문·리뷰와 같은 외부 평가 방식은 운영 비용이 크다. LLM이 콘텐츠 생성에 활용되고 있지만, AI가 만든 결과물의 품질(일관성, 흥미도, 공정성 등)에 대한 신뢰 부족이 존재한다. 따라서 사람을 대체·보완하여 콘텐츠를 자동으로 평가해 줄 저비용·고효율 수단이 필요하다.

Method: LLM 위에 구축된 ‘Generative Agents’를 설계하여, 이들이 인간 평가자를 모사해 콘텐츠의 다양한 품질 기준(일관성, 흥미도, 명료성, 공정성, 관련성 등)을 점수화·평가하도록 한다. 구체적으로는 에이전트가 AI 생성 콘텐츠를 입력받아, 사전에 정의된 평가지표에 따라 평가를 수행하고, 이를 통해 자동 품질 평가 파이프라인을 구성하는 방식이다.

Result: 생성 에이전트는 인간 설문에 비해 훨씬 빠르고 비용 효율적으로 콘텐츠를 평가하면서도, 인간의 판단을 어느 정도 모사하는 평가 결과를 제공한다. 이로써 기업은 대규모 콘텐츠를 신속하게 필터링·선별하고, LLM 출력의 품질을 지속적으로 모니터링·개선할 수 있는 기반을 확보한다.

Conclusion: Generative Agents를 활용하면 LLM이 생성한 콘텐츠를 자동으로 평가·관리할 수 있어, 고비용의 인간 평가 의존도를 줄이면서도 비즈니스 요구에 맞는 고품질 콘텐츠 생산이 가능하다. 이는 향후 비즈니스 맞춤형 LLM 튜닝과 콘텐츠 운영 자동화에 중요한 역할을 할 수 있는 접근법임을 시사한다.

Abstract: Modern businesses are increasingly challenged by the time and expense required to generate and assess high-quality content. Human writers face time constraints, and extrinsic evaluations can be costly. While Large Language Models (LLMs) offer potential in content creation, concerns about the quality of AI-generated content persist. Traditional evaluation methods, like human surveys, further add operational costs, highlighting the need for efficient, automated solutions. This research introduces Generative Agents as a means to tackle these challenges. These agents can rapidly and cost-effectively evaluate AI-generated content, simulating human judgment by rating aspects such as coherence, interestingness, clarity, fairness, and relevance. By incorporating these agents, businesses can streamline content generation and ensure consistent, high-quality output while minimizing reliance on costly human evaluations. The study provides critical insights into enhancing LLMs for producing business-aligned, high-quality content, offering significant advancements in automated content generation and evaluation.

</details>


### [29] [Towards a Science of Scaling Agent Systems](https://arxiv.org/abs/2512.08296)
*Yubin Kim,Ken Gu,Chanwoo Park,Chunjong Park,Samuel Schmidgall,A. Ali Heydari,Yao Yan,Zhihan Zhang,Yuchen Zhuang,Mark Malhotra,Paul Pu Liang,Hae Won Park,Yuzhe Yang,Xuhai Xu,Yilun Du,Shwetak Patel,Tim Althoff,Daniel McDuff,Xin Liu*

Main category: cs.AI

TL;DR: 이 논문은 다양한 벤치마크와 아키텍처를 통해 에이전트형 LLM 시스템의 성능이 어떻게 규모와 구조에 따라 변하는지 정량적 ‘스케일링 법칙’을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 에이전트형 LLM 시스템이 실제 응용의 핵심 패러다임이 되었지만, 어떤 상황에서 몇 명의 에이전트와 어떤 구조(중앙집중, 분산 등)를 써야 성능·비용 면에서 최적인지에 대한 이론적 원칙이 부족하다. 현재는 경험적 튜닝에 의존하고 있어, 재현 가능하고 예측 가능한 설계 원칙이 필요하다.

Method: Finance-Agent, BrowseComp-Plus, PlanCraft, Workbench 네 가지 서로 다른 벤치마크에서, Single/Independent/Centralized/Decentralized/Hybrid 다섯 가지 에이전트 아키텍처를 세 개의 LLM 패밀리로 구현하여 총 180개 설정을 동일한 도구 및 토큰 예산 하에 비교 실험했다. 효율, 오버헤드, 오류 증폭, 중복성 등의 조정(coordination) 지표를 수집하고, 이를 사용해 성능을 예측하는 회귀 모델을 학습해 교차 검증으로 설명력을 평가했다(R^2=0.513).

Result: (1) 도구-조정 상충관계: 계산 예산이 고정일 때, 도구 사용 비중이 높은 작업은 다중 에이전트 조정 오버헤드의 영향을 크게 받아 성능이 악화된다. (2) 역량 포화: 단일 에이전트 기준 성능이 약 45%를 넘으면 조정에 따른 성능 이득이 급격히 줄거나 오히려 음(-)의 효과를 보인다(회귀 계수 β=-0.408, p<0.001). (3) 토폴로지 의존 오류 증폭: 독립형 에이전트 구조는 오류를 17.2배까지 증폭시키는 반면, 중앙집중형 구조는 이를 4.4배 수준으로 억제한다. 금융 추론처럼 병렬화 가능한 작업에서는 중앙집중 구조가 80.9%의 성능 향상을 보였고, 동적 웹 탐색에서는 분산 구조가 더 우수(+9.2% vs +0.2%)했다. 그러나 순차 추론 작업에서는 모든 다중 에이전트 변형이 단일 에이전트 대비 39~70% 성능 저하를 보였다. 제안된 모델은 미사용 설정 중 87%에서 최적 조정 전략을 정확히 예측했다.

Conclusion: 에이전트 수를 늘리거나 복잡한 조정 구조를 도입한다고 항상 성능이 좋아지는 것이 아니라, 작업의 도구 의존도, 병렬 가능성, 단일 에이전트 기준 성능 수준 등에 따라 최적의 조정 전략이 달라진다는 ‘에이전트 스케일링 법칙’을 제시한다. 이를 통해 실제 시스템 설계자는 작업 특성을 계량적으로 분석하여 중앙집중·분산·단일 에이전트 중 어떤 구조를 택할지, 그리고 몇 개의 에이전트를 쓰는 것이 좋은지 사전에 예측할 수 있는 원칙적 틀을 제공한다.

Abstract: Agents, language model (LM)-based systems that are capable of reasoning, planning, and acting are becoming the dominant paradigm for real-world AI applications. Despite this widespread adoption, the principles that determine their performance remain underexplored, leaving practitioners to rely on heuristics rather than principled design choices. We address this gap by deriving quantitative scaling principles for agent systems. We evaluate this across four diverse benchmarks: Finance-Agent, BrowseComp-Plus, PlanCraft, and Workbench. Using five canonical architectures (Single, Independent, Centralized, Decentralized, Hybrid) instantiated across three LLM families, we perform a controlled evaluation spanning 180 configurations with standardized tools and token budgets. We derive a predictive model using empirical coordination metrics, including efficiency, overhead, error amplification, and redundancy, that achieves cross-validated R^2=0.513. We identify three dominant effects: (1) a tool-coordination trade-off: under fixed computational budgets, tool-heavy tasks suffer disproportionately from multi-agent overhead. (2) a capability saturation: coordination yields diminishing or negative returns (beta=-0.408, p<0.001) once single-agent baselines exceed ~45%. (3) topology-dependent error amplification: independent agents amplify errors 17.2x through unchecked propagation, while centralized coordination contains this to 4.4x. Centralized coordination improves performance by 80.9% on parallelizable tasks like financial reasoning, while decentralized coordination excels on dynamic web navigation (+9.2% vs. +0.2%). Yet for sequential reasoning tasks, all multi-agent variants degraded performance by 39-70%. The framework predicts the optimal coordination strategy for 87% of held-out configurations, providing a predictive principle of agentic scaling based on measurable task properties.

</details>


### [30] [rSIM: Incentivizing Reasoning Capabilities of LLMs via Reinforced Strategy Injection](https://arxiv.org/abs/2512.08300)
*Sijia Chen,Baochun Li,Di Niu*

Main category: cs.AI

TL;DR: 이 논문은 작은 플래너 에이전트를 강화학습으로 LLM과 함께 학습시켜, 체계적으로 추론 전략을 삽입함으로써 어떤 LLM이든 강력한 추론 언어 모델(RLM)로 바꾸는 방법(rSIM)을 제안한다.


<details>
  <summary>Details</summary>
Motivation: LLM은 RL 기반 후속 학습을 통해 자기반성, 깊은 사고 등 ‘aha’식 전략을 체인 오브 쏘츠 안에서 스스로 사용하게 될 때 훨씬 강한 추론 능력을 보인다. 그러나 이런 전략적 추론은 대규모 비용이 드는 후속 학습에 의존하고, 특정 모델·태스크에 과도하게 맞춰져 재사용성이 낮다. 따라서, 다양한 기존 LLM에 쉽게 꽂아 쓸 수 있고, 적응적으로 추론 전략을 주입해 RLM 수준의 성능을 내게 하는 일반화 가능한 모듈이 필요하다.

Method: 리더-팔로워 구조의 멀티에이전트 강화학습(MARL)을 사용한다. 작은 플래너(리더 에이전트)는 현재 문제 상황과 LLM의 진행 중인 CoT를 관찰해, 언제 어떤 추론 전략(예: 자기반성, 더 깊은 분해, 검증 요청 등)을 쓸지 결정한다. LLM(팔로워 에이전트)은 플래너가 제안하는 전략 지침을 따르며 CoT를 생성한다. 두 에이전트는 단순 규칙 기반 보상(정답 여부, 전략 사용 패턴 등)을 통해 공동으로 학습되며, 학습이 끝난 플래너는 독립적인 플러그인처럼 다른 LLM에도 붙여 쓸 수 있게 설계된다.

Result: rSIM을 Qwen2.5-0.5B 모델에 적용한 결과, 훨씬 더 큰 모델인 Qwen2.5-14B를 유의미하게 능가하는 추론 성능을 달성했다. 또한 한 번 학습된 플래너는 다른 기존 LLM에 그대로 적용해도 추론 능력을 크게 향상시키며, 다양한 태스크를 순차적으로 학습하는 continual learning 설정에서도 점진적으로 계획 능력이 개선되고 더 넓은 문제 범위로 일반화되는 것이 관찰되었다.

Conclusion: 작고 일반화 가능한 플래너를 LLM과 함께 MARL로 학습시키는 rSIM은, 별도의 대규모 파인튜닝 없이도 다양한 LLM을 강력한 추론 언어 모델(RLM)로 변환할 수 있는 실용적 프레임워크임을 보여준다. 이 방식은 모델 크기 제약을 완화하면서도, 전략적 CoT 계획과 지속 학습을 통해 고성능 추론을 달성할 수 있는 경로를 제시한다.

Abstract: Large language models (LLMs) are post-trained through reinforcement learning (RL) to evolve into Reasoning Language Models (RLMs), where the hallmark of this advanced reasoning is ``aha'' moments when they start to perform strategies, such as self-reflection and deep thinking, within chain of thoughts (CoTs). Motivated by this, this paper proposes a novel reinforced strategy injection mechanism (rSIM), that enables any LLM to become an RLM by employing a small planner to guide the LLM's CoT through the adaptive injection of reasoning strategies. To achieve this, the planner (leader agent) is jointly trained with an LLM (follower agent) using multi-agent RL (MARL), based on a leader-follower framework and straightforward rule-based rewards. Experimental results show that rSIM enables Qwen2.5-0.5B to become an RLM and significantly outperform Qwen2.5-14B. Moreover, the planner is generalizable: it only needs to be trained once and can be applied as a plug-in to substantially improve the reasoning capabilities of existing LLMs. In addition, the planner supports continual learning across various tasks, allowing its planning abilities to gradually improve and generalize to a wider range of problems.

</details>


### [31] [Predicting California Bearing Ratio with Ensemble and Neural Network Models: A Case Study from Türkiye](https://arxiv.org/abs/2512.08340)
*Abdullah Hulusi Kökçam,Uğur Dağdeviren,Talas Fikret Kurnaz,Alparslan Serhat Demir,Caner Erden*

Main category: cs.AI

TL;DR: 이 논문은 토질의 지지력을 나타내는 CBR 값을 실험 대신 기계학습으로 예측하는 프레임워크를 제안하며, 여러 알고리즘 중 랜덤 포레스트가 가장 높은 예측 성능을 보였음을 보고한다.


<details>
  <summary>Details</summary>
Motivation: 전통적인 CBR 실내 관입시험은 정확하지만 시간과 비용이 많이 들고, 다양한 토질·대규모 현장에 적용하기 비효율적이기 때문에 더 빠르고 실용적인 예측 방법이 필요하다.

Method: 튀르키예 여러 지기후 지역에서 채취한 382개 토사 시료의 물리·화학적 특성 데이터를 이용해 감독학습 문제로 정식화하고, 의사결정나무, 랜덤 포레스트, 엑스트라 트리, 그래디언트 부스팅, XGBoost, KNN, SVR, MLP, AdaBoost, 배깅, 보팅, 스태킹 회귀 등 12개 ML 회귀 모델을 학습·검증·테스트하여 성능과 일반화 능력을 비교했다.

Result: 랜덤 포레스트 회귀모델이 가장 우수한 성능을 보여 학습 R2=0.95, 검증 R2=0.76, 테스트 R2=0.83을 달성하여 비선형 관계를 효과적으로 포착함을 입증했다.

Conclusion: 지지력 예측에서 전통 실험을 보완·대체할 수 있는 데이터 중심 ML 모델의 가능성을 확인했으며, 특히 랜덤 포레스트 기반 CBR 예측 모델은 지반공학 분야의 디지털 전환과 인프라 설계·해석의 효율화를 촉진하는 유망한 도구임을 제시한다.

Abstract: The California Bearing Ratio (CBR) is a key geotechnical indicator used to assess the load-bearing capacity of subgrade soils, especially in transportation infrastructure and foundation design. Traditional CBR determination relies on laboratory penetration tests. Despite their accuracy, these tests are often time-consuming, costly, and can be impractical, particularly for large-scale or diverse soil profiles. Recent progress in artificial intelligence, especially machine learning (ML), has enabled data-driven approaches for modeling complex soil behavior with greater speed and precision. This study introduces a comprehensive ML framework for CBR prediction using a dataset of 382 soil samples collected from various geoclimatic regions in Türkiye. The dataset includes physicochemical soil properties relevant to bearing capacity, allowing multidimensional feature representation in a supervised learning context. Twelve ML algorithms were tested, including decision tree, random forest, extra trees, gradient boosting, xgboost, k-nearest neighbors, support vector regression, multi-layer perceptron, adaboost, bagging, voting, and stacking regressors. Each model was trained, validated, and evaluated to assess its generalization and robustness. Among them, the random forest regressor performed the best, achieving strong R2 scores of 0.95 (training), 0.76 (validation), and 0.83 (test). These outcomes highlight the model's powerful nonlinear mapping ability, making it a promising tool for predictive geotechnical tasks. The study supports the integration of intelligent, data-centric models in geotechnical engineering, offering an effective alternative to traditional methods and promoting digital transformation in infrastructure analysis and design.

</details>


### [32] [Soil Compaction Parameters Prediction Based on Automated Machine Learning Approach](https://arxiv.org/abs/2512.08343)
*Caner Erden,Alparslan Serhat Demir,Abdullah Hulusi Kokcam,Talas Fikret Kurnaz,Ugur Dagdeviren*

Main category: cs.AI

TL;DR: 이 논문은 건설 공학에서 토질 다짐의 핵심 지표인 최적함수비(OMC)와 최대건조밀도(MDD)를 예측하기 위해 AutoML을 활용하고, 그중 XGBoost가 가장 높은 예측 성능을 보였다는 것을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 기존의 OMC와 MDD 결정은 실내 다짐 시험에 의존해 시간과 인력이 많이 들고, 회귀식 기반의 경험적 모델은 토질 종류가 달라지면 정확도가 떨어지며 적용 범위가 제한적이다. 최근 AI/ML 기법이 도입되었지만, 다양한 토질이 섞인 이질적인 데이터셋에서 예측 정확도와 일반화 성능이 충분치 않다는 문제가 있다. 이를 개선하기 위해 알고리즘 선택과 하이퍼파라미터 튜닝을 자동화해 더 정확하고 범용적인 예측 모델을 만들 필요가 있다.

Method: 여러 토질 유형이 포함된 이질적인 데이터셋을 구축한 뒤, AutoML 프레임워크를 사용하여 다양한 ML 알고리즘 후보와 하이퍼파라미터 조합을 자동 탐색하고 성능을 비교하였다. 그 과정에서 OMC와 MDD를 목표 변수로 설정하고, AutoML이 선택·튜닝한 여러 모델 중 성능이 가장 우수한 알고리즘을 식별하였다.

Result: AutoML 실험 결과, Extreme Gradient Boosting(XGBoost) 알고리즘이 가장 우수한 성능을 보였으며, 분리된 검증용 데이터셋에서 MDD 예측의 결정계수(R²)는 80.4%, OMC 예측의 R²는 89.1%를 달성했다. 이는 기존 수작업 모델 선택 및 단순 회귀 모델에 비해 예측력이 크게 향상된 수치로 제시된다.

Conclusion: AutoML을 활용하면 토질 특성이 다양한 데이터셋에서도 OMC와 MDD를 높은 정확도로 예측할 수 있으며, 특히 XGBoost가 매우 효과적인 알고리즘임을 확인했다. 이질적인 토질 데이터의 활용이 모델의 일반화와 성능 향상에 중요함을 강조하며, 결과적으로 실내 다짐 시험 의존도를 줄이고 토목·건설 현장에서 더 효율적이고 신뢰성 있는 다짐 설계를 지원할 수 있음을 결론으로 제시한다.

Abstract: Soil compaction is critical in construction engineering to ensure the stability of structures like road embankments and earth dams. Traditional methods for determining optimum moisture content (OMC) and maximum dry density (MDD) involve labor-intensive laboratory experiments, and empirical regression models have limited applicability and accuracy across diverse soil types. In recent years, artificial intelligence (AI) and machine learning (ML) techniques have emerged as alternatives for predicting these compaction parameters. However, ML models often struggle with prediction accuracy and generalizability, particularly with heterogeneous datasets representing various soil types. This study proposes an automated machine learning (AutoML) approach to predict OMC and MDD. AutoML automates algorithm selection and hyperparameter optimization, potentially improving accuracy and scalability. Through extensive experimentation, the study found that the Extreme Gradient Boosting (XGBoost) algorithm provided the best performance, achieving R-squared values of 80.4% for MDD and 89.1% for OMC on a separate dataset. These results demonstrate the effectiveness of AutoML in predicting compaction parameters across different soil types. The study also highlights the importance of heterogeneous datasets in improving the generalization and performance of ML models. Ultimately, this research contributes to more efficient and reliable construction practices by enhancing the prediction of soil compaction parameters.

</details>


### [33] [Enhancing Explainability of Graph Neural Networks Through Conceptual and Structural Analyses and Their Extensions](https://arxiv.org/abs/2512.08344)
*Tien Cuong Bui*

Main category: cs.AI

TL;DR: 이 논문은 GNN을 위한 새로운 그래프 기반 XAI 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존 GNN 설명 기법은 그래프 구조의 복잡한 상호작용을 충분히 해석하지 못하고, 사후적 기법은 계산 비용이 크고 신뢰성이 낮으며, 자체 해석 가능한 모델은 범용성이 떨어지는 한계가 있다.

Method: 그래프 구조와 예측 간의 관계를 직접 포착하도록 설계된 새로운 XAI 프레임워크를 정의하고, 개별 피처 수준을 넘어서 구조적 패턴과 상호작용을 설명하도록 GNN 설명 모듈을 설계한다.

Result: 제안된 프레임워크는 GNN에 대해 적응 가능하며 계산 효율적인 설명을 제공하고, 예측에 영향을 주는 중요한 그래프 구조를 포착할 수 있다.

Conclusion: 새로운 프레임워크를 통해 GNN의 의사결정 과정을 더 투명하게 만들고, 구조적 설명을 제공함으로써 기존 사후적/자체 해석 모델의 한계를 보완한다.

Abstract: Graph Neural Networks (GNNs) have become a powerful tool for modeling and analyzing data with graph structures. The wide adoption in numerous applications underscores the value of these models. However, the complexity of these methods often impedes understanding their decision-making processes. Current Explainable AI (XAI) methods struggle to untangle the intricate relationships and interactions within graphs. Several methods have tried to bridge this gap via a post-hoc approach or self-interpretable design. Most of them focus on graph structure analysis to determine essential patterns that correlate with prediction outcomes. While post-hoc explanation methods are adaptable, they require extra computational resources and may be less reliable due to limited access to the model's internal workings. Conversely, Interpretable models can provide immediate explanations, but their generalizability to different scenarios remains a major concern. To address these shortcomings, this thesis seeks to develop a novel XAI framework tailored for graph-based machine learning. The proposed framework aims to offer adaptable, computationally efficient explanations for GNNs, moving beyond individual feature analysis to capture how graph structure influences predictions.

</details>


### [34] [The High Cost of Incivility: Quantifying Interaction Inefficiency via Multi-Agent Monte Carlo Simulations](https://arxiv.org/abs/2512.08345)
*Benedikt Mangold*

Main category: cs.AI

TL;DR: LLM 기반 멀티에이전트 시스템으로 ‘유독한’ 직장 커뮤니케이션을 시뮬레이션하여, 독성 발화가 의사결정 속도를 약 25% 늦춘다는 점을 계량적으로 보여준다.


<details>
  <summary>Details</summary>
Motivation: 직장 내 독성 커뮤니케이션이 조직문화에 해롭다는 것은 알려져 있지만, 실제 운영 효율성과 재무적 손실에 어떤 정량적 영향을 미치는지 윤리적·실무적 제약 때문에 인간 대상 실험으로 측정하기 어렵다. 이를 해결하기 위해, 사람 대신 LLM 에이전트를 활용해 반복 가능하고 통제 가능한 ‘사회적 마찰’ 실험 환경을 만들고자 한다.

Method: 대형언어모델(LLM)을 기반으로 한 멀티에이전트 시스템을 구성해 1:1 대립적 토론을 시뮬레이션한다. 정상(비독성) 프롬프트를 적용한 통제 집단과, 독성을 유도하는 시스템 프롬프트를 부여한 처리 집단을 비교한다. 몬테카를로 방식으로 수백 회의 토론을 반복 실행하고, 각 토론이 결론(합의 혹은 종료 지점)에 도달할 때까지 필요한 발언 수를 ‘수렴 시간’으로 정의해 양 집단 간 차이를 통계적으로 분석한다.

Result: 독성 프롬프트를 가진 에이전트가 참여한 토론에서 수렴 시간이 약 25% 유의미하게 증가했다. 즉, 동일한 문제를 두고 논의할 때 대화 길이·지속 시간이 독성으로 인해 체계적으로 늘어나는 패턴이 관찰되었다.

Conclusion: LLM 기반 에이전트 시뮬레이션을 통해 독성 커뮤니케이션이 의사결정과 문제 해결 속도를 지연시킨다는 점을 정량적으로 입증했고, 이 ‘독성의 지연(latency of toxicity)’을 조직 내 시간·비용 손실의 대용 지표로 쓸 수 있음을 제안한다. 아울러, 이러한 에이전트 기반 모델링이 인간 대상 실험을 대체·보완하는 재현 가능하고 윤리적인 방법론임을 강조한다.

Abstract: Workplace toxicity is widely recognized as detrimental to organizational culture, yet quantifying its direct impact on operational efficiency remains methodologically challenging due to the ethical and practical difficulties of reproducing conflict in human subjects. This study leverages Large Language Model (LLM) based Multi-Agent Systems to simulate 1-on-1 adversarial debates, creating a controlled "sociological sandbox". We employ a Monte Carlo method to simulate hundrets of discussions, measuring the convergence time (defined as the number of arguments required to reach a conclusion) between a baseline control group and treatment groups involving agents with "toxic" system prompts. Our results demonstrate a statistically significant increase of approximately 25\% in the duration of conversations involving toxic participants. We propose that this "latency of toxicity" serves as a proxy for financial damage in corporate and academic settings. Furthermore, we demonstrate that agent-based modeling provides a reproducible, ethical alternative to human-subject research for measuring the mechanics of social friction.

</details>


### [35] [Reflecting with Two Voices: A Co-Adaptive Dual-Strategy Framework for LLM-Based Agent Decision Making](https://arxiv.org/abs/2512.08366)
*Wentao Zhang,Qunbo Wang,Tao Zhang,Junsheng Wu,Hongping Gan,Yang Liu,Ling Dai,Shizhuang Deng,Shuntong Sun*

Main category: cs.AI

TL;DR: DuSAR는 예시(데모) 없이도 하나의 고정 LLM으로 고수준 계획 전략과 로컬 정책 전략을 동시 운용하고, 반성(reflection) 메커니즘으로 둘을 조정해 ALFWorld와 Mind2Web에서 SOTA 성능과 토큰 비용 절감을 달성한 에이전트 프레임워크이다.


<details>
  <summary>Details</summary>
Motivation: 기존 LLM 에이전트는 외부 데모나 검색 기반 플래닝에 많이 의존해 환경이 바뀌면 쉽게 깨지거나 일반화가 약하고, 매 스텝마다 많은 토큰을 소모하는 비효율 문제가 있었다. 인간처럼 스스로 계획을 세우고, 진행 상황을 점검·수정하면서 적응적으로 문제를 해결하는 에이전트 구조가 필요했다.

Method: 하나의 고정 LLM에 두 가지 상보적 전략을 부여한다. (1) 환경 전반을 보는 고수준 거시 플랜(holistic plan)과, (2) 현재 컨텍스트에 밀착된 로컬 행동 정책(local policy)을 동시에 운용한다. 여기에 가벼운 반성(reflection) 모듈을 두어, 매 단계마다 전략 수행 정도를 정량화한 Strategy Fitness Score를 계산하고, 점수가 낮거나 정체되면 글로벌 플랜을 재구성하고, 의미 있는 진전이 있으면 플랜을 세밀하게 다듬도록 한다. 이 과정은 LLM 파라미터를 업데이트하지 않고 프롬프트·롤 플로우 설계로 구현된다.

Result: ALFWorld와 Mind2Web 두 환경에서 공개 LLM(7B~70B)만으로 최고 수준 성능을 달성했다. 특히 ALFWorld에서 Llama3.1-70B로 37.1% 성공률을 기록해 기존 최고 13.0%를 2배 이상 상회했고, Mind2Web에서도 4.02%로 기존 최강 기준을 2배 이상 상회했다. 또한 스텝당 토큰 사용량을 3~9배 줄이면서도 높은 성능을 유지했음을 보고한다. 추가로 두 전략 중 하나를 제거하거나 반성 메커니즘을 꺼두는 소거 실험에서 성능 저하가 확인되어, 듀얼 전략 조정의 중요성이 입증되었다.

Conclusion: DuSAR는 데모나 무거운 검색 없이도, 하나의 고정 LLM이 고수준 계획과 로컬 정책을 반성 메커니즘으로 조율해 복잡한 환경에서 강인하고 효율적인 행동을 할 수 있음을 보여준다. 이 구조는 토큰 비용을 크게 줄이면서도 성능을 향상시키고, 필요 시 전문가 데모와도 쉽게 통합될 수 있어 다른 에이전트 시스템·도메인으로의 확장성이 크다.

Abstract: Large language model (LLM) agents often rely on external demonstrations or retrieval-augmented planning, leading to brittleness, poor generalization, and high computational overhead. Inspired by human problem-solving, we propose DuSAR (Dual-Strategy Agent with Reflecting) - a demonstration-free framework that enables a single frozen LLM to perform co-adaptive reasoning via two complementary strategies: a high-level holistic plan and a context-grounded local policy. These strategies interact through a lightweight reflection mechanism, where the agent continuously assesses progress via a Strategy Fitness Score and dynamically revises its global plan when stuck or refines it upon meaningful advancement, mimicking human metacognitive behavior. On ALFWorld and Mind2Web, DuSAR achieves state-of-the-art performance with open-source LLMs (7B-70B), reaching 37.1% success on ALFWorld (Llama3.1-70B) - more than doubling the best prior result (13.0%) - and 4.02% on Mind2Web, also more than doubling the strongest baseline. Remarkably, it reduces per-step token consumption by 3-9X while maintaining strong performance. Ablation studies confirm the necessity of dual-strategy coordination. Moreover, optional integration of expert demonstrations further boosts results, highlighting DuSAR's flexibility and compatibility with external knowledge.

</details>


### [36] [DeepFeature: Iterative Context-aware Feature Generation for Wearable Biosignals](https://arxiv.org/abs/2512.08379)
*Kaiwei Liu,Yuting He,Bufang Yang,Mu Yuan,Chun Man Victor Wong,Ho Pong Andrew Sze,Zhenyu Yan,Hongkai Chen*

Main category: cs.AI

TL;DR: 이 논문은 웨어러블 생체신호용 특성(feature)을 LLM으로 자동 설계·코딩·검증하는 프레임워크 DeepFeature를 제안하고, 여러 작업에서 기존 방법보다 AUROC를 평균 4~10% 정도 향상시켰다고 보고한다.


<details>
  <summary>Details</summary>
Motivation: 웨어러블 기기로부터 얻는 생체신호(심전도, PPG 등)를 활용한 헬스케어 ML 모델은 주로 신호에서 추출한 특성(feature)에 의존한다. 그런데 기존의 수동 혹은 라이브러리 기반 특성 추출은 ① 과업(질병, 예측목표 등) 맥락이 잘 반영되지 않고, ② 조합 가능한 특성 공간이 고차원이라 최적 설정을 찾기 어렵고, ③ 자동 코드 생성 시 오류가 많아 실제 파이프라인에서 깨지기 쉽다는 한계가 있다. 저자들은 대형언어모델(LLM)의 코드 생성과 도메인 지식 활용 능력을 이용해, 과업 맥락을 반영하면서도 신뢰성 있게 돌아가는 특성 추출 파이프라인을 만들고자 한다.

Method: DeepFeature라는 LLM 기반 특성 생성 프레임워크를 제안한다. (1) 멀티소스 특성 생성: 과업 설명, 신호 종류, 도메인 전문가 지식 등 여러 정보를 LLM에 제공하여 후보 특성 목록과 정의를 생성하게 한다. (2) 반복적 특성 정제: 초기 후보 특성으로 모델을 학습·평가한 뒤, 성능/중요도 피드백을 LLM에 다시 제공하여 비효율적 특성을 제거하고 유망한 특성을 재설계·추가하는 루프를 돌린다. (3) 다층 필터링·검증: LLM이 생성한 특성 추출 코드를 정적 검사, 유닛 테스트, 예외 처리 등 여러 단계로 필터링·수정해, 실제 생체신호 데이터에서 크래시 없이 실행되도록 한다. 이 전체 과정을 자동화된 파이프라인으로 구축해 다양한 웨어러블 생체신호 데이터셋과 예측 과업에 적용한다.

Result: 8개의 서로 다른 웨어러블 생체신호 기반 과업에서 DeepFeature로 생성한 특성들을 사용해 학습한 모델이 기존 피처 엔지니어링/기성 라이브러리 기반 방법들보다 AUROC가 평균 4.21~9.67% 향상되었다. 최첨단(state-of-the-art) 비교 기법들 대비 5개 과업에서는 성능을 우월하게 달성했고, 나머지 3개 과업에서도 비슷한 수준의 성능을 유지했다. 또한 코드 생성 단계에서의 다층 검증 덕분에 특성 추출 함수 실행 시 크래시가 크게 줄어드는 등 실용적인 안정성도 확보했다는 점을 보고한다.

Conclusion: LLM을 단순 코드 자동완성 도구가 아니라, 과업 맥락을 이해하고 도메인 지식을 반영해 특성을 설계·선별·코딩하는 에이전트로 활용하면 웨어러블 생체신호 분석의 성능과 개발 효율을 동시에 높일 수 있음을 보였다. DeepFeature는 (1) 컨텍스트 인지형 멀티소스 특성 설계, (2) 성능 피드백을 활용한 반복적 특성 정제, (3) 다층 검증 기반 안정적인 코드 생성이라는 세 가지 축을 결합한 첫 프레임워크로 제시되며, 향후 다른 시계열·의료 데이터 도메인으로의 확장 가능성을 시사한다.

Abstract: Biosignals collected from wearable devices are widely utilized in healthcare applications. Machine learning models used in these applications often rely on features extracted from biosignals due to their effectiveness, lower data dimensionality, and wide compatibility across various model architectures. However, existing feature extraction methods often lack task-specific contextual knowledge, struggle to identify optimal feature extraction settings in high-dimensional feature space, and are prone to code generation and automation errors. In this paper, we propose DeepFeature, the first LLM-empowered, context-aware feature generation framework for wearable biosignals. DeepFeature introduces a multi-source feature generation mechanism that integrates expert knowledge with task settings. It also employs an iterative feature refinement process that uses feature assessment-based feedback for feature re-selection. Additionally, DeepFeature utilizes a robust multi-layer filtering and verification approach for robust feature-to-code translation to ensure that the extraction functions run without crashing. Experimental evaluation results show that DeepFeature achieves an average AUROC improvement of 4.21-9.67% across eight diverse tasks compared to baseline methods. It outperforms state-of-the-art approaches on five tasks while maintaining comparable performance on the remaining tasks.

</details>


### [37] [From Accuracy to Impact: The Impact-Driven AI Framework (IDAIF) for Aligning Engineering Architecture with Theory of Change](https://arxiv.org/abs/2512.08449)
*Yong-Woon Kim*

Main category: cs.AI

TL;DR: 이 논문은 Theory of Change(변화 이론)를 AI 아키텍처에 접목한 Impact-Driven AI Framework(IDAIF)를 제안하여, 성능 중심이 아닌 사회적 임팩트 중심의 AI 설계 방법론을 제시한다.


<details>
  <summary>Details</summary>
Motivation: AI가 의료, 금융, 공공 정책 등 고위험 영역에 깊이 침투하면서, 단순한 정확도나 손실 최소화가 아니라 인간의 가치·의도와 실제 AI 행동을 정렬시키는 ‘정렬 문제(alignment problem)’가 핵심 과제로 부상했다. 기존 연구는 기술적 성능 지표에 치우쳐, 실제 배치 환경의 사회·기술적 맥락과 장기적 사회적 영향(임팩트)을 충분히 반영하지 못했다. 이에 따라 설계 단계에서부터 ‘어떤 사회적 변화를 만들려는가’라는 관점으로 AI를 구조화할 수 있는 체계적 프레임워크가 필요해졌다.

Method: Theory of Change의 5단계(투입-활동-산출-성과-임팩트)를 각각 AI 아키텍처의 5개 계층(데이터 레이어-파이프라인 레이어-추론 레이어-에이전틱 레이어-규범/노머티브 레이어)에 일대일로 매핑하는 IDAIF를 제시한다. 각 계층에 대해 수학적·이론적 정식을 제공하며, (1) 다목적 파레토 최적화를 통해 여러 가치(성능, 공정성, 안전성 등)를 동시에 고려하는 정렬, (2) 계층적 멀티에이전트 오케스트레이션을 통한 목표 달성 구조화, (3) 인과 DAG를 활용한 환각(hallucination) 감소 및 추론 신뢰성 향상, (4) 적대적 디바이어싱과 인간 피드백 기반 강화학습(RLHF)를 통한 공정성 확보 메커니즘을 포함한다. 추가적으로 가정이 깨지는 상황을 탐지·관리하는 가디언 아키텍처 중심의 ‘보증(Assurance) 레이어’를 도입한다.

Result: 제안된 IDAIF를 의료, 사이버보안, 소프트웨어 공학 세 가지 도메인에 적용한 사례 연구를 통해, 각 영역에서 입력 데이터 설계부터 에이전트 구성, 규범 레이어 정의, 보증 메커니즘까지를 체계적으로 구성할 수 있음을 보인다. 이를 통해 단순한 모델 성능 향상이 아니라, 구체적인 사회적 임팩트 목표(예: 환자 안전, 보안 위협 완화, 개발자 생산성 향상 등)에 맞춰 AI 시스템을 설계·평가할 수 있음을 시연한다.

Conclusion: IDAIF는 기존의 ‘모델 중심’ AI 개발 패러다임을 넘어, 설계 단계에서부터 목표로 하는 사회적 임팩트와 가치 정렬을 구조적으로 반영하는 ‘임팩트 중심’ AI 설계 방법론을 제안한다. 이 프레임워크는 엔지니어에게 데이터·파이프라인·추론·에이전트·규범·보증 레이어에 걸친 구체적인 아키텍처 패턴과 수학적 도구를 제공하여, 보다 윤리적이고 신뢰할 수 있으며 사회적으로 이로운 AI 시스템을 구축하는 데 실질적인 가이드를 제공한다.

Abstract: This paper introduces the Impact-Driven AI Framework (IDAIF), a novel architectural methodology that integrates Theory of Change (ToC) principles with modern artificial intelligence system design. As AI systems increasingly influence high-stakes domains including healthcare, finance, and public policy, the alignment problem--ensuring AI behavior corresponds with human values and intentions--has become critical. Current approaches predominantly optimize technical performance metrics while neglecting the sociotechnical dimensions of AI deployment. IDAIF addresses this gap by establishing a systematic mapping between ToC's five-stage model (Inputs-Activities-Outputs-Outcomes-Impact) and corresponding AI architectural layers (Data Layer-Pipeline Layer-Inference Layer-Agentic Layer-Normative Layer). Each layer incorporates rigorous theoretical foundations: multi-objective Pareto optimization for value alignment, hierarchical multi-agent orchestration for outcome achievement, causal directed acyclic graphs (DAGs) for hallucination mitigation, and adversarial debiasing with Reinforcement Learning from Human Feedback (RLHF) for fairness assurance. We provide formal mathematical formulations for each component and introduce an Assurance Layer that manages assumption failures through guardian architectures. Three case studies demonstrate IDAIF application across healthcare, cybersecurity, and software engineering domains. This framework represents a paradigm shift from model-centric to impact-centric AI development, providing engineers with concrete architectural patterns for building ethical, trustworthy, and socially beneficial AI systems.

</details>


### [38] [Using reinforcement learning to probe the role of feedback in skill acquisition](https://arxiv.org/abs/2512.08463)
*Antonio Terpin,Raffaello D'Andrea*

Main category: cs.AI

TL;DR: 이 논문은 실제 난류 유동 환경에서 범용 강화학습 에이전트를 사용해 원통의 항력을 극대/극소화하는 기술을 학습시키고, 학습에는 풍부한 피드백이 필요하지만 실행에는 그렇지 않을 수 있음을 보인다.


<details>
  <summary>Details</summary>
Motivation: 많은 고성능 인간 기술은 외부 피드백 없이도 정교하게 수행되지만, 그 기술이 어떻게 학습되는지 인간 실험으로는 제어·재현이 어렵다. 저자들은 복잡한 물리계에서의 기술 습득 과정을 정량적·재현 가능하게 연구하기 위해, 사람 대신 강화학습 에이전트를 실제 유동 물리 실험 장치에 직접 연결해 ‘고난도 기술 학습’의 메커니즘을 탐구하고자 한다.

Method: 테이블탑 순환 수조 안에 회전 가능한 원통을 두고, 그 회전 속도/패턴을 제어하는 범용 강화학습 에이전트를 연결한다. 보상은 원통에 작용하는 항력을 최대화하거나 최소화하는 값으로 정의해, 시뮬레이션 없이 실제 난류 유동에서 짧은 시간(수 분) 동안 상호작용하며 정책을 학습시킨다. 학습 후에는 센서 피드백 없이 같은 행동 시퀀스를 오픈-루프 방식으로 재생해 성능이 유지되는지를 비교한다. 또한, 학습 단계에서 유동 피드백을 제거한 조건과 포함한 조건을 비교해 목표(극대화 vs 극소화)별 학습 난이도를 분석한다.

Result: 난류 유동 상태에 대한 고차원 피드백을 제공하면 에이전트는 수 분 이내의 실제 상호작용만으로도 기존 실험 레시피에 견줄 만큼 우수한 항력 제어 전략을 발견했다. 학습 후 같은 행동 시퀀스를 피드백 없이 재생해도 항력 성능이 거의 동일해, 정책 실행에는 유동 피드백이 필요하지 않음이 확인됐다. 그러나 학습 시 유동 피드백을 제거하면 항력 극대화 문제에서는 좋은 정책을 전혀 찾지 못했고, 항력 극소화 문제에서는 여전히 학습에 성공하되 더 느리고 신뢰성이 낮았다.

Conclusion: 고성능 기술의 ‘학습’에는 풍부한 정보(예: 유동 피드백)가 필요하지만, 일단 학습된 기술의 ‘실행’에는 그러한 피드백이 필수적이지 않을 수 있음을 실험적으로 입증했다. 또한 동일한 물리계와 정책 복잡도에서도, 목표(항력 극대화 vs 극소화)에 따라 학습 환경이 매우 가혹하거나 상대적으로 온순해질 수 있음을 보여준다. 이는 기술 습득 연구와 강화학습 응용에서, 피드백 구조와 목표 설정이 학습 난이도를 결정하는 핵심 요인임을 시사한다.

Abstract: Many high-performance human activities are executed with little or no external feedback: think of a figure skater landing a triple jump, a pitcher throwing a curveball for a strike, or a barista pouring latte art. To study the process of skill acquisition under fully controlled conditions, we bypass human subjects. Instead, we directly interface a generalist reinforcement learning agent with a spinning cylinder in a tabletop circulating water channel to maximize or minimize drag. This setup has several desirable properties. First, it is a physical system, with the rich interactions and complex dynamics that only the physical world has: the flow is highly chaotic and extremely difficult, if not impossible, to model or simulate accurately. Second, the objective -- drag minimization or maximization -- is easy to state and can be captured directly in the reward, yet good strategies are not obvious beforehand. Third, decades-old experimental studies provide recipes for simple, high-performance open-loop policies. Finally, the setup is inexpensive and far easier to reproduce than human studies. In our experiments we find that high-dimensional flow feedback lets the agent discover high-performance drag-control strategies with only minutes of real-world interaction. When we later replay the same action sequences without any feedback, we obtain almost identical performance. This shows that feedback, and in particular flow feedback, is not needed to execute the learned policy. Surprisingly, without flow feedback during training the agent fails to discover any well-performing policy in drag maximization, but still succeeds in drag minimization, albeit more slowly and less reliably. Our studies show that learning a high-performance skill can require richer information than executing it, and learning conditions can be kind or wicked depending solely on the goal, not on dynamics or policy complexity.

</details>


### [39] [Autonomous Issue Resolver: Towards Zero-Touch Code Maintenance](https://arxiv.org/abs/2512.08492)
*Aliaksei Kaliutau*

Main category: cs.AI

TL;DR: 이 논문은 코드 수리 에이전트가 제어 흐름이 아닌 데이터 변환 흐름을 중심으로 코드베이스를 이해·수리하도록 하는 새로운 그래프 구조(DTG)와 멀티 에이전트 APR 프레임워크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 대형 언어모델이 함수 단위 코드 생성에는 뛰어나지만, 실제 대규모 레포지토리 수준의 자동 프로그램 수리(APR)에서는 디렉터리 구조와 복잡한 제어 흐름에 발목 잡혀 성능이 제한된다. 기존 Code Property Graph(CPG)에 기반한 접근은 제어 중심이라 버그의 근본 원인(데이터 의미·계약 위반)을 찾기 어렵고, RAG 기반 코딩 에이전트는 관련 없는 코드 조각을 많이 가져와 ‘의미론적 함정(Semantic Trap)’에 빠진다는 문제가 있다. 이를 해결하기 위해, 코드의 제어 흐름이 아니라 데이터의 변환·계약·계통(lineage)에 초점을 두는 새로운 표현과 에이전트 패러다임이 필요하다.

Method: (1) Code Property Graph와 반대로, ‘데이터 상태’를 노드로, 이 상태들을 변환하는 함수/메서드를 엣지로 두는 Data Transformation Graph(DTG)를 정의한다. 이로써 프로그램 전체를 ‘데이터가 어떻게 생성·변환·전달되는지’에 따른 계통 그래프로 표현한다. (2) DTG를 중심으로, 하나의 에이전트가 데이터 무결성과 데이터 계통을 따라 결함 후보 지점을 좁혀가고, 다른 에이전트가 구체적인 제어 흐름·구현 수준 수리를 수행하는 멀티 에이전트 프레임워크를 설계한다. (3) RAG에서 흔히 발생하는, 의미적으로 핵심이 아닌 코드 조각을 가져오는 ‘Semantic Trap’을 이 데이터 중심 탐색으로 줄일 수 있음을 이론적으로 분석하고, 사례 연구를 통해 보여준다. (4) 이를 실제 시스템으로 구현한 Autonomous Issue Resolver(AIR)를 제안한다. AIR는 DTG를 기반으로 이슈를 추적·분석하고, 신경망(LLM)과 기호적 분석을 결합한 뉴로-심볼릭 추론을 사용해 패치를 생성·검증하는 ‘제로 터치’ 자동 코드 유지보수 시스템이다. (5) SWE-Verified 등 여러 SWE 벤치마크에서 실험을 수행해, 특히 SWE-Verified에서 87.1% 이슈 해결률을 달성했음을 보고한다.

Result: DTG 기반의 멀티 에이전트 APR 프레임워크(AIR)는 기존 제어 중심 및 RAG 중심 코드 에이전트보다 높은 버그 해결률을 보였으며, SWE-Verified 벤치마크에서 87.1%의 이슈 해결률을 기록했다. 사례 연구에서, 데이터 계통을 따라가며 논리 결함을 찾는 방식이 기존 CPG·제어 흐름 중심 접근이 놓치던 의미론적 버그(데이터 무결성 위반, 잘못된 변환 체인 등)를 더 안정적으로 포착함을 보여주었다. 또한 이론 분석을 통해, DTG 기반 검색이 표준 RAG 시스템에서의 ‘Semantic Trap’을 구조적으로 완화함을 설명했다.

Conclusion: 레포지토리 규모의 자동 프로그램 수리를 위해서는 제어 흐름이 아니라 데이터 변환·계통을 중심으로 코드를 바라보는 패러다임 전환이 필요하며, Data Transformation Graph(DTG)는 이를 위한 유효한 표현 방식임을 보였다. DTG와 멀티 에이전트, 뉴로-심볼릭 추론을 결합한 AIR 시스템은 높은 버그 해결률을 통해 기존 AI 코드 어시스턴트의 핵심 한계를 완화하고, 장기적으로는 ‘제로 터치’ 코드 유지보수와 대규모 소프트웨어 생태계의 안정성을 뒷받침할 수 있는 기반 기술이 될 수 있음을 시사한다.

Abstract: Recent advances in Large Language Models have revolutionized function-level code generation; however, repository-scale Automated Program Repair (APR) remains a significant challenge. Current approaches typically employ a control-centric paradigm, forcing agents to navigate complex directory structures and irrelevant control logic. In this paper, we propose a paradigm shift from the standard Code Property Graphs (CPGs) to the concept of Data Transformation Graph (DTG) that inverts the topology by modeling data states as nodes and functions as edges, enabling agents to trace logic defects through data lineage rather than control flow. We introduce a multi-agent framework that reconciles data integrity navigation with control flow logic. Our theoretical analysis and case studies demonstrate that this approach resolves the "Semantic Trap" inherent in standard RAG systems in modern coding agents. We provide a comprehensive implementation in the form of Autonomous Issue Resolver (AIR), a self-improvement system for zero-touch code maintenance that utilizes neuro-symbolic reasoning and uses the DTG structure for scalable logic repair. Our approach has demonstrated good results on several SWE benchmarks, reaching a resolution rate of 87.1% on SWE-Verified benchmark. Our approach directly addresses the core limitations of current AI code-assistant tools and tackles the critical need for a more robust foundation for our increasingly software-dependent world.

</details>


### [40] [A Lightweight Transfer Learning-Based State-of-Health Monitoring with Application to Lithium-ion Batteries in Unmanned Air Vehicles](https://arxiv.org/abs/2512.08512)
*Jiang Liu,Yan Qin,Wei Dai,Chau Yuen*

Main category: cs.AI

TL;DR: 이 논문은 휴대용 리튬이온 배터리의 SOH(상태건강도)를 모바일 기기에서 쓸 수 있을 만큼 가벼운 전이학습 기법(CITL)으로 정확·고속 추정하는 방법을 제안한다.


<details>
  <summary>Details</summary>
Motivation: 리튬이온 배터리로 구동되는 휴대용 모바일·UAV 기기에서는 배터리 상태(SOH)를 정확히 추정해야 에너지 관리와 안전 운용이 가능하다. 기존 전이학습 기반 SOH 모니터링은 다양한 작동 조건에서의 데이터 부족 문제를 해결하지만, 전이 단계에서 많은 연산 자원을 요구해 실제 모바일 디바이스에 적용하기 어렵다. 따라서 데이터 요구량은 줄이면서도 연산 부담이 작고 신뢰할 수 있는 SOH 모니터링 방법이 필요하다.

Method: 저자는 ‘구성적 점진 전이학습(Constructive Incremental Transfer Learning, CITL)’이라는 경량 전이학습 구조를 제안한다. 1) 타깃 도메인의 비라벨 데이터까지 활용하는 반지도(supervised+unsupervised) 전이 메커니즘을 설계해, 모니터링 잔차를 최소화하는 방향으로 네트워크 노드를 점진적으로 추가(constructive incremental)한다. 2) 구조적 위험 최소화(SRM), 전이 불일치 최소화(도메인 간 분포 차이 축소), 매니폴드 일관성 최대화(원본·타깃의 기저 구조 보존)를 동시에 고려해, 새로 추가되는 노드의 파라미터가 도메인 간에서도 잘 일반화되도록 학습한다. 3) 제안한 CITL의 수렴성을 이론적으로 분석하여 TL 성능과 네트워크의 소형성(compactness)을 보장한다.

Result: 수십 회 비행 미션에서 수집된 실제 UAV 배터리 데이터셋으로 검증한 결과, 제안한 CITL은 기존 SOH 전이학습 기법(SS-TCA, MMD-LSTM-DA, DDAN, BO-CNN-TL, AS^3LSTM)에 비해 RMSE 기준으로 각각 83.73%, 61.15%, 28.24%, 87.70%, 57.34%의 오차 감소를 보여, 전반적으로 훨씬 높은 추정 정확도를 달성했다.

Conclusion: CITL 기반의 경량 전이학습 SOH 모니터링은 모바일·UAV와 같이 연산 자원이 제한된 기기에서도 적용 가능하며, 적은 타깃 도메인 라벨 데이터와 비라벨 데이터만으로도 높은 정확도와 네트워크 소형성을 동시에 달성한다. 이로써 다양한 작동 조건을 갖는 휴대용 리튬이온 배터리 시스템에서 실용적인 상태 모니터링 솔루션이 될 수 있음을 보여준다.

Abstract: Accurate and rapid state-of-health (SOH) monitoring plays an important role in indicating energy information for lithium-ion battery-powered portable mobile devices. To confront their variable working conditions, transfer learning (TL) emerges as a promising technique for leveraging knowledge from data-rich source working conditions, significantly reducing the training data required for SOH monitoring from target working conditions. However, traditional TL-based SOH monitoring is infeasible when applied in portable mobile devices since substantial computational resources are consumed during the TL stage and unexpectedly reduce the working endurance. To address these challenges, this paper proposes a lightweight TL-based SOH monitoring approach with constructive incremental transfer learning (CITL). First, taking advantage of the unlabeled data in the target domain, a semi-supervised TL mechanism is proposed to minimize the monitoring residual in a constructive way, through iteratively adding network nodes in the CITL. Second, the cross-domain learning ability of node parameters for CITL is comprehensively guaranteed through structural risk minimization, transfer mismatching minimization, and manifold consistency maximization. Moreover, the convergence analysis of the CITL is given, theoretically guaranteeing the efficacy of TL performance and network compactness. Finally, the proposed approach is verified through extensive experiments with a realistic unmanned air vehicles (UAV) battery dataset collected from dozens of flight missions. Specifically, the CITL outperforms SS-TCA, MMD-LSTM-DA, DDAN, BO-CNN-TL, and AS$^3$LSTM, in SOH estimation by 83.73%, 61.15%, 28.24%, 87.70%, and 57.34%, respectively, as evaluated using the index root mean square error.

</details>


### [41] [Principles2Plan: LLM-Guided System for Operationalising Ethical Principles into Plans](https://arxiv.org/abs/2512.08536)
*Tammy Zhong,Yang Song,Maurice Pagnucco*

Main category: cs.AI

TL;DR: 로봇이 인간 환경에서 행동할 때 필요한 윤리 의식을, 사람-LLM 협업으로 생성한 원칙 기반 규칙을 통해 자동 계획에 반영하는 연구 프로토타입 소개.


<details>
  <summary>Details</summary>
Motivation: 기존 자동 계획(플래닝) 도구는 안전·효율 같은 기술적 제약은 잘 다루지만, '이 행동이 윤리적인가?'라는 판단을 시스템 안에 녹여 넣는 기능은 거의 없다. 윤리 규칙을 사람이 일일이 설계하면 도메인·상황마다 다르고 작업량이 크며, 실무자(도메인 전문가)가 일반적인 윤리 원칙(예: 선행, 프라이버시)을 구체적인 계획 제약으로 바꾸기 어렵다. 따라서, 고수준 윤리 원칙을 각 상황에 맞는 세부 규칙으로 자동·반자동 변환해 주는 도구가 필요하다.

Method: Principles2Plan이라는 인터랙티브 프로토타입 시스템을 설계했다. 1) 도메인 전문가는 플래닝 도메인과 문제 정의, 적용하려는 윤리 원칙(선행, 프라이버시 등)을 입력한다. 2) LLM이 이 입력을 바탕으로, 원칙에 일관되면서도 실제 플래너가 사용할 수 있는 형태(운용 가능한 제약·규칙)로 윤리 규칙 후보를 생성한다. 3) 사용자는 생성된 규칙을 검토·수정하고 우선순위를 정한다. 4) 최종 규칙을 고전적 플래닝(planning) 알고리즘에 제약으로 제공하여 윤리적으로 고려된 계획을 생성하도록 한다. 이 과정을 통해 인간-LLM 협업 구조를 실증적으로 보여 준다.

Result: 시스템 수준에서, 고수준 윤리 원칙을 고전적 플래닝에 적용 가능한 세부 규칙으로 변환해 주는 인터랙티브 도구를 구현했다. LLM이 제안한 규칙을 사람이 검토·조정하고, 이를 플래너에 제공해 '윤리적으로 정보가 반영된 계획'을 생성할 수 있음을 보였다. 또한 기존 문헌을 검토한 결과, 원칙 기반 윤리 규칙을 자동 계획 맥락에서 사용자가 생성·다듬도록 돕는 선행 시스템이 없음을 확인해, 연구의 신규성을 주장한다.

Conclusion: Principles2Plan은 인간 전문가와 LLM이 협업해, 추상적인 윤리 원칙을 구체적이고 맥락 민감한 규칙으로 변환하고 이를 자동 계획에 통합할 수 있음을 보여 준다. 이 접근법은 윤리적 자동 플래닝을 실제 환경에 적용하는 데 있어 실용성과 실행 가능성을 크게 높일 잠재력이 있으며, 원칙-규칙-계획을 잇는 상호작용형 프레임워크의 유용성을 시사한다.

Abstract: Ethical awareness is critical for robots operating in human environments, yet existing automated planning tools provide little support. Manually specifying ethical rules is labour-intensive and highly context-specific. We present Principles2Plan, an interactive research prototype demonstrating how a human and a Large Language Model (LLM) can collaborate to produce context-sensitive ethical rules and guide automated planning. A domain expert provides the planning domain, problem details, and relevant high-level principles such as beneficence and privacy. The system generates operationalisable ethical rules consistent with these principles, which the user can review, prioritise, and supply to a planner to produce ethically-informed plans. To our knowledge, no prior system supports users in generating principle-grounded rules for classical planning contexts. Principles2Plan showcases the potential of human-LLM collaboration for making ethical automated planning more practical and feasible.

</details>


### [42] [CogMCTS: A Novel Cognitive-Guided Monte Carlo Tree Search Framework for Iterative Heuristic Evolution with Large Language Models](https://arxiv.org/abs/2512.08609)
*Hui Wang,Yang Liu,Xiaoyu Zhang,Chaoxu Mu*

Main category: cs.AI

TL;DR: 이 논문은 LLM과 몬테카를로 트리 탐색(MCTS)을 결합한 새로운 CogMCTS 프레임워크를 제안해, 자동 휴리스틱 설계의 탐색 효율과 해의 품질을 향상시킨다.


<details>
  <summary>Details</summary>
Motivation: 기존 LLM 기반 자동 휴리스틱 설계(AHD) 방법은 주로 진화 알고리즘의 개체군 전략에 의존해, 국소 최적해에 빠지기 쉽고 탐색‑활용 균형이 부족하다. LLM과 MCTS를 결합한 시도가 있었지만, 다회적 인지 피드백(역사 정보·노드 컨텍스트·실패 사례 등)을 충분히 활용하지 못하고 탐색 다양성이 제한되는 문제가 있다. 따라서 LLM의 인지적 능력을 더 깊게 MCTS와 통합해, 효율적이면서도 다양한 휴리스틱을 자동으로 설계할 필요가 있다.

Method: CogMCTS라는 인지‑유도 MCTS 프레임워크를 제안한다. (1) LLM의 다회전 인지 피드백을 통해 과거 탐색 경험, 노드 정보, 부정적 결과(실패한 휴리스틱)를 지속적으로 반영하여 휴리스틱 생성 정책을 동적으로 개선한다. (2) 듀얼 트랙 노드 확장 방식을 도입해, 한 트랙은 새로운 다양한 휴리스틱 탐색, 다른 트랙은 성능이 검증된 정예(elite) 휴리스틱의 활용에 집중하게 한다. (3) 정예 휴리스틱 관리 메커니즘을 통해 고품질 휴리스틱을 저장·재사용하며, (4) 전략적 돌연변이 연산으로 휴리스틱의 형태와 파라미터를 체계적으로 변형해 탐색 공간의 다양성을 확대한다.

Result: 제안한 CogMCTS를 여러 최적화 문제에서 기존 LLM 기반 AHD 및 LLM+MCTS 기법들과 비교한 결과, 탐색의 안정성(성능 분산 감소), 효율성(동일 계산 예산에서 더 빠른 수렴 또는 더 적은 평가 횟수), 그리고 해의 품질(더 낮은 비용 또는 더 높은 적합도)에서 우수한 성능을 보였다.

Conclusion: LLM의 인지적 피드백을 MCTS와 긴밀히 통합한 CogMCTS는 자동 휴리스틱 설계에서 탐색‑활용 균형과 탐색 다양성을 동시에 향상시킨다. 다회전 인지 피드백, 듀얼 트랙 확장, 정예 관리, 전략적 돌연변이의 결합을 통해 기존 LLM 기반 AHD 방법보다 더 안정적이고 고성능의 최적화 결과를 제공하며, 복잡한 최적화 문제 해결을 위한 유망한 일반적 프레임워크가 될 수 있음을 시사한다.

Abstract: Automatic Heuristic Design (AHD) is an effective1 framework for solving complex optimization prob-2 lems. The development of large language mod-3 els (LLMs) enables the automated generation of4 heuristics. Existing LLM-based evolutionary meth-5 ods rely on population strategies and are prone6 to local optima. Integrating LLMs with Monte7 Carlo Tree Search (MCTS) improves the trade-off8 between exploration and exploitation, but multi-9 round cognitive integration remains limited and10 search diversity is constrained. To overcome these11 limitations, this paper proposes a novel cognitive-12 guided MCTS framework (CogMCTS). CogMCTS13 tightly integrates the cognitive guidance mecha-14 nism of LLMs with MCTS to achieve efficient au-15 tomated heuristic optimization. The framework16 employs multi-round cognitive feedback to incor-17 porate historical experience, node information, and18 negative outcomes, dynamically improving heuris-19 tic generation. Dual-track node expansion com-20 bined with elite heuristic management balances the21 exploration of diverse heuristics and the exploita-22 tion of high-quality experience. In addition, strate-23 gic mutation modifies the heuristic forms and pa-24 rameters to further enhance the diversity of the so-25 lution and the overall optimization performance.26 The experimental results indicate that CogMCTS27 outperforms existing LLM-based AHD methods in28 stability, efficiency, and solution quality.

</details>


### [43] [Protein Secondary Structure Prediction Using Transformers](https://arxiv.org/abs/2512.08613)
*Manzi Kevin Maxime*

Main category: cs.AI

TL;DR: 이 논문은 트랜스포머 기반 모델로 단백질 2차 구조(알파 나선, 베타 병풍, 코일)를 아미노산 서열로부터 예측한다.


<details>
  <summary>Details</summary>
Motivation: 단백질의 기능 이해를 위해서는 1차 서열만으로 2차 구조(알파 헬릭스, 베타 시트, 코일)를 정확히 예측하는 것이 중요하다. 기존 방법은 긴 서열에서 국소·장거리 잔기 상호작용을 동시에 잘 포착하기 어렵다. 트랜스포머와 어텐션은 장거리 의존성 모델링에 강점을 가지므로 이를 단백질 구조 예측에 적용하고자 한다.

Method: CB513 데이터셋에 대해 슬라이딩 윈도우 데이터 증강을 수행해 학습 샘플을 늘리고, 트랜스포머 기반 모델에 단백질 서열을 입력하여 어텐션 메커니즘으로 잔기 간 상호작용(국소 및 장거리)을 학습하게 한다. 모델은 가변 길이 서열을 처리하도록 설계되었다.

Result: 트랜스포머 모델은 다양한 길이의 단백질 서열에 대해 잘 일반화하며, 국소 및 장거리 잔기 상호작용을 효과적으로 포착하는 능력을 보였다. (초록에서는 정량 지표는 제시하지 않음).

Conclusion: 트랜스포머와 어텐션 메커니즘은 단백질 2차 구조 예측에서 가변 길이 서열 처리와 장거리 상호작용 학습에 유리하며, 슬라이딩 윈도우 기반 데이터 증강과 결합할 경우 구조 모티프 예측에 효과적인 접근법이 될 수 있음을 시사한다.

Abstract: Predicting protein secondary structures such as alpha helices, beta sheets, and coils from amino acid sequences is essential for understanding protein function. This work presents a transformer-based model that applies attention mechanisms to protein sequence data to predict structural motifs. A sliding-window data augmentation technique is used on the CB513 dataset to expand the training samples. The transformer shows strong ability to generalize across variable-length sequences while effectively capturing both local and long-range residue interactions.

</details>


### [44] [See-Control: A Multimodal Agent Framework for Smartphone Interaction with a Robotic Arm](https://arxiv.org/abs/2512.08629)
*Haoyu Zhao,Weizhong Ding,Yuhao Yang,Zheng Tian,Linyi Yang,Kun Shao,Jun Wang*

Main category: cs.AI

TL;DR: 이 논문은 안드로이드 ADB에 의존하지 않고, 로봇 팔을 이용해 실제 스마트폰 화면을 직접 조작하는 멀티모달 LLM 기반 프레임워크 See-Control과 ESO 태스크·벤치마크를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존 스마트폰 조작형 지능 에이전트는 ADB 등 시스템 백엔드 접근에 의존해 안드로이드에만 제한되고, 실제 물리 환경의 다양한 스마트폰·OS에 일반화하기 어렵다. 집안 로봇이 스마트폰을 활용해 여러 작업을 수행하려면 디지털 에이전트가 물리 세계에서 스마트폰을 직접 다룰 수 있는 새로운 패러다임이 필요하다.

Method: Embodied Smartphone Operation(ESO)라는 새로운 태스크를 정의하고, 저자유도(low-DoF) 로봇 팔이 스마트폰을 직접 터치·조작하도록 하는 See-Control 프레임워크를 설계한다. MLLM을 기반으로 한 체화 에이전트가 화면을 인식해 로봇 제어 명령을 생성하며, ADB나 시스템 백엔드 접근 없이 동작한다. 이를 위해 155개 작업과 평가지표를 갖춘 벤치마크, 그리고 풍부한 주석이 달린 스마트폰 조작 에피소드 데이터셋을 구축한다.

Result: See-Control은 플랫폼에 구애받지 않는(플랫폼-불가지론적) 스마트폰 조작을 가능하게 하고, 155개 ESO 과제에 대한 평가 환경과 데이터셋을 제공함으로써 MLLM 기반 로봇-스마트폰 상호작용 연구를 체계적으로 실험·비교할 수 있는 기반을 마련했다.

Conclusion: 디지털 에이전트(MLLM)와 물리 세계(로봇, 실제 스마트폰) 사이의 간극을 줄이는 구체적 프레임워크를 제시했으며, 이를 통해 향후 가정용 로봇이 다양한 스마트폰 의존 작업을 실제 환경에서 수행하도록 만드는 방향으로 한 걸음 나아갔다.

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have enabled their use as intelligent agents for smartphone operation. However, existing methods depend on the Android Debug Bridge (ADB) for data transmission and action execution, limiting their applicability to Android devices. In this work, we introduce the novel Embodied Smartphone Operation (ESO) task and present See-Control, a framework that enables smartphone operation via direct physical interaction with a low-DoF robotic arm, offering a platform-agnostic solution. See-Control comprises three key components: (1) an ESO benchmark with 155 tasks and corresponding evaluation metrics; (2) an MLLM-based embodied agent that generates robotic control commands without requiring ADB or system back-end access; and (3) a richly annotated dataset of operation episodes, offering valuable resources for future research. By bridging the gap between digital agents and the physical world, See-Control provides a concrete step toward enabling home robots to perform smartphone-dependent tasks in realistic environments.

</details>


### [45] [Multi-Agent Intelligence for Multidisciplinary Decision-Making in Gastrointestinal Oncology](https://arxiv.org/abs/2512.08674)
*Rongzhao Zhang,Junqiao Wang,Shuyun Yang,Mouxiao Bian,Chao Ding,Yuwei Bai,Chihao Zhang,Yuguang Shen,Lei Wang,Lei Zheng,Qiujuan Yan,Yun Zhong,Meiling Liu,Jiwei Yu,Zheng Wang,Jie Xu,Meng Luo*

Main category: cs.AI

TL;DR: 이 논문은 위장관 종양학에서 내시경, 영상, 혈액검사 등 다양한 데이터를 함께 이해하기 위해, 인간 다학제팀(MDT)의 협업 방식을 모방한 계층형 멀티에이전트 프레임워크를 제안하며, 단일 MLLM보다 임상 추론 성능과 정확도가 크게 향상되었음을 보인다.


<details>
  <summary>Details</summary>
Motivation: GI 종양학 진료에서는 내시경 이미지, 영상의학 소견, 생화학 지표 등 이질적인 데이터를 통합적으로 해석해야 하는데, 기존 멀티모달 LLM은 복잡한 병력과 다양한 모달리티가 섞일 때 문맥 희석과 환각 문제가 두드러진다. 이를 해결하고 실제 다학제 진료처럼 역할을 분담해 협업하는 방식으로 더 정확하고 신뢰할 수 있는 자동 의사결정 지원 시스템을 구축하는 것이 동기이다.

Method: 인간의 다학제팀(MDT) 협업을 모방한 계층형 멀티에이전트 구조를 설계한다. 서로 다른 역할을 가진 다수의 에이전트가 내시경, 영상, 생화학 데이터에 대해 분담 분석을 수행하고, 상위 조정 에이전트가 이들의 결과를 통합해 임상 추론과 결론을 도출하도록 한다. 이 구조를 기존의 단일(모놀리식) MLLM 기반 시스템과 비교 평가한다.

Result: 제안한 시스템은 전문가 복합 평가 점수 4.60/5.00을 기록해 단일 MLLM 기반 기준 모델보다 성능이 유의하게 높았다. 특히 추론 논리의 일관성, 의료적 정확도 측면에서 가장 큰 성능 향상이 관찰되었다.

Conclusion: 다수의 역할 특화 에이전트가 협업하는, 인간 MDT를 모방한 에이전트 기반 구조는 다중 모달 의료 데이터에 대한 임상 추론에서 확장 가능하고 해석 가능하며 임상적으로 견고한 자동 의사결정 지원 패러다임이 될 수 있음을 보여준다.

Abstract: Multimodal clinical reasoning in the field of gastrointestinal (GI) oncology necessitates the integrated interpretation of endoscopic imagery, radiological data, and biochemical markers. Despite the evident potential exhibited by Multimodal Large Language Models (MLLMs), they frequently encounter challenges such as context dilution and hallucination when confronted with intricate, heterogeneous medical histories. In order to address these limitations, a hierarchical Multi-Agent Framework is proposed, which emulates the collaborative workflow of a human Multidisciplinary Team (MDT). The system attained a composite expert evaluation score of 4.60/5.00, thereby demonstrating a substantial improvement over the monolithic baseline. It is noteworthy that the agent-based architecture yielded the most substantial enhancements in reasoning logic and medical accuracy. The findings indicate that mimetic, agent-based collaboration provides a scalable, interpretable, and clinically robust paradigm for automated decision support in oncology.

</details>


### [46] [Deconstructing the Dual Black Box:A Plug-and-Play Cognitive Framework for Human-AI Collaborative Enhancement and Its Implications for AI Governance](https://arxiv.org/abs/2512.08740)
*Yiming Lu*

Main category: cs.AI

TL;DR: 인간 전문가의 직관적 사고를 구조화하여 AI와 결합 가능한 ‘인지 플러그인’으로 만들고, 이를 메타 사고 네트워크(RAMTN)에 장착해 인간‑AI 협업형 인지 향상을 구현하는 프레임워크 제안 논문.


<details>
  <summary>Details</summary>
Motivation: 현재 인간 전문가의 ‘인지 블랙박스’(암묵지, 직관)와 AI 모델의 ‘계산 블랙박스’(설명·신뢰 부족)가 분리되어 있어, 상호 보완적 협업·검증이 어렵고, 전문가 지식이 체계적으로 재사용·확장되기 힘들다. 또한 AI 거버넌스에서도 모델 내부를 들여다보는 방식은 한계가 크므로, 새로운 투명성과 통제 방법이 필요하다.

Method: 1) 전문가 대화에서 추출 가능한 ‘플러그 앤 플레이 인지 프레임워크’(computable knowledge package)를 정의하고 형식화한다. 2) 이 패키지를 재귀적 대항적 메타 사고 네트워크(RAMTN)에 로딩해, 인간 전문가의 진단 로직·교육 직관 등을 계산 가능한 모듈로 사용한다. 3) 이를 통해 인간‑AI 간 구조화된 ‘메타 인터랙션’ 프로토콜을 설계하고, 실제 시스템 구현 및 사례 검증(의료 진단, 교육 등)을 수행한다. 4) 전체 프레임워크와 프로토콜을 오픈소스로 공개해 재현성과 확장성을 확보한다.

Result: 전문가의 암묵적 사고 패턴을 구조화·컴퓨팅 가능한 모듈(인지 패키지)로 추출해 RAMTN에 장착하는 데 성공했고, 이를 통해 AI가 단순 도구가 아니라 전문가의 사고 과정을 함께 구성·검증하는 ‘생각 파트너’로 동작함을 사례로 보였다. 또한, 모델 내부 파라미터를 해부하지 않고도, 상호작용 프로토콜의 투명화·기록을 통해 검증 가능하고 개입 가능한 AI 거버넌스 메커니즘을 설계 가능함을 시연했다.

Conclusion: 인간‑AI 협업형 인지 향상을 위해, 전문가 직관과 AI 연산을 하나의 ‘기능적 화이트박스’로 통합하는 메타 인터랙션 기반 프레임워크가 유효함을 초기 공학적 증거로 제시한다. 이 접근은 ‘인지 형평성’을 구현하고, 모델 내부를 직접 들여다보지 않고도 상호작용 규약의 투명성을 통해 새로운 AI 거버넌스 경로를 제공한다. 제안된 RAMTN 및 인지 패키지 개념은 향후 다양한 도메인에서 재사용·확장 가능하며, 오픈소스로서 공익적·포용적 AI 발전에 기여할 수 있음을 시사한다.

Abstract: Currently, there exists a fundamental divide between the "cognitive black box" (implicit intuition) of human experts and the "computational black box" (untrustworthy decision-making) of artificial intelligence (AI). This paper proposes a new paradigm of "human-AI collaborative cognitive enhancement," aiming to transform the dual black boxes into a composable, auditable, and extensible "functional white-box" system through structured "meta-interaction." The core breakthrough lies in the "plug-and-play cognitive framework"--a computable knowledge package that can be extracted from expert dialogues and loaded into the Recursive Adversarial Meta-Thinking Network (RAMTN). This enables expert thinking, such as medical diagnostic logic and teaching intuition, to be converted into reusable and scalable public assets, realizing a paradigm shift from "AI as a tool" to "AI as a thinking partner." This work not only provides the first engineering proof for "cognitive equity" but also opens up a new path for AI governance: constructing a verifiable and intervenable governance paradigm through "transparency of interaction protocols" rather than prying into the internal mechanisms of models. The framework is open-sourced to promote technology for good and cognitive inclusion. This paper is an independent exploratory research conducted by the author. All content presented, including the theoretical framework (RAMTN), methodology (meta-interaction), system implementation, and case validation, constitutes the author's individual research achievements.

</details>


### [47] [Towards Foundation Models with Native Multi-Agent Intelligence](https://arxiv.org/abs/2512.08743)
*Shuyue Hu,Haoyang Yan,Yiqun Zhang,Yang Chen,Dongzhan Zhou,Lei Bai*

Main category: cs.AI

TL;DR: 이 논문은 대규모 기초 모델(FM)에 ‘멀티에이전트 지능’을 원천적으로 부여하기 위한 핵심 능력과 향후 연구 방향을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 기초 모델이 단일 에이전트로서 GUI 조작, 도구 사용 등은 잘하지만, 실제 응용에서는 여러 에이전트가 상호작용하는 복잡한 환경이 점점 중요해지고 있다. 현재 커뮤니티에서는 멀티에이전트 능력이 모델 규모 증가와 함께 자연스럽게 생길 것이라는 암묵적 가정이 있는데, 이 가정이 타당한지 검증하고, 부족하다면 어떻게 보완해야 할지 체계적으로 논의할 필요가 있다.

Method: 41개의 서로 다른 대형 언어 모델을 대상으로 멀티에이전트 상황에서의 능력을 평가하고, 그 결과를 바탕으로 멀티에이전트 맥락에서 중요한 네 가지 핵심 능력(이해, 계획, 효율적 소통, 적응)을 정의한다. 이어서 데이터셋 구성, 평가 지표/벤치마크, 학습 패러다임, 안전성 측면에서 어떤 연구가 필요할지 개념적으로 정리한다.

Result: 실험 결과, 단일 에이전트 과제에서 강력한 성능을 보이는 모델이라도 멀티에이전트 환경에서는 일관되고 강건한 성능을 보이지 못한다는 경험적 증거를 제시했다. 즉, ‘모델이 크면 멀티에이전트 지능도 저절로 생긴다’는 가정이 성립하지 않음을 보여준다.

Conclusion: 멀티에이전트 지능은 단일 에이전트 성능의 자동 산물이 아니라 별도의 연구·설계가 필요한 영역이며, 이를 위해 이해·계획·커뮤니케이션·적응 네 축을 중심으로 데이터셋, 평가, 학습, 안전 연구를 체계적으로 진행해야 한다고 결론짓는다.

Abstract: Foundation models (FMs) are increasingly assuming the role of the "brain" of AI agents. While recent efforts have begun to equip FMs with native single-agent abilities -- such as GUI interaction or integrated tool use -- we argue that the next frontier is endowing FMs with native multi-agent intelligence. We identify four core capabilities of FMs in multi-agent contexts: understanding, planning, efficient communication, and adaptation. Contrary to assumptions about the spontaneous emergence of such abilities, we provide extensive empirical evidence across 41 large language models showing that strong single-agent performance alone does not automatically yield robust multi-agent intelligence. To address this gap, we outline key research directions -- spanning dataset construction, evaluation, training paradigms, and safety considerations -- for building FMs with native multi-agent intelligence.

</details>


### [48] [Performance Comparison of Aerial RIS and STAR-RIS in 3D Wireless Environments](https://arxiv.org/abs/2512.08755)
*Dongdong Yang,Bin Li,Jiguang He*

Main category: cs.AI

TL;DR: 이 논문은 무인기(UAV)에 탑재된 공중 RIS와 STAR-RIS의 3차원 무선 환경에서의 성능을 정량적으로 비교한다.


<details>
  <summary>Details</summary>
Motivation: 6G에서 커버리지와 용량 향상을 위해 RIS와 STAR-RIS가 주목받고 있으나, 특히 UAV에 탑재된 공중 구조물로 사용할 때 두 구조 간의 성능 차이와 최적 배치 전략에 대한 체계적 비교 연구가 부족하다.

Method: 방향성 안테나 패턴을 반영한 정확한 공중 채널 모델을 구축하고, UAV의 고도와 자세(방향)에 따른 영향을 분석한다. RIS와 STAR-RIS 각각에 대해 시스템 합율(sum-rate) 최대화를 위한 공동 최적화 문제를 정식화하고, 가중 최소 평균제곱오차(WMMSE)와 블록 좌표 하강(BCD)에 기반한 효율적 알고리즘을 제안한다.

Result: 시뮬레이션을 통해 저고도에서는 전공간(Full-space) 커버리지를 제공하는 STAR-RIS가 RIS보다 우수한 합율 성능을 보이고, 반대로 기지국에 더 가까운 고고도 영역에서는 RIS가 STAR-RIS보다 성능이 더 좋음을 보였다.

Conclusion: 공중 RIS와 STAR-RIS는 고도와 배치 환경에 따라 장단점이 다르며, 저고도·양방향 커버리지가 필요한 경우 STAR-RIS, 기지국 인접 고고도에서는 RIS가 더 적합하다. 이 결과는 향후 6G 공중 지능형 표면 설계와 배치 전략 수립에 실질적인 가이드라인을 제공한다.

Abstract: Reconfigurable intelligent surface (RIS) and simultaneously transmitting and reflecting RIS (STAR-RIS) have emerged as key enablers for enhancing wireless coverage and capacity in next-generation networks. When mounted on unmanned aerial vehicles (UAVs), they benefit from flexible deployment and improved line-of-sight conditions. Despite their promising potential, a comprehensive performance comparison between aerial RIS and STAR-RIS architectures has not been thoroughly investigated. This letter presents a detailed performance comparison between aerial RIS and STAR-RIS in three-dimensional wireless environments. Accurate channel models incorporating directional radiation patterns are established, and the influence of deployment altitude and orientation is thoroughly examined. To optimize the system sum-rate, we formulate joint optimization problems for both architectures and propose an efficient solution based on the weighted minimum mean square error and block coordinate descent algorithms. Simulation results reveal that STAR-RIS outperforms RIS in low-altitude scenarios due to its full-space coverage capability, whereas RIS delivers better performance near the base station at higher altitudes. The findings provide practical insights for the deployment of aerial intelligent surfaces in future 6G communication systems.

</details>


### [49] [A Practical Guide for Designing, Developing, and Deploying Production-Grade Agentic AI Workflows](https://arxiv.org/abs/2512.08769)
*Eranga Bandara,Ross Gore,Peter Foytik,Sachin Shetty,Ravi Mukkamala,Abdul Rahman,Xueping Liang,Safdar H. Bouk,Amin Hass,Sachini Rajapakse,Ng Wee Keong,Kasun De Zoysa,Aruna Withanage,Nilaan Loganathan*

Main category: cs.AI

TL;DR: 이 논문은 생산 환경에서 신뢰성과 안전성을 갖춘 에이전트형 AI(Agentic AI) 워크플로를 설계·구현·운영하는 실무 지침을 제시한다.


<details>
  <summary>Details</summary>
Motivation: 단일 LLM 프롬프트 기반 자동화로는 복잡한 멀티스텝 업무, 도구 연동, 거버넌스 요구를 만족하기 어렵다. 산업계와 연구계에서 에이전트형 AI 도입이 빠르게 늘고 있어, 여러 에이전트·도구·외부 시스템을 묶어 안정적이고 관측 가능하며 유지보수 가능한 프로덕션급 워크플로를 어떻게 설계·운영할지에 대한 체계적인 방법론이 필요하다.

Method: 에이전트형 AI 시스템을 위한 구조화된 엔지니어링 라이프사이클을 제안한다. 여기에는 (1) 워크플로 분해, (2) 멀티 에이전트 설계 패턴, (3) MCP(Model Context Protocol) 및 도구 통합, (4) 결정적 오케스트레이션 설계, (5) 책임 있는 AI(Responsible-AI) 고려, (6) 환경 인지적 배포 전략이 포함된다. 이어서 MCP 기반 툴 우선 설계, 순수 함수형 툴 호출, 단일 책임 에이전트, 프롬프트 외부화, 모델 컨소시엄 설계, 워크플로 로직과 MCP 서버 분리, 컨테이너 기반 배포, KISS 원칙 등 9가지 핵심 베스트 프랙티스를 체계적으로 정리한다. 마지막으로 멀티모달 뉴스 분석 및 미디어 생성 워크플로 사례를 설계·구현해 제안 원칙을 검증한다.

Result: 제안된 라이프사이클과 9가지 베스트 프랙티스를 통해 복수 LLM·도구·에이전트가 참여하는 복잡한 워크플로에서도 결정적 오케스트레이션, 관측 가능성, 유지보수 용이성, 안전·거버넌스 정렬을 동시에 달성할 수 있음을 보인다. 사례 연구를 통해 실제 시스템에서 아키텍처 구성, MCP 기반 도구 설계, 배포 전략이 어떻게 적용되는지 구체적으로 제시한다.

Conclusion: 에이전트형 AI는 단순 프롬프트 호출을 넘어, 여러 특화 에이전트와 도구, 오케스트레이션 논리를 갖춘 프로덕션 워크플로로 발전하고 있다. 이 논문은 이를 위한 종합적인 엔지니어링 프레임워크와 실무 베스트 프랙티스를 제시함으로써, 신뢰성과 확장성, 책임성을 갖춘 에이전트형 AI 시스템 구축을 위한 기초 참고서 역할을 한다.

Abstract: Agentic AI marks a major shift in how autonomous systems reason, plan, and execute multi-step tasks. Unlike traditional single model prompting, agentic workflows integrate multiple specialized agents with different Large Language Models(LLMs), tool-augmented capabilities, orchestration logic, and external system interactions to form dynamic pipelines capable of autonomous decision-making and action. As adoption accelerates across industry and research, organizations face a central challenge: how to design, engineer, and operate production-grade agentic AI workflows that are reliable, observable, maintainable, and aligned with safety and governance requirements. This paper provides a practical, end-to-end guide for designing, developing, and deploying production-quality agentic AI systems. We introduce a structured engineering lifecycle encompassing workflow decomposition, multi-agent design patterns, Model Context Protocol(MCP), and tool integration, deterministic orchestration, Responsible-AI considerations, and environment-aware deployment strategies. We then present nine core best practices for engineering production-grade agentic AI workflows, including tool-first design over MCP, pure-function invocation, single-tool and single-responsibility agents, externalized prompt management, Responsible-AI-aligned model-consortium design, clean separation between workflow logic and MCP servers, containerized deployment for scalable operations, and adherence to the Keep it Simple, Stupid (KISS) principle to maintain simplicity and robustness. To demonstrate these principles in practice, we present a comprehensive case study: a multimodal news-analysis and media-generation workflow. By combining architectural guidance, operational patterns, and practical implementation insights, this paper offers a foundational reference to build robust, extensible, and production-ready agentic AI workflows.

</details>


### [50] [CARLoS: Retrieval via Concise Assessment Representation of LoRAs at Scale](https://arxiv.org/abs/2512.08826)
*Shahar Sarfaty,Adi Haviv,Uri Hacohen,Niva Elkin-Koren,Roi Livni,Amit H. Bermano*

Main category: cs.AI

TL;DR: CARLoS는 수많은 LoRA를 메타데이터 없이도 자동으로 특성화하고 검색할 수 있는 표현·검색 프레임워크다.


<details>
  <summary>Details</summary>
Motivation: LoRA와 같은 생성형 컴포넌트가 폭발적으로 늘어나면서, 어떤 LoRA가 어떤 시각적/의미적 효과를 내는지 체계적으로 알 수 있는 방법이 부족하다. 현재는 사용자가 적어 둔 설명이나 다운로드 수 같은 편향된 인기도 지표에 의존해 검색·발견을 하는데, 이는 부정확하고 신뢰성이 낮다. 따라서 LoRA의 동작을 데이터 기반으로 분석해 공통적인 표현 공간에 넣고, 이를 통해 더 정확한 검색·분류·법적 분석까지 가능하게 하는 체계가 필요하다.

Method: 650개 이상의 LoRA를 대상으로, 다양한 텍스트 프롬프트와 시드 조합으로 이미지를 생성한 뒤, 각 LoRA로 생성된 이미지와 기본(base) 모델로 생성된 이미지를 CLIP 임베딩 공간에서 비교한다. 이때 임베딩 차이를 이용해 각 LoRA의 영향을 세 가지 요소로 분해해 표현한다. (1) Directions: CLIP 임베딩 상에서 LoRA가 유도하는 의미적 이동 방향(어떤 개념/스타일로 이동하는지). (2) Strength: 그 이동의 크기, 즉 LoRA 효과의 강도. (3) Consistency: 서로 다른 프롬프트·시드에서도 효과가 얼마나 안정적으로 반복되는지. 이런 표현을 기반으로 텍스트 질의와 LoRA 표현을 매칭하는 검색 시스템을 설계하고, 강도와 일관성이 지나치게 크거나 낮은 LoRA를 필터링할 수 있는 메커니즘을 포함한다.

Result: 제안한 CARLoS 표현(Directions, Strength, Consistency)을 사용해 구축한 검색 시스템은, LoRA 제작자가 쓴 설명문이나 단순 키워드 매칭에 기반한 기존 텍스트 기반 검색보다 자동 평가와 인간 평가 모두에서 더 관련성 높은 LoRA를 찾아준다. 또한 Strength와 Consistency 지표는 저작권 맥락에서 논의되는 ‘실질성(substantiality)’과 ‘자의성(volition)’과도 정량적으로 연결될 수 있음을 보여, 단순 검색을 넘어 LoRA의 법적·윤리적 분석에도 활용 가능함을 시사한다.

Conclusion: CARLoS는 LoRA를 CLIP 기반의 세 가지 지표(Directions, Strength, Consistency)로 요약함으로써, 메타데이터 없이도 대규모 LoRA 생태계를 구조화하고 탐색할 수 있음을 보였다. 이 표현은 텍스트–LoRA 의미 매칭과 품질 필터링에서 기존 방법을 능가하며, 동시에 저작권 관련 개념과도 연계 가능한 해석 가능성을 제공한다. 따라서 CARLoS는 실용적인 LoRA 검색 시스템이자, 향후 LoRA 분석·규제·평가 연구의 기반 도구로 활용될 수 있는 잠재력을 가진다.

Abstract: The rapid proliferation of generative components, such as LoRAs, has created a vast but unstructured ecosystem. Existing discovery methods depend on unreliable user descriptions or biased popularity metrics, hindering usability. We present CARLoS, a large-scale framework for characterizing LoRAs without requiring additional metadata. Analyzing over 650 LoRAs, we employ them in image generation over a variety of prompts and seeds, as a credible way to assess their behavior. Using CLIP embeddings and their difference to a base-model generation, we concisely define a three-part representation: Directions, defining semantic shift; Strength, quantifying the significance of the effect; and Consistency, quantifying how stable the effect is. Using these representations, we develop an efficient retrieval framework that semantically matches textual queries to relevant LoRAs while filtering overly strong or unstable ones, outperforming textual baselines in automated and human evaluations. While retrieval is our primary focus, the same representation also supports analyses linking Strength and Consistency to legal notions of substantiality and volition, key considerations in copyright, positioning CARLoS as a practical system with broader relevance for LoRA analysis.

</details>


### [51] [Interpolation in Knowledge Representation](https://arxiv.org/abs/2512.08833)
*Jean Christoph Jung,Patrick Koopmann,Matthias Knorr*

Main category: cs.AI

TL;DR: 이 논문은 지식 표현에서 중요한 크레이그 보간과 균일 보간의 이론·실용적 측면을, 특히 기술 논리(Description Logic)와 논리 프로그래밍을 중심으로 정리·분석한다.


<details>
  <summary>Details</summary>
Motivation: 설명 가능성, 망각(지식 삭제), 모듈화 및 재사용, 학습 등 다양한 지식 표현 작업에서 보간이 핵심 도구인데, 실제 많이 쓰이는 형식들에서는 보간 성질이 항상 성립하지 않고, 있어도 실제 보간식을 계산하는 것이 매우 어렵기 때문에, 이론적 조건과 실용적 알고리즘을 체계적으로 이해·정리할 필요가 있다.

Method: 대표적 지식 표현 형식인 기술 논리와 논리 프로그래밍을 대상으로, (1) 크레이그 보간 및 균일 보간 가능 여부에 대한 기존 이론 결과를 조사·정리하고, (2) 가능한 경우에 보간식을 실제로 계산하기 위한 알고리즘·기법들을 비교·분석한다.

Result: 기술 논리와 논리 프로그래밍에서 언제 보간/균일 보간이 존재하는지에 대한 조건과 한계가 분명해지고, 현재 사용 가능한 보간 계산 방법들(예: 특정 파편에 대한 알고리즘, 변환 기반 기법 등)의 장단점과 적용 범위가 정리된다.

Conclusion: 지식 표현에서 보간은 여러 응용에 필수적이지만, 기술 논리와 논리 프로그래밍에서는 이론적 제약과 계산 복잡성 때문에 일반적으로 쉽지 않으며, 특정 제한된 경우에만 효과적으로 계산 가능하다는 점을 보여준다. 또한 이러한 분석은 향후 더 강한 보간 성질을 갖는 논리 설계나, 보다 효율적인 보간 계산 알고리즘 개발의 필요성을 시사한다.

Abstract: Craig interpolation and uniform interpolation have many applications in knowledge representation, including explainability, forgetting, modularization and reuse, and even learning. At the same time, many relevant knowledge representation formalisms do in general not have Craig or uniform interpolation, and computing interpolants in practice is challenging. We have a closer look at two prominent knowledge representation formalisms, description logics and logic programming, and discuss theoretical results and practical methods for computing interpolants.

</details>


### [52] [EcomBench: Towards Holistic Evaluation of Foundation Agents in E-commerce](https://arxiv.org/abs/2512.08868)
*Rui Min,Zile Qiao,Ze Xu,Jiawen Zhai,Wenyu Gao,Xuanzhong Chen,Haozhen Sun,Zhen Zhang,Xinyu Wang,Hong Zhou,Wenbiao Yin,Xuan Zhou,Yong Jiang,Haicheng Liu,Liang Ding,Ling Zou,Yi R.,Fung,Yalong Li,Pengjun Xie*

Main category: cs.AI

TL;DR: 이 논문은 실제 전자상거래 환경에서 지능형 에이전트의 성능을 평가하기 위한 현실적 벤치마크(EcomBench)를 제안한다.


<details>
  <summary>Details</summary>
Motivation: 기존 에이전트 벤치마크는 주로 학술적·인위적 시나리오에 집중해, 실제 애플리케이션에서 발생하는 복잡한 요구(다양한 사용자 상호작용, 동적인 시장 환경, 실제 의사결정과 직결된 업무)를 제대로 반영하지 못했다. 특히 전자상거래 도메인은 이러한 실제적 난제가 집약된 분야이지만, 이를 포괄적으로 다루는 평가 기준이 부족했다.

Method: 연구진은 글로벌 주요 이커머스 플랫폼에서 추출한 실제 사용자 요구를 바탕으로, 인간 전문가가 명확성·정확성·도메인 관련성을 기준으로 선별·주석을 달아 EcomBench를 구축했다. 이 벤치마크는 여러 전자상거래 작업 카테고리(예: 상품 탐색, 추천, 의사결정 지원 등)를 포함하고, 정보 탐색 난이도와 추론 복잡도에 따라 세 가지 난이도로 구성되며, 심층 정보 검색, 다단계 추론, 복수 정보원의 통합 능력 등을 측정하도록 설계되었다.

Result: EcomBench는 실제 이커머스 맥락에 기반해, 다양한 난이도와 작업 유형에서 에이전트의 실질적 문제 해결 능력을 측정할 수 있는 동적 테스트베드를 제공한다. 이를 통해 기존 벤치마크로는 드러나지 않던 에이전트의 강·약점을 보다 현실적으로 드러낼 수 있다.

Conclusion: EcomBench는 현실 세계 전자상거래 환경을 반영한 전면적인 벤치마크로, 에이전트의 실용적 역량(정보 검색, 복합 추론, 지식 통합)을 체계적으로 평가할 수 있게 한다. 이를 통해 향후 에이전트 개발·개선이 실제 비즈니스 요구와 더 잘 정렬되도록 돕는 기반 인프라 역할을 한다.

Abstract: Foundation agents have rapidly advanced in their ability to reason and interact with real environments, making the evaluation of their core capabilities increasingly important. While many benchmarks have been developed to assess agent performance, most concentrate on academic settings or artificially designed scenarios while overlooking the challenges that arise in real applications. To address this issue, we focus on a highly practical real-world setting, the e-commerce domain, which involves a large volume of diverse user interactions, dynamic market conditions, and tasks directly tied to real decision-making processes. To this end, we introduce EcomBench, a holistic E-commerce Benchmark designed to evaluate agent performance in realistic e-commerce environments. EcomBench is built from genuine user demands embedded in leading global e-commerce ecosystems and is carefully curated and annotated through human experts to ensure clarity, accuracy, and domain relevance. It covers multiple task categories within e-commerce scenarios and defines three difficulty levels that evaluate agents on key capabilities such as deep information retrieval, multi-step reasoning, and cross-source knowledge integration. By grounding evaluation in real e-commerce contexts, EcomBench provides a rigorous and dynamic testbed for measuring the practical capabilities of agents in modern e-commerce.

</details>


### [53] [Same Content, Different Answers: Cross-Modal Inconsistency in MLLMs](https://arxiv.org/abs/2512.08923)
*Angela van Sprang,Laurens Samson,Ana Lucic,Erman Acar,Sennay Ghebreab,Yuki M. Asano*

Main category: cs.AI

TL;DR: 이 논문은 MLLM의 텍스트·이미지·혼합 입력 사이에서 생기는 모달리티 불일치를 체계적으로 측정하기 위한 REST/REST+ 벤치마크를 제안하고, 기존 모델들이 같은 의미의 정보를 모달만 바꿔 제시했을 때도 일관되게 추론하지 못함을 보여준다.


<details>
  <summary>Details</summary>
Motivation: 멀티모달 대형 언어 모델(MLLM)은 언어와 시각 정보를 같은 임베딩 공간에서 다루도록 학습되지만, 실제로는 같은 의미의 정보를 텍스트로 줄 때와 이미지로 줄 때 서로 다른 성능과 판단을 보인다. 기존 평가 세트는 이런 ‘교차 모달리티 불일치’를 정량적으로 측정·분석하기 어렵기 때문에, 모달만 바꾸어도 답이 달라지는 문제를 정교하게 드러내고 그 원인을 분석하기 위한 새로운 벤치마크가 필요하다.

Method: 1) 동일한 의미(semantic information)를 담되 표현 형태만 다른 세 가지 모달리티(이미지, 텍스트, 텍스트+이미지 혼합)로 구성된 문제들을 설계하여 REST 및 REST+ 벤치마크를 구축한다. 2) 15개의 최신 MLLM을 대상으로 각 모달리티별 성능과 모달 간 일관성을 측정한다. 3) OCR 오류를 통제한 상태에서도 계속되는 성능 차이를 분석하고, 텍스트 색상·해상도·폰트, 비전 토큰 수 등 시각적 요인이 성능에 미치는 영향을 정량적으로 평가한다. 4) 텍스트와 이미지 임베딩 간 ‘모달리티 갭’과 제안한 일관성 점수의 상관관계를 분석해, 불일치의 기계적(메카니즘 관점) 해석을 시도한다.

Result: (1) 15개 SOTA MLLM 모두에서, 같은 의미의 정보를 모달만 바꾸어 제시했을 때 정답이나 추론 과정이 일관되지 못한 경우가 광범위하게 관찰된다. (2) OCR 문제를 보정해도 모달리티 불일치는 상당 부분 남아 있으며, 텍스트를 이미지로 렌더링하거나 이미지를 텍스트로 옮겨도 완전히 해결되지 않는다. (3) 텍스트 색상과 해상도, 그리고 비전 토큰 수는 모델 성능과 일관성에 유의미한 영향을 주지만, 폰트 종류는 상대적으로 영향이 적다. (4) 제안한 모달 일관성 점수는 텍스트-이미지 임베딩 간 모달리티 갭과 강하게 상관되어, 임베딩 공간에서의 거리/차이가 불일치의 중요한 원인임을 시사한다.

Conclusion: REST/REST+는 MLLM의 교차 모달리티 불일치를 체계적으로 측정·분석할 수 있는 새로운 벤치마크이며, 현재 SOTA 모델들도 동일 의미의 정보를 다른 모달로 제시하면 추론이 일관되지 못함이 확인된다. 이 불일치는 단순한 OCR 문제나 텍스트-이미지 변환만으로 해결되지 않고, 색상·해상도·비전 토큰 수 같은 시각적 요소와 텍스트·이미지 임베딩 간 모달리티 갭에 깊게 연관되어 있다. 따라서 향후 MLLM 연구는 단일 모달 성능뿐 아니라 모달 간 일관성, 임베딩 공간 정렬, 시각적 렌더링 요인까지 고려한 학습·아키텍처 설계가 필요함을 시사한다.

Abstract: We introduce two new benchmarks REST and REST+(Render-Equivalence Stress Tests) to enable systematic evaluation of cross-modal inconsistency in multimodal large language models (MLLMs). MLLMs are trained to represent vision and language in the same embedding space, yet they cannot perform the same tasks in both modalities. Our benchmarks contain samples with the same semantic information in three modalities (image, text, mixed) and we show that state-of-the-art MLLMs cannot consistently reason over these different modalities. We evaluate 15 MLLMs and find that the degree of modality inconsistency varies substantially, even when accounting for problems with text recognition (OCR). Neither rendering text as image nor rendering an image as text solves the inconsistency. Even if OCR is correct, we find that visual characteristics (text colour and resolution, but not font) and the number of vision tokens have an impact on model performance. Finally, we find that our consistency score correlates with the modality gap between text and images, highlighting a mechanistic interpretation of cross-modal inconsistent MLLMs.

</details>
